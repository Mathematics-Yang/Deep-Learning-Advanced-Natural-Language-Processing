{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4adc40a3",
   "metadata": {},
   "source": [
    "# 第五章 &nbsp; &nbsp; RNN \n",
    "到目前为止，我们看到的神经网络都是前馈型神经网络。 **前馈（feedforward）** 是指网络的传播方向是单向的。具体地说，先将输入信号传给下一层（隐藏层），接收到信号的层也同样传给下一层，然后再传给下一层……像这样，信号仅在一个方向上传播。\n",
    "\n",
    "虽然前馈网络结构简单、易于理解，但是可以应用于许多任务中。不过，这种网络存在一个大问题，就是不能很好地处理时间序列数据（以下简称为“时序数据”）。更确切地说，单纯的前馈网络无法充分学习时序数据的性质（模式）。于是，**RNN（Recurrent Neural Network，循环神经网络）**便应运而生。\n",
    "\n",
    "本章我们将指出前馈网络的问题，并介绍 RNN 如何很好地解决这些问题。然后，我们会详细解释 RNN 的结构，并用 Python 对其进行实现。\n",
    "\n",
    "## 概率和语言模型\n",
    "作为介绍 RNN 的准备，我们将首先复习上一章的 word2vec，然后使用概率描述自然语言相关的现象，最后介绍从概率视角研究语言的“语言模型”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d5a28",
   "metadata": {},
   "source": [
    "## 概率视角下的word2vec\n",
    "我们先复习一下 word2vec 的 CBOW 模型。这里，我们来考虑由单词序列 $w_1, w_2, \\cdots, w_T$ 表示的语料库，将第 $t$ 个单词作为目标词，将它左右的（第 $t - 1$ 个和第 $t + 1$ 个）单词作为上下文。\n",
    "\n",
    "在本书中，目标词是指中间的单词，上下文是指目标词周围的单词。\n",
    "\n",
    "如图所示，CBOW 模型所做的事情就是从上下文（$w_{t - 1}$ 和 $w_{t + 1}$）预测目标词（$w_t$）。\n",
    "\n",
    "<img src=\"./fig/CBOW_word2vec_predict.png\" alt=\"CBOW_word2vec_predict\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "下面，我们用数学式来表示 “当给定 $w_{t - 1}$ 和 $w_{t + 1}$ 时目标词是 $w_t$ 的概率”，如式 (5.1) 所示：\n",
    "\n",
    "$$P(w_t | w_{t - 1}, w_{t + 1}) \\tag{5.1}$$\n",
    "\n",
    "CBOW 模型对式 (5.1) 这一后验概率进行建模。这个后验概率表示 “当给定 $w_{t - 1}$ 和 $w_{t + 1}$ 时 $w_t$ 发生的概率”。这是窗口大小为 1 时的 CBOW 模型。\n",
    "\n",
    "顺便提一下，我们之前考虑的窗口都是左右对称的。这里我们将上下文限定为左侧窗口，比如图所示的情况。\n",
    "\n",
    "<img src=\"./fig/context_left.png\" alt=\"context_left\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "在仅将左侧 2 个单词作为上下文的情况下，CBOW 模型输出的概率如式 (5.2) 所示：\n",
    "\n",
    "$$P(w_t | w_{t - 2}, w_{t - 1}) \\tag{5.2}$$\n",
    "\n",
    "word2vec 的上下文窗口大小是超参数，可以设置为任何值。这里将窗口大小设置为左右非对称的形式，即左侧 2 个单词，右侧 0 个单词。这样设定的理由是提前考虑了后面要说的语言模型。\n",
    "\n",
    "使用式 (5.2) 的写法，CBOW 模型的损失函数可以写成式 (5.3)。式 (5.3) 是从交叉熵误差推导出来的结果。\n",
    "\n",
    "$$L = -\\log P(w_t | w_{t - 2}, w_{t - 1}) \\tag{5.3}$$\n",
    "\n",
    "CBOW 模型的学习旨在找到使式 (5.3) 表示的损失函数（确切地说，是整个语料库的损失函数之和）最小的权重参数。只要找到了这样的权重参数，CBOW 模型就可以更准确地从上下文预测目标词。\n",
    "\n",
    "像这样，CBOW 模型的学习目的是从上下文预测出目标词。为了达成这一目标，随着学习的推进，（作为副产品）获得了编码了单词含义信息的单词的分布式表示。\n",
    "\n",
    "那么，CBOW 模型本来的目的 “从上下文预测目标词” 是否可以用来做些什么呢？式 (5.2) 表示的概率 $P(w_t | w_{t - 2}, w_{t - 1})$ 是否可以在一些实际场景中发挥作用呢？说到这里，就要提一下语言模型了。\n",
    "\n",
    "###  语言模型\n",
    "**语言模型（language model）** 给出了单词序列发生的概率。具体来说，就是使用概率来评估一个单词序列发生的可能性，即在多大程度上是自然的单词序列。比如，对于 “you say goodbye” 这一单词序列，语言模型给出高概率（比如 0.092）；对于 “you say good die” 这一单词序列，模型则给出低概率（比如 0.000 000 000 003 2）。\n",
    "\n",
    "语言模型可以应用于多种应用，典型的例子有机器翻译和语音识别。比如，语音识别系统会根据人的发言生成多个句子作为候选。此时，使用语言模型，可以按照 “作为句子是否自然” 这一基准对候选句子进行排序。\n",
    "\n",
    "语言模型也可以用于生成新的句子。因为语言模型可以使用概率来评价单词序列的自然程度，所以它可以根据这一概率分布造出（采样）单词。另外，第 7 章中我们会讨论如何使用语言模型生成文章。\n",
    "\n",
    "现在，我们使用数学式来表示语言模型。这里考虑由 $m$ 个单词 $w_1, \\cdots, w_m$ 构成的句子，将单词按 $w_1, \\cdots, w_m$ 的顺序出现的概率记为 $P(w_1, \\cdots, w_m)$。因为这个概率是多个事件一起发生的概率，所以称为**联合概率**。\n",
    "\n",
    "使用后验概率可以将这个联合概率 $P(w_1, \\cdots, w_m)$ 分解成如下形式：\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(w_1, \\cdots, w_m) &= P(w_m | w_1, \\cdots, w_{m - 1})P(w_{m - 1} | w_1, \\cdots, w_{m - 2}) \\\\\n",
    "&\\quad \\cdots P(w_3 | w_1, w_2)P(w_2 | w_1)P(w_1) \\\\\n",
    "&= \\prod_{t = 1}^{m} P(w_t | w_1, \\cdots, w_{t - 1}) \\tag{5.4}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "与表示总和的 $\\sum$（sigma）相对，式 (5.4) 中的 $\\prod$（pi）表示所有元素相乘的乘积。如式 (5.4) 所示，联合概率可以由后验概率的乘积表示。\n",
    "\n",
    "式 (5.4) 的结果可以从概率的**乘法定理**推导出来。这里我们花一点时间来说明一下乘法定理，并看一下式 (5.4) 的推导过程。\n",
    "\n",
    "首先，概率的乘法定理可由下式表示：\n",
    "\n",
    "$$P(A,B) = P(A|B)P(B) \\tag{5.5}$$\n",
    "\n",
    "式 (5.5) 表示的乘法定理是概率论中最重要的定理，意思是 “$A$ 和 $B$ 两个事件共同发生的概率 $P(A,B)$” 是 “$B$ 发生的概率 $P(B)$” 和 “$B$ 发生后 $A$ 发生的概率 $P(A|B)$” 的乘积（这个解释感觉上非常自然）。\n",
    "\n",
    "概率 $P(A,B)$ 也可以分解为 $P(A,B) = P(B|A)P(A)$。也就是说，根据将 $A$ 和 $B$ 中的哪一个作为后验概率的条件，存在 $P(A,B) = P(B|A)P(A)$ 和 $P(A,B) = P(A|B)P(B)$ 两种表示方法。\n",
    "\n",
    "使用这个乘法定理，$m$ 个单词的联合概率 $P(w_1, \\cdots, w_m)$ 就可以用后验概率来表示。为了便于理解，我们先将式子如下变形：\n",
    "\n",
    "$$\\underbrace{P(w_1, \\cdots, w_{m - 1}, w_m)}_{A} = P(A, w_m) = P(w_m|A)P(A) \\tag{5.6}$$\n",
    "\n",
    "这里，将 $w_1, \\cdots, w_{m - 1}$ 整体表示为 $A$。这样一来，按照乘法定理，可以推导出式 (5.6)。接着，再对 $A(w_1, \\cdots, w_{m - 1})$ 进行同样的变形：\n",
    "\n",
    "$$P(A) = \\underbrace{P(w_1, \\cdots, w_{m - 2}, w_{m - 1})}_{A'} = P(A', w_{m - 1}) = P(w_{m - 1}|A')P(A') \\tag{5.7}$$\n",
    "\n",
    "像这样，单词序列每次减少一个，分解为后验概率。然后，重复这一过程，就可以推导出式 (5.4)。\n",
    "\n",
    "如式 (5.4) 所示，联合概率 $P(w_1, \\cdots, w_m)$ 可以表示为后验概率的乘积 $\\prod P(w_t|w_1, \\cdots, w_{t - 1})$。这里需要注意的是，这个后验概率是以目标词左侧的全部单词为上下文（条件）时的概率，如下图所示。\n",
    "\n",
    "<img src=\"./fig/language_model_possibility.png\" alt=\"language_model_possibility\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "这里我们来总结一下，我们的目标是求 $P(w_t|w_1, \\cdots, w_{t - 1})$ 这个概率。如果能计算出这个概率，就能求得语言模型的联合概率 $P(w_1, \\cdots, w_m)$。\n",
    "\n",
    "由 $P(w_t|w_1, \\cdots, w_{t - 1})$ 表示的模型称为条件语言模型（conditional language model），有时也将其称为语言模型。\n",
    "\n",
    "### 将CBOW模型用作语言模型？\n",
    "那么，如果要把 word2vec 的 CBOW 模型（强行）用作语言模型，该怎么办呢？可以通过将上下文的大小限制在某个值来近似实现，用数学式可以如下表示：\n",
    "\n",
    "$$P(w_1, \\cdots, w_m) = \\prod_{t = 1}^{m} P(w_t|w_1, \\cdots, w_{t - 1}) \\approx \\prod_{t = 1}^{m} P(w_t|w_{t - 2}, w_{t - 1}) \\tag{5.8}$$\n",
    "\n",
    "这里，我们将上下文限定为左侧的 2 个单词。如此一来，就可以用 CBOW 模型（CBOW 模型的后验概率）近似表示。\n",
    "\n",
    "在机器学习和统计学领域，经常会听到 “马尔可夫性”（或者 “马尔可夫模型”“马尔可夫链”）这个词。马尔可夫性是指未来的状态仅依存于当前状态。此外，当某个事件的概率仅取决于其前面的 $N$ 个事件时，称为 “$N$ 阶马尔可夫链”。这里展示的是下一个单词仅取决于前面 2 个单词的模型，因此可以称为 “2 阶马尔可夫链”。\n",
    "\n",
    "式 (5.8) 是使用 2 个单词作为上下文的例子，但是这个上下文的大小可以设定为任意长度（比如 5 或 10）。不过，虽说可以设定为任意长度，但必须是某个“固定”长度。比如，即便是使用左侧 10 个单词作为上下文的 CBOW 模型，其上下文更左侧的单词的信息也会被忽略，而这会导致问题，如图中的例子所示。\n",
    "\n",
    "<img src=\"./fig/long_context_example.png\" alt=\"long_context_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "在上图的问题中，“Tom 在房间看电视，Mary 进了房间”。根据该语境（上下文），正确答案应该是 Mary 向 Tom（或者 “him”）打招呼。这里要获得正确答案，就必须将 “?” 前面第 18 个单词处的 Tom 记住。如果 CBOW 模型的上下文大小是 10，则这个问题将无法被正确回答。\n",
    "\n",
    "那么，是否可以通过增大 CBOW 模型的上下文大小（比如变为 20 或 30）来解决此问题呢？的确，CBOW 模型的上下文大小可以任意设定，但是 CBOW 模型还存在忽视了上下文中单词顺序的问题。\n",
    "\n",
    "CBOW是 Continuous Bag-Of-Words 的简称。Bag-Of-Words 是 “一袋子单词” 的意思，这意味着袋子中单词的顺序被忽视了。\n",
    "\n",
    "关于上下文的单词顺序被忽视这个问题，我们举个例子来具体说明。比如，在上下文是 2 个单词的情况下，CBOW 模型的中间层是那 2 个单词向量的和，如图所示。\n",
    "\n",
    "<img src=\"./fig/CBOW_compared.png\" alt=\"CBOW_compared\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如上图的左图所示，在 CBOW 模型的中间层求单词向量的和，因此上下文的单词顺序会被忽视。比如，(you, say) 和 (say, you) 会被作为相同的内容进行处理。\n",
    "\n",
    "我们想要的是考虑了上下文中单词顺序的模型。为此，可以像图 5-5 中的右图那样，在中间层 “拼接”（concatenate）上下文的单词向量。实际上，“Neural Probabilistic Language Model”中提出的模型就采用了这个方法。但是，如果采用拼接的方法，权重参数的数量将与上下文大小成比例地增加。显然，这是我们不愿意看到的。\n",
    "\n",
    "那么，如何解决这里提出的问题呢？这就轮到 RNN 出场了。RNN 具有一个机制，那就是无论上下文有多长，都能将上下文信息记住。因此，使用 RNN 可以处理任意长度的时序数据。下面，我们就来感受一下 RNN 的魅力。\n",
    "\n",
    "word2vec 是以获取单词的分布式表示为目的的方法，因此一般不会用于语言模型。这里，为了引出 RNN 的魅力，我们拓展了话题，强行将 word2vec 的 CBOW 模型应用在了语言模型上。word2vec 和基于 RNN 的语言模型是由托马斯・米科洛夫团队分别在 2013 年和 2010 年提出的。基于 RNN 的语言模型虽然也能获得单词的分布式表示，但是为了应对词汇量的增加、提高分布式表示的质量，word2vec 被提了出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32001f71",
   "metadata": {},
   "source": [
    "## RNN\n",
    "RNN（Recurrent Neural Network）中的 Recurrent 源自拉丁语，意思是“反复发生”，可以翻译为“重复发生”“周期性地发生”“循环”，因此 RNN 可以直译为“复发神经网络”或者“循环神经网络”。下面，我们将探讨“循环”一词。\n",
    "\n",
    "Recurrent Neural Network 通常译为“循环神经网络”。另外，还有一种被称为 Recursive Neural Network（递归神经网络）的网络。这个网络主要用于处理树结构的数据，和循环神经网络不是一个东西。\n",
    "\n",
    "## 循环的神经网络\n",
    "“循环”是什么意思呢？是“反复并持续”的意思。从某个地点出发，经过一定时间又回到这个地点，然后重复进行，这就是“循环”一词的含义。这里要注意的是，循环需要一个“环路”。\n",
    "\n",
    "只有存在了“环路”或者“回路”这样的路径，媒介（或者数据）才能在相同的地点之间来回移动。随着数据的循环，信息不断被更新。\n",
    "\n",
    "血液在我们体内循环。今天流动的血液是接着昨天的血液继续流动的。另外，它也是接着一周前的、一个月前的、一年前的，甚至刚出生时的血液继续流动的。血液通过在体内循环，从过去一直被“更新”到现在。\n",
    "\n",
    "RNN 的特征就在于拥有这样一个环路（或回路）。这个环路可以使数据不断循环。通过数据的循环，RNN 一边记住过去的数据，一边更新到最新的数据。\n",
    "\n",
    "下面，我们来具体地看一下 RNN。这里，我们将 RNN 中使用的层称为“RNN 层”，如图所示。\n",
    "\n",
    "<img src=\"./fig/RNN_layer.png\" alt=\"RNN_layer\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，RNN 层有环路。通过该环路，数据可以在层内循环。在图中，时刻 $t$ 的输入是 $\\boldsymbol{x}_t$，这暗示着时序数据 $(\\boldsymbol{x}_0, \\boldsymbol{x}_1, \\cdots, \\boldsymbol{x}_t, \\cdots)$ 会被输入到层中。然后，以与输入对应的形式，输出 $(\\boldsymbol{h}_0, \\boldsymbol{h}_1, \\cdots, \\boldsymbol{h}_t, \\cdots)$。\n",
    "\n",
    "这里假定在各时刻向 RNN 层输入的 $\\boldsymbol{x}_t$ 是向量。比如，在处理句子（单词序列）的情况下，将各个单词的分布式表示（单词向量）作为 $\\boldsymbol{x}_t$ 输入 RNN 层。\n",
    "\n",
    "仔细看一下上图，可以发现输出有两个分叉，这意味着同一个东西被复制了。输出中的一个分叉将成为其自身的输入。\n",
    "\n",
    "接着，我们来详细介绍一下循环结构。在此之前，我们先将 RNN 层的绘制方法更改如下。\n",
    "\n",
    "如下图所示，到目前为止，我们在绘制层时都是假设数据从左向右流动的。不过，从现在开始，为了节省纸面空间，我们将假设数据是从下向上流动的（这是为了在之后需要展开循环时，能够在左右方向上将层铺开）。\n",
    "\n",
    "<img src=\"./fig/RNN_layer_spin.png\" alt=\"RNN_layer_spin\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "###  展开循环\n",
    "现在，准备工作已经完成了，我们来仔细看一下 RNN 层的循环结构。RNN 的循环结构在之前的神经网络中从未出现过，但是通过展开循环，可以将其转化为我们熟悉的神经网络。百闻不如一见，现在我们就实际地进行展开。\n",
    "\n",
    "<img src=\"./fig/RNN_layer_unfold.png\" alt=\"RNN_layer_unfold\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，通过展开 RNN 层的循环，我们将其转化为了从左向右延伸的长神经网络。这和我们之前看到的前馈神经网络的结构相同（前馈网络的数据只向一个方向传播）。不过，图中的多个 RNN 层都是“**同一个层**”，这一点与之前的神经网络是不一样的。\n",
    "\n",
    "时序数据按时间顺序排列。因此，我们用“时刻”这个词指代时序数据的索引（比如，时刻$t$的输入数据为$\\boldsymbol{x}_t$）。在自然语言处理的情况下，既使用“第$t$个单词”“第$t$个RNN层”这样的表述，也使用“时刻$t$的单词”或者“时刻$t$的RNN层”这样的表述。\n",
    "\n",
    "由上图可以看出，各个时刻的 RNN 层接收传给该层的输入和前一个 RNN 层的输出，然后据此计算当前时刻的输出，此时进行的计算可以用下式表示：\n",
    "\n",
    "$$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{h}_{t - 1}\\boldsymbol{W}_h + \\boldsymbol{x}_t\\boldsymbol{W}_x + \\boldsymbol{b}) \\tag{5.9}$$\n",
    "\n",
    "首先说明一下式 (5.9) 中的符号。RNN 有两个权重，分别是将输入 $\\boldsymbol{x}$ 转化为输出 $\\boldsymbol{h}$ 的权重 $\\boldsymbol{W}_x$ 和将前一个 RNN 层的输出转化为当前时刻的输出的权重 $\\boldsymbol{W}_h$。此外，还有偏置 $\\boldsymbol{b}$。这里，$\\boldsymbol{h}_{t - 1}$ 和 $\\boldsymbol{x}_t$ 都是行向量。\n",
    "\n",
    "在式 (5.9) 中，首先执行矩阵的乘积计算，然后使用 $\\tanh$ 函数（双曲正切函数）变换它们的和，其结果就是时刻 $t$ 的输出 $\\boldsymbol{h}_t$。这个 $\\boldsymbol{h}_t$ 一方面向上输出到另一个层，另一方面向右输出到下一个 RNN 层（自身）。\n",
    "\n",
    "观察式 (5.9) 可以看出，现在的输出 $\\boldsymbol{h}_t$ 是由前一个输出 $\\boldsymbol{h}_{t - 1}$ 计算出来的。从另一个角度看，这可以解释为，RNN 具有 “状态” $\\boldsymbol{h}$，并以式 (5.9) 的形式被更新。这就是说 RNN 层是 “具有状态的层” 或 “具有存储（记忆）的层” 的原因。\n",
    "\n",
    "RNN 的 $\\boldsymbol{h}$ 存储“状态”，时间每前进一步（一个单位），它就以式 (5.9) 的形式被更新。许多文献中将 RNN 的输出 $\\boldsymbol{h}_t$ 称为隐藏状态（hidden state）或隐藏状态向量（hidden state vector），本书中也是如此。\n",
    "\n",
    "另外，许多文献中将展开后的 RNN 层绘制成下图的左图。\n",
    "\n",
    "<img src=\"./fig/RNN_layer_compared.png\" alt=\"RNN_layer_compared\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "在左图中，从 RNN 层输出了两个箭头，但是请注意这两个箭头代表的是同一份数据（准确地说，是同一份数据被复制了）。在本书中，和之前一样，我们明确地在图中显示了输出处存在分叉，如右图所示。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b196162",
   "metadata": {},
   "source": [
    "## Backpropagation Through Time\n",
    "将 RNN 层展开后，就可以视为在水平方向上延伸的神经网络，因此 RNN 的学习可以用与普通神经网络的学习相同的方式进行，如图所示。\n",
    "\n",
    "<img src=\"./fig/RNN_backpropagation.png\" alt=\"RNN_backpropagation\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，将循环展开后的 RNN 可以使用（常规的）误差反向传播法。换句话说，可以通过先进行正向传播，再进行反向传播的方式求目标梯度。因为这里的误差反向传播法是 “按时间顺序展开的神经网络的误差反向传播法”，所以称为 **Backpropagation Through Time**（基于时间的反向传播），简称 BPTT。\n",
    "\n",
    "通过该 BPTT，RNN 的学习似乎可以进行了，但是在这之前还有一个必须解决的问题，那就是学习长时序数据的问题。因为随着时序数据的时间跨度的增大，BPTT 消耗的计算机资源也会成比例地增大。另外，反向传播的梯度也会变得不稳定。\n",
    "\n",
    "要基于 BPTT 求梯度，必须在内存中保存各个时刻的 RNN 层的中间数据（RNN 层的反向传播将在后文中说明）。因此，随着时序数据变长，计算机的内存使用量（不仅仅是计算量）也会增加。\n",
    "\n",
    "## Truncated BPTT\n",
    "在处理长时序数据时，通常的做法是将网络连接截成适当的长度。具体来说，就是将时间轴方向上过长的网络在合适的位置进行截断，从而创建多个小型网络，然后对截出来的小型网络执行误差反向传播法，这个方法称为 **Truncated BPTT**（截断的 BPTT）。\n",
    "\n",
    "Truncated 是“被截断”的意思。Truncated BPTT 是指按适当长度截断的误差反向传播法。\n",
    "\n",
    "在 Truncated BPTT 中，网络连接被截断，但严格地讲，只是网络的反向传播的连接被截断，正向传播的连接依然被维持，这一点很重要。也就是说，正向传播的信息没有中断地传播。与此相对，反向传播则被截断为适当的长度，以被截出的网络为单位进行学习。\n",
    "\n",
    "现在，我们结合具体的例子来介绍 Truncated BPTT。假设有一个长度为 1000 的时序数据。在自然语言处理的情况下，这相当于一个有 1000 个单词的语料库。顺便说一下，我们之前处理的 PTB 数据集将多个串联起来的句子当作一个大的时序数据。这里也一样，将多个串联起来的句子当作一个时序数据。\n",
    "\n",
    "在处理长度为 1000 的时序数据时，如果展开 RNN 层，它将成为在水平方向上排列有 1000 个层的网络。当然，无论排列多少层，都可以根据误差反向传播法计算梯度。但是，如果序列太长，就会出现计算量或者内存使用量方面的问题。此外，随着层变长，梯度逐渐变小，梯度将无法向前一层传递。因此，如图所示，我们来考虑在水平方向上以适当的长度截断网络的反向传播的连接。\n",
    "\n",
    "------\n",
    "\n",
    "在自然语言处理（NLP）中，将“多个串联起来的句子当作一个大的时序数据”是一种常见的数据处理方式，目的是为了更高效地训练循环神经网络（RNN）或Transformer等模型，尤其与Truncated BPTT（截断的时间反向传播）的训练方式相适配。\n",
    "\n",
    "\n",
    "### 具体含义：把句子“连起来”形成长序列\n",
    "假设我们有3个独立的句子：\n",
    "1. \"I like machine learning.\"\n",
    "2. \"It is interesting and useful.\"\n",
    "3. \"I want to learn more.\"\n",
    "\n",
    "在NLP中，我们会先将每个句子拆分为单词（或子词）的序列，再添加特殊标记（如句尾标记`<eos>`），最后把它们**首尾拼接**成一个连续的长序列：\n",
    "\n",
    "```\n",
    "[\"I\", \"like\", \"machine\", \"learning\", \"<eos>\", \n",
    " \"It\", \"is\", \"interesting\", \"and\", \"useful\", \"<eos>\", \n",
    " \"I\", \"want\", \"to\", \"learn\", \"more\", \"<eos>\"]\n",
    "```\n",
    "\n",
    "这个拼接后的长序列就被视为一个**单一的时序数据**，其中每个单词（包括`<eos>`）是时序数据中的一个“时间步”。当处理类似PTB（Penn Treebank）这样的语料库时，整个数据集会被拼接成一个极长的时序序列（可能包含数万甚至数十万个单词）。\n",
    "\n",
    "\n",
    "### 为什么要这样做？\n",
    "1. **适配RNN的“时序连续性”**  \n",
    "   RNN的核心能力是处理时序依赖关系（如“上下文语义”），而句子之间往往存在潜在的语义关联（例如篇章中的逻辑衔接）。将句子拼接成连续序列，能让模型学习到更广泛的上下文依赖，而不仅仅是单个句子内部的关系。\n",
    "\n",
    "2. **提高训练效率**  \n",
    "   若单独处理每个句子，句子长度通常较短（比如平均20-30个单词），训练时需要频繁处理“句子开始/结束”的边界，效率较低。拼接成大序列后，可以更充分地利用计算资源（如GPU的并行计算能力）。\n",
    "\n",
    "3. **配合Truncated BPTT的训练需求**  \n",
    "   Truncated BPTT的核心是将超长时序数据**分段截断**后训练（例如将1000步的长序列分成10段，每段100步）。如果原始数据是分散的短句子，截断后可能频繁出现“跨句子”的无效截断；而拼接成大序列后，截断可以更灵活地在连续的时序中进行，减少边界干扰。\n",
    "\n",
    "\n",
    "### 与Truncated BPTT的结合示例\n",
    "假设我们有一个拼接后的长时序数据（长度1000，即1000个单词）：\n",
    "\n",
    "```\n",
    "[w1, w2, ..., w100, w101, ..., w200, ..., w901, ..., w1000]\n",
    "```\n",
    "\n",
    "Truncated BPTT的处理方式是：\n",
    "1. 将长序列**按固定长度截断**（如每100步为一段），得到10个分段：`[w1-w100], [w101-w200], ..., [w901-w1000]`。\n",
    "2. 对每个分段独立计算前向传播和反向传播（只在分段内部更新梯度），避免了原始BPTT处理1000步时的梯度消失/爆炸问题。\n",
    "3. 由于原始数据是连续拼接的，相邻分段（如`w1-w100`和`w101-w200`）在语义上仍有连续性，模型通过“隐藏状态传递”（保留上一分段的最终隐藏状态作为下一分段的初始状态），仍能学到跨分段的时序依赖。\n",
    "\n",
    "\n",
    "### 关键总结\n",
    "“将多个句子串联成大的时序数据”本质上是一种**数据整合策略**，它：\n",
    "- 让模型能学习更广泛的上下文依赖（从句子内扩展到句子间）；\n",
    "- 与Truncated BPTT的“分段截断”训练方式完美适配，既解决了RNN训练的梯度问题，又保留了时序连续性；\n",
    "- 是PTB等经典语料库的标准处理方式，也是早期RNN/LSTM在NLP中成功应用的重要基础。\n",
    "\n",
    "-----\n",
    "\n",
    "<img src=\"./fig/RNN_cut_off.png\" alt=\"RNN_cut_off\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "在图中，我们截断了反向传播的连接，以使学习可以以 10 个 RNN 层为单位进行。像这样，只要将反向传播的连接截断，就不需要再考虑块范围以外的数据了，因此可以以各个块为单位（和其他块没有关联）完成误差反向传播法。\n",
    "\n",
    "这里需要注意的是，虽然反向传播的连接会被截断，但是正向传播的连接不会。因此，在进行 RNN 的学习时，必须考虑到正向传播之间是有关联的，这意味着必须按顺序输入数据。下面，我们来说明什么是按顺序输入数据。\n",
    "\n",
    "我们之前看到的神经网络在进行 mini-batch 学习时，数据都是随机选择的。但是，在 RNN 执行 Truncated BPTT 时，数据需要按顺序输入。\n",
    "\n",
    "现在，我们考虑使用 Truncated BPTT 来学习 RNN。我们首先要做的是，将第 1 个块的输入数据 $(\\boldsymbol{x}_0, \\cdots, \\boldsymbol{x}_9)$ 输入 RNN 层。这里要进行的处理如下图所示。\n",
    "\n",
    "<img src=\"./fig/propagation_cut_off.png\" alt=\"propagation_cut_off\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，先进行正向传播，再进行反向传播，这样可以得到所需的梯度。接着，对下一个块的输入数据 $(\\boldsymbol{x}_{10}, \\boldsymbol{x}_{11}, \\cdots, \\boldsymbol{x}_{19})$ 执行误差反向传播法，如下图所示。\n",
    "\n",
    "<img src=\"./fig/two_propagation.png\" alt=\"two_propagation\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "这里，和第 1 个块一样，先执行正向传播，再执行反向传播。这里的重点是，这个正向传播的计算需要前一个块最后的隐藏状态 $\\boldsymbol{h}_9$，这样可以维持正向传播的连接。\n",
    "\n",
    "用同样的方法，继续学习第 3 个块，此时要使用第 2 个块最后的隐藏状态 $\\boldsymbol{h}_{19}$。像这样，在 RNN 的学习中，通过将数据按顺序输入，从而继承隐藏状态进行学习。根据到目前为止的讨论，可知 RNN 的学习流程如下图所示。\n",
    "\n",
    "<img src=\"./fig/Truncated_BPTT_example.png\" alt=\"Truncated_BPTT_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，Truncated BPTT 按顺序输入数据，进行学习。这样一来，能够在维持正向传播的连接的同时，以块为单位应用误差反向传播法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c442814",
   "metadata": {},
   "source": [
    "## Truncated BPTT的mini-batch学习\n",
    "到目前为止，我们在探讨 Truncated BPTT 时，并没有考虑 mini-batch 学习。换句话说，我们之前的探讨对应于批大小为 1 的情况。为了执行 mini-batch 学习，需要考虑批数据，让它也能像上图一样按顺序输入数据。因此，在输入数据的开始位置，需要在各个批次中进行 “偏移”。\n",
    "\n",
    "为了说明 “偏移”，我们仍用上一节的通过 Truncated BPTT 进行学习的例子，对长度为 1000 的时序数据，以时间长度 10 为单位进行截断。此时，如何将批大小设为 2 进行学习呢？在这种情况下，作为 RNN 层的输入数据，第 1 笔样本数据从头开始按顺序输入，第 2 笔数据从第 500 个数据开始按顺序输入。也就是说，将开始位置平移 500，如下图所示。\n",
    "\n",
    "<img src=\"./fig/mini_batch.png\" alt=\"mini_batch\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，批次的第 1 个元素是 $\\boldsymbol{x}_0, \\cdots, \\boldsymbol{x}_9$，批次的第 2 个元素是 $\\boldsymbol{x}_{500}, \\cdots, \\boldsymbol{x}_{509}$，将这个 mini-batch 作为 RNN 的输入数据进行学习。因为要输入的数据是按顺序的，所以接下来是时序数据的第 10～19 个数据和第 510～519 个数据。像这样，在进行 mini-batch 学习时，平移各批次输入数据的开始位置，按顺序输入。此外，如果在按顺序输入数据的过程中遇到了结尾，则需要设法返回头部。\n",
    "\n",
    "如上所述，虽然 Truncated BPTT 的原理非常简单，但是关于数据的输入方法有几个需要注意的地方。具体而言，一是要按顺序输入数据，二是要平移各批次（各样本）输入数据的开始位置。这里的探讨有些复杂，大家一时间可能还不能理解，之后通过实际查看和运行代码，相信大家就能够理解了。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1260e",
   "metadata": {},
   "source": [
    "## RNN的实现\n",
    "通过之前的探讨，我们已经看到了 RNN 的全貌。实际上，我们要实现的是一个在水平方向上延伸的神经网络。另外，考虑到基于 Truncated BPTT 的学习，只需要创建一个在水平方向上长度固定的网络序列即可，如图所示。\n",
    "\n",
    "<img src=\"./fig/RNN_network.png\" alt=\"RNN_network\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，目标神经网络接收长度为 $T$ 的时序数据（$T$ 为任意值），输出各个时刻的隐藏状态 $T$ 个。这里，考虑到模块化，将图中在水平方向上延伸的神经网络实现为“一个层”，如下图所示。\n",
    "\n",
    "<img src=\"./fig/RNN_time.png\" alt=\"RNN_time\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，将垂直方向上的输入和输出分别捆绑在一起，就可以将水平排列的层视为一个层。换句话说，可以将 $(\\boldsymbol{x}_0, \\boldsymbol{x}_1, \\cdots, \\boldsymbol{x}_{T - 1})$ 捆绑为 $\\boldsymbol{x}s$ 作为输入，将 $(\\boldsymbol{h}_0, \\boldsymbol{h}_1, \\cdots, \\boldsymbol{h}_{T - 1})$ 捆绑为 $\\boldsymbol{h}s$ 作为输出。这里，我们将进行 Time RNN 层中的单步处理的层称为“RNN 层”，将一次处理 $T$ 步的层称为“Time RNN 层”。\n",
    "\n",
    "像 Time RNN 这样，将整体处理时序数据的层以单词“Time”开头命名，这是本书中规定的命名规范。之后，我们还会实现 Time Affine 层、Time Embedding 层等。\n",
    "\n",
    "我们接下来进行的实现的流程是：首先，实现进行 RNN 单步处理的 RNN 类；然后，利用这个 RNN 类，完成一次进行 $T$ 步处理的 ``TimeRNN`` 类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfa0944",
   "metadata": {},
   "source": [
    "### RNN层的实现\n",
    "现在，我们来实现进行 RNN 单步处理的 RNN 类。首先复习一下 RNN 正向传播的数学式，如式 (5.10) 所示：\n",
    "\n",
    "$$\\boldsymbol{h}_t = \\tanh(\\boldsymbol{h}_{t - 1}\\boldsymbol{W}_h + \\boldsymbol{x}_t\\boldsymbol{W}_x + \\boldsymbol{b}) \\tag{5.10}$$\n",
    "\n",
    "这里，我们将数据整理为 mini-batch 进行处理。因此，$\\boldsymbol{x}_t$（和 $\\boldsymbol{h}_t$）在行方向上保存各样本数据。在矩阵计算中，矩阵的形状检查非常重要。这里，假设批大小是 $N$，输入向量的维数是 $D$，隐藏状态向量的维数是 $H$，则矩阵的形状检查可以像下面这样进行。\n",
    "\n",
    "<img src=\"./fig/matrix_check.png\" alt=\"matrix_check\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，通过矩阵的形状检查，可以确认它的实现是否正确，至少可以确认它的计算是否成立。基于以上内容，现在我们给出 RNN 类的初始化方法和正向传播的 `forward()` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7c5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]  # 输入权重，隐藏状态权重，偏置\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] \n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params \n",
    "        t = np.dot(x, Wx) + np.dot(h_prev, Wh) + b # 计算当前时刻的隐状态\n",
    "        t_next = np.tanh(t) # 激活函数\n",
    "\n",
    "        self.cache = (x, h_prev, t_next) # 缓存前向传播需要的变量\n",
    "        return t_next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30999957",
   "metadata": {},
   "source": [
    "RNN 的初始化方法接收两个权重参数和一个偏置参数。这里，将通过函数参数传进来的模型参数设置为列表类型的成员变量 `params`。然后，以各个参数对应的形状初始化梯度，并保存在 `grads` 中。最后，使用 `None` 对反向传播时要用到的中间数据 `cache` 进行初始化。\n",
    "\n",
    "正向传播的 `forward(x, h_prev)` 方法接收两个参数：从下方输入的 `x` 和从左边输入的 `h_prev`。剩下的就是按式 (5.10) 进行实现。顺便说一下，这里从前一个 RNN 层接收的输入是 `h_prev`，当前时刻的 RNN 层的输出（= 下一时刻的 RNN 层的输入）是 `h_next`。\n",
    "\n",
    "接下来，我们继续实现 RNN 的反向传播。在此之前，让我们通过下图的计算图再次确认一下 RNN 的正向传播。\n",
    "\n",
    "<img src=\"./fig/RNN_calculation.png\" alt=\"RNN_calculation\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "RNN 层的正向传播可由上图的计算图表示。这里进行的计算由矩阵乘积 “MatMul”、加法 “+” 和 “tanh” 这 3 种运算构成。此外，因为偏置 $\\boldsymbol{b}$ 的加法运算会触发广播操作，所以严格地讲，这里还应该加上 Repeat 节点。不过简单起见，这里省略了它。\n",
    "\n",
    "那么，上图的计算图的反向传播是什么样的呢？答案很简单。因为这 3 种运算的反向传播我们都已经掌握了（关于反向传播，请参考第一章内容），剩下就是基于下图，按正向传播的反方向实现各个运算的反向传播。\n",
    "\n",
    "<img src=\"./fig/RNN_backpropagation_calculation.png\" alt=\"RNN_backpropagation_calculation\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "下面实现 RNN 层的 ``backward()``。参考上图，可以如下实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df281318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dh_next):\n",
    "    Wx, Wh, b = self.params\n",
    "    x, h_prev, t_next = self.cache\n",
    "\n",
    "    dt = (1 - t_next ** 2) * dh_next # tanh的导数，维度为 (N, H)\n",
    "    db = np.sum(dt, axis=0) # 偏置梯度，维度为 (H,)\n",
    "    dWh = np.dot(h_prev.T, dt) # 隐状态权重梯度，维度为 (H, H)\n",
    "    dh_prev = np.dot(dt, Wh.T) # 上一时刻隐状态梯度，维度为 (N, H)\n",
    "    dWx = np.dot(x.T, dt) # 输入权重梯度，维度为 (D, H)\n",
    "    dx = np.dot(dt, Wx.T) # 输入数据梯度，维度为 (N, D)\n",
    "\n",
    "    self.grads[0][...] = dWx # 更新梯度\n",
    "    self.grads[1][...] = dWh # 更新梯度\n",
    "    self.grads[2][...] = db # 更新梯度\n",
    "\n",
    "    return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343bf24",
   "metadata": {},
   "source": [
    "## Time RNN层的实现\n",
    "Time RNN 层由 $T$ 个 RNN 层构成（$T$ 可以设置为任意值），如下图所示。\n",
    "\n",
    "<img src=\"./fig/time_RNN_vs_RNN.png\" alt=\"time_RNN_vs_RNN\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "由图可知，Time RNN 层是 $T$ 个 RNN 层连接起来的网络。我们将这个网络实现为 Time RNN 层。这里，RNN 层的隐藏状态 $\\boldsymbol{h}$ 保存在成员变量中。如下图所示，在进行隐藏状态的 “继承” 时会用到它。\n",
    "\n",
    "<img src=\"./fig/time_RNN_h.png\" alt=\"time_RNN_h\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，我们使用 Time RNN 层管理 RNN 层的隐藏状态。这样一来，使用 Time RNN 的人就不必考虑 RNN 层的隐藏状态的“继承工作”了。另外，我们可以用 `stateful` 这个参数来控制是否继承隐藏状态。\n",
    "\n",
    "下面，我们来看一下 Time RNN 层的实现。首先实现初始化方法和两个方法（`common/time_layers.py`）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f480fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False): # stateful表示是否保持状态\n",
    "        self.params = [Wx, Wh, b] # 输入权重，隐藏状态权重，偏置\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)] \n",
    "        self.layers = None # RNN层列表\n",
    "        self.h, self.dh = None, None # 隐状态和梯度\n",
    "        self.stateful = stateful # 是否保持状态\n",
    "\n",
    "    def set_state(self, h):\n",
    "        self.h = h # 设置隐状态\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h = None # 重置隐状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebd563",
   "metadata": {},
   "source": [
    "初始化方法的参数有权重、偏置和布尔型（True/False）的 `stateful`。一个成员变量 `layers` 在列表中保存多个 RNN 层，另一个成员变量 `h` 保存调用 `forward()` 方法时的最后一个 RNN 层的隐藏状态。另外，在调用 `backward()` 时，`dh` 保存传给前一个块的隐藏状态的梯度（关于 `dh`，我们会在反向传播的实现中说明）。\n",
    "\n",
    "考虑到 TimeRNN 类的扩展性，将设定 Time RNN 层的隐藏状态的方法实现为 <code>set_state(h)</code>。另外，将重置隐藏状态的方法实现为 <code>reset_state()</code>。\n",
    "\n",
    "上述参数中的 `stateful` 是“有状态”的意思。在本书的实现中，当 `stateful` 为 `True` 时，Time RNN 层“有状态”。这里说的“有状态”是指维持 Time RNN 层的隐藏状态。也就是说，无论时序数据多长，Time RNN 层的正向传播都可以不中断地进行。而当 `stateful` 为 `False` 时，每次调用 Time RNN 层的 `forward()` 时，第一个 RNN 层的隐藏状态都会被初始化为零矩阵（所有元素均为 0 的矩阵）。这是没有状态的模式，称为“无状态”。\n",
    "\n",
    "在处理长时序数据时，需要维持 RNN 的隐藏状态，这一功能通常用“stateful”一词表示。在许多深度学习框架中，RNN 层都有 stateful 参数，该参数用于指定是否保存上一时刻的隐藏状态。\n",
    "\n",
    "接着，我们来看一下正向传播的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ae3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, xs):\n",
    "    Wx, Wh, b = self.params\n",
    "    N, T, D = xs.shape # 输入数据的形状 (批量大小，时间步数，输入维度)\n",
    "    H = Wh.shape[0] # 隐状态维度\n",
    "\n",
    "    self.layers = [] # 初始化RNN层列表\n",
    "    hs = np.empty((N, T, H), dtype='f') # 初始化输出隐藏状态\n",
    "\n",
    "    if not self.stateful or self.h is None:\n",
    "        self.h = np.zeros((N, H), dtype='f') # 初始化隐状态\n",
    "\n",
    "    for t in range(T):\n",
    "        layer = RNN(*self.params) # 创建RNN层，传入权重和偏置\n",
    "        self.h = layer.forward(xs[:, t, :], self.h) # 前向传播\n",
    "        hs[:, t, :] = self.h # 保存当前时刻的隐状态\n",
    "        self.layers.append(layer) # 保存RNN层\n",
    "\n",
    "    return hs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d39ad8",
   "metadata": {},
   "source": [
    "正向传播的 `forward(xs)` 方法从下方获取输入 `xs`，`xs` 囊括了 $T$ 个时序数据。因此，如果批大小是 $N$，输入向量的维数是 $D$，则 `xs` 的形状为 $(N, T, D)$。\n",
    "\n",
    "在首次调用时（`self.h` 为 `None` 时），RNN 层的隐藏状态 $\\boldsymbol{h}$ 由所有元素均为 0 的矩阵初始化。另外，在成员变量 `stateful` 为 `False` 的情况下，$\\boldsymbol{h}$ 将总是被重置为零矩阵。\n",
    "\n",
    "在主体实现中，首先通过 `hs=np.empty((N, T, H), dtype='f')` 为输出准备一个“容器”。接着，在 $T$ 次 `for` 循环中，生成 RNN 层，并将其添加到成员变量 `layers` 中。然后，计算 RNN 层各个时刻的隐藏状态，并存放在 `hs` 的对应索引（时刻）中。\n",
    "\n",
    "如果调用 Time RNN 层的 <code>forward()</code> 方法，则成员变量 <code>h</code> 中将存放最后一个 RNN 层的隐藏状态。在 <code>stateful</code> 为 <code>True</code> 的情况下，在下一次调用 <code>forward()</code> 方法时，刚才的成员变量 <code>h</code> 将被继续使用。而在 <code>stateful</code> 为 <code>False</code> 的情况下，成员变量 <code>h</code> 将被重置为零向量。\n",
    "\n",
    "接下来是 Time RNN 层的反向传播的实现。用计算图绘制这个反向传播，如下图所示。\n",
    "\n",
    "<img src=\"./fig/time_RNN_backpropagation.png\" alt=\"time_RNN_backpropagation\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "在图中，将从上游（输出侧的层）传来的梯度记为 $\\boldsymbol{dh}s$，将流向下游的梯度记为 $\\boldsymbol{dx}s$。因为这里我们进行的是 Truncated BPTT，所以不需要流向这个块上一时刻的反向传播。不过，我们将流向上一时刻的隐藏状态的梯度存放在成员变量 $\\boldsymbol{dh}$ 中。这是因为在第 7 章探讨 seq2seq（sequence-to-sequence，序列到序列）时会用到它（具体请参考第 7 章）。\n",
    "\n",
    "以上就是 Time RNN 层的反向传播的全貌图。如果关注第 $t$ 个 RNN 层，则它的反向传播如图所示。\n",
    "\n",
    "<img src=\"./fig/RNN_propagation_t.png\" alt=\"RNN_propagation_t\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "从上方传来的梯度 $\\boldsymbol{dh}_t$ 和从将来的层传来的梯度 $\\boldsymbol{dh}_{\\text{next}}$ 会传到第 $t$ 个 RNN 层。这里需要注意的是，RNN 层的正向传播的输出有两个分叉。在正向传播存在分叉的情况下，在反向传播时各梯度将被求和。因此，在反向传播时，流向 RNN 层的是求和后的梯度。考虑到以上这些，反向传播的实现如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710d3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, dhs):\n",
    "    Wx, Wh, b = self.params \n",
    "    N, T, H = dhs.shape # 输出隐藏状态的形状 (批量大小，时间步数，隐状态维度)\n",
    "    D = Wx.shape[0] # 输入维度\n",
    "\n",
    "    dxs = np.empty((N, T, D), dtype='f') # 初始化输入数据梯度\n",
    "    dh = 0 # 初始化隐状态梯度\n",
    "    grads = [0, 0, 0] # 初始化权重和偏置梯度\n",
    "\n",
    "    for t in reversed(range(T)):\n",
    "        layer = self.layers[t] # 获取当前时刻的RNN层\n",
    "        dx, dh = layer.backward(dhs[:, t, :] + dh) # 反向传播，累积隐状态梯度\n",
    "        dxs[:, t, :] = dx # 保存输入数据梯度\n",
    "\n",
    "        for i, grad in enumerate(layer.grads):\n",
    "            grads[i] += grad # 累积权重和偏置梯度\n",
    "\n",
    "    for i, grad in enumerate(grads):\n",
    "        self.grads[i][...] = grad # 更新梯度\n",
    "    self.dh = dh # 保存隐状态梯度\n",
    "\n",
    "    return dxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13db79cb",
   "metadata": {},
   "source": [
    "这里，首先创建传给下游的梯度的“容器”（`dxs`）。接着，按与正向传播相反的方向，调用 RNN 层的 `backward()` 方法，求得各个时刻的梯度 `dx`，并存放在 `dxs` 的对应索引处。另外，关于权重参数，需要求各个 RNN 层的权重梯度的和，并通过“`...`”用最终结果覆盖成员变量 `self.grads`。\n",
    "\n",
    "在 Time RNN 层中有多个 RNN 层。另外，这些 RNN 层使用相同的权重。因此，Time RNN 层的（最终）权重梯度是各个 RNN 层的权重梯度之和。\n",
    "\n",
    "以上就是对 Time RNN 层的实现的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31cbb97",
   "metadata": {},
   "source": [
    "## 处理时序数据的层的实现\n",
    "本章我们的目标是使用 RNN 实现语言模型。目前我们已经实现了 RNN 层和整体处理时序数据的 Time RNN 层，本节将创建几个可以处理时序数据的新层。我们将基于 RNN 的语言模型称为 RNNLM（RNN Language Model，RNN 语言模型）。现在，我们来完成 RNNLM。\n",
    "\n",
    "## RNNLM的全貌图\n",
    "首先，我们看一下 RNNLM 使用的网络。下图所示为最简单的 RNNLM 的网络，其中左图显示了 RNNLM 的层结构，右图显示了在时间轴上展开后的网络。\n",
    "\n",
    "<img src=\"./fig/RNNLM_network.png\" alt=\"RNNLM_network\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "图中的第 1 层是 Embedding 层，该层将单词 ID 转化为单词的分布式表示（单词向量）。然后，这个单词向量被输入到 RNN 层。RNN 层向下一层（上方）输出隐藏状态，同时也向下一时刻的 RNN 层（右侧）输出隐藏状态。RNN 层向上方输出的隐藏状态经过 Affine 层，传给 Softmax 层。\n",
    "\n",
    "现在，我们仅考虑正向传播，向上图的神经网络传入具体的数据，并观察输出结果。这里使用的句子还是我们熟悉的 “you say goodbye and i say hello.”，此时 RNNLM 进行的处理如下图所示。\n",
    "\n",
    "<img src=\"./fig/RNNLM_example.png\" alt=\"RNNLM_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，被输入的数据是单词 ID 列表。首先，我们关注第 1 个时刻。作为第 1 个单词，单词 ID 为 0 的 you 被输入。此时，查看 Softmax 层输出的概率分布，可知 say 的概率最高，这表明正确预测出了 you 后面出现的单词为 say。当然，这样的正确预测只在有“好的”（学习顺利的）权重时才会发生。\n",
    "\n",
    "接着，我们关注第 2 个单词 say。此时，Softmax 层的输出在 goodbye 处和 hello 处概率较高。确实，“you say goodby”和“you say hello”都是很自然的句子（顺便说一下，正确答案是 goodbye）。这里需要注意的是，RNN 层“记忆”了“you say”这一上下文。更准确地说，RNN 将“you say”这一过去的信息保存为了简短的隐藏状态向量。RNN 层的工作是将这个信息传送到上方的 Affine 层和下一时刻的 RNN 层。\n",
    "\n",
    "像这样，RNNLM 可以“记忆”目前为止输入的单词，并以此为基础预测接下来会出现的单词。RNN 层通过从过去到现在继承并传递数据，使得编码和存储过去的信息成为可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39752598",
   "metadata": {},
   "source": [
    "## Time层的实现\n",
    "之前我们将整体处理时序数据的层实现为了 Time RNN 层，这里也同样使用 Time Embedding 层、Time Affine 层等来实现整体处理时序数据的层。一旦创建了这些 Time ××层，我们的目标神经网络就可以像下图这样实现。\n",
    "\n",
    "<img src=\"./fig/timexx.png\" alt=\"timexx\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "我们将整体处理含有$T$个时序数据的层称为 “Time ××层”。如果可以实现这些层，通过像组装乐高积木一样组装它们，就可以完成处理时序数据的网络。\n",
    "\n",
    "Time 层的实现很简单。比如，在 Time Affine 层的情况下，只需要像下图那样，准备 $T$ 个 Affine 层分别处理各个时刻的数据即可。\n",
    "\n",
    "<img src=\"./fig/time_Affine.png\" alt=\"time_Affine\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "Time Embedding 层也一样，在正向传播时准备 $T$ 个 Embedding 层，由各个 Embedding 层处理各个时刻的数据。\n",
    "\n",
    "关于 Time Affine 层和 Time Embedding 层没有什么特别难的内容，我们就不再赘述了。需要注意的是，Time Affine 层并不是单纯地使用 $T$ 个 Affine 层，而是使用矩阵运算实现了高效的整体处理。感兴趣的读者可以参考源代码（`common/time_layers.py` 的 `TimeAffine` 类）。接下来我们看一下时序版本的 Softmax。\n",
    "\n",
    "我们在 Softmax 中一并实现损失误差 Cross Entropy Error 层。这里，按照下图所示的网络结构实现 Time Softmax with Loss 层。\n",
    "\n",
    "<img src=\"./fig/time_softmax_with_loss.png\" alt=\"time_softmax_with_loss\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "图中的 $\\boldsymbol{x}_0$、$\\boldsymbol{x}_1$ 等数据表示从下方的层传来的得分（得分是正规化为概率之前的值），$t_0$、$t_1$ 等数据表示正确解标签。如该图所示，$T$ 个 Softmax with Loss 层各自算出损失，然后将它们加在一起取平均，将得到的值作为最终的损失。此处进行的计算可用下式表示：\n",
    "\n",
    "$$ L = \\frac{1}{T}(L_0 + L_1 + \\cdots + L_{T - 1}) \\tag{5.11} $$\n",
    "\n",
    "顺便说一下，本书的 Softmax with Loss 层计算 mini-batch 的平均损失。具体而言，假设 mini-batch 有 $N$ 笔数据，通过先求 $N$ 笔数据的损失之和，再除以 $N$，可以得到单笔数据的平均损失。这里也一样，通过取时序数据的平均，可以求得单笔数据的平均损失作为最终的输出。\n",
    "\n",
    "以上就是对 Time 层的说明。这里只是做了一个简短的说明，实际的实现可以在 `common/time_layers.py` 中找到，感兴趣的读者可以参考一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b563d8",
   "metadata": {},
   "source": [
    "##  RNNLM的学习和评价\n",
    "实现 RNNLM 所需要的层都已经准备好了，现在我们来实现 RNNLM，并对其进行训练，然后再评价一下它的结果。\n",
    "\n",
    "### RNNLM的实现\n",
    "这里我们将 RNNLM 使用的网络实现为 `SimpleRnnlm` 类，其层结构如下图所示。\n",
    "\n",
    "<img src=\"./fig/simple_RNNLM.png\" alt=\"simple_RNNLM\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，SimpleRnnlm 类是一个堆叠了 4 个 Time 层的神经网络。我们先来看一下初始化的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918225be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入父目录的模块\n",
    "import numpy as np\n",
    "from common.time_layers import * \n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词汇表大小，词向量维度，隐藏状态维度\n",
    "        rn = np.random.randn # 标准正态分布随机数生成函数\n",
    "\n",
    "        # 初始化权重\n",
    "        embed_W = (rn(V, D) / 100).astype('f') # 词嵌入层权重\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f') # RNN层输入权重\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f') # RNN层隐藏状态权重\n",
    "        rnn_b = np.zeros(H).astype('f') # RNN层偏置\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f') # 全连接层权重\n",
    "        affine_b = np.zeros(V).astype('f') # 全连接层偏置\n",
    "\n",
    "        # 生成层\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W), # 词嵌入层\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True), # RNN层，保持状态\n",
    "            TimeAffine(affine_W, affine_b) # 全连接层\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss() # 损失层\n",
    "        self.rnn_layer = self.layers[1] # RNN层，便于访问\n",
    "\n",
    "        # 将所有的权重和梯度整理到列表中\n",
    "        self.params, self.grads = [], [] # 初始化参数和梯度列表\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params # 添加层的参数\n",
    "            self.grads += layer.grads # 添加层的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c450c9",
   "metadata": {},
   "source": [
    "这里，对各个层使用的参数（权重和偏置）进行初始化，生成必要的层。假设使用 Truncated BPTT 进行学习，将 Time RNN 层的 `stateful` 设置为 `True`，如此 Time RNN 层就可以继承上一时刻的隐藏状态。\n",
    "\n",
    "另外，在上面的初始化代码中，RNN 层和 Affine 层使用了 “Xavier 初始值”。如下图所示，在上一层的节点数是 $n$ 的情况下，使用标准差为 $\\frac{1}{\\sqrt{n}}$ 的分布作为 Xavier 初始值 。顺便说一下，标准差可以直观地解释为表示数据分散程度的指标。\n",
    "\n",
    "<img src=\"./fig/Xavier.png\" alt=\"Xavier\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "在深度学习中，权重的初始值非常重要。关于这一点，我们在前作《深度学习入门：基于Python的理论与实现》中已经进行了详细的探讨。同样，对RNN而言，权重的初始值也很重要。通过设置好的初始值，学习的进展和最终的精度都会有很大变化。本书此后都将使用Xavier初始值作为权重的初始值。另外，在语言模型的相关研究中，经常使用<code>0.01 * np.random.uniform(...)</code>这样的经过缩放的均匀分布。\n",
    "\n",
    "接着，我们来实现 `forward()` 方法、`backward()` 方法和 `reset_state()` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e127c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, xs, ts):\n",
    "    for layer in self.layers: # 遍历所有层\n",
    "        xs = layer.forward(xs) # 依次通过各个层进行前向传播\n",
    "    loss = self.loss_layer.forward(xs, ts) # 计算损失\n",
    "    return loss\n",
    "\n",
    "def backward(self, dout=1):\n",
    "    dout = self.loss_layer.backward(dout) # 反向传播通过损失层\n",
    "\n",
    "    for layer in reversed(self.layers): # 反向遍历层\n",
    "        dout = layer.backward(dout) # 依次通过各个层进行反向传播\n",
    "\n",
    "    return dout\n",
    "\n",
    "def reset_state(self):\n",
    "    self.rnn_layer.reset_state() # 重置RNN层的状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0abb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入父目录的模块\n",
    "import numpy as np\n",
    "from common.time_layers import * \n",
    "\n",
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词汇表大小，词向量维度，隐藏状态维度\n",
    "        rn = np.random.randn # 标准正态分布随机数生成函数\n",
    "\n",
    "        # 初始化权重\n",
    "        embed_W = (rn(V, D) / 100).astype('f') # 词嵌入层权重\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f') # RNN层输入权重\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f') # RNN层隐藏状态权重\n",
    "        rnn_b = np.zeros(H).astype('f') # RNN层偏置\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f') # 全连接层权重\n",
    "        affine_b = np.zeros(V).astype('f') # 全连接层偏置\n",
    "\n",
    "        # 生成层\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W), # 词嵌入层\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True), # RNN层，保持状态\n",
    "            TimeAffine(affine_W, affine_b) # 全连接层\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss() # 损失层\n",
    "        self.rnn_layer = self.layers[1] # RNN层，便于访问\n",
    "\n",
    "        # 将所有的权重和梯度整理到列表中\n",
    "        self.params, self.grads = [], [] # 初始化参数和梯度列表\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params # 添加层的参数\n",
    "            self.grads += layer.grads # 添加层的梯度\n",
    "\n",
    "def forward(self, xs, ts):\n",
    "    for layer in self.layers: # 遍历所有层\n",
    "        xs = layer.forward(xs) # 依次通过各个层进行前向传播\n",
    "    loss = self.loss_layer.forward(xs, ts) # 计算损失\n",
    "    return loss\n",
    "\n",
    "def backward(self, dout=1):\n",
    "    dout = self.loss_layer.backward(dout) # 反向传播通过损失层\n",
    "\n",
    "    for layer in reversed(self.layers): # 反向遍历层\n",
    "        dout = layer.backward(dout) # 依次通过各个层进行反向传播\n",
    "\n",
    "    return dout\n",
    "\n",
    "def reset_state(self):\n",
    "    self.rnn_layer.reset_state() # 重置RNN层的状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda710a1",
   "metadata": {},
   "source": [
    "可以看出实现非常简单。在各个层中，正向传播和反向传播都正确地进行了实现。因此，我们只要以正确的顺序调用 `forward()`（或者 `backward()`）即可。方便起见，这里将重设网络状态的方法实现为 `reset_state()`。以上就是对 `SimpleRnnlm` 类的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a731ac75",
   "metadata": {},
   "source": [
    "## 语言模型的评价\n",
    "`SimpleRnnlm` 的实现结束了，接下来要做的就是向这个网络输入数据进行学习。在实现用于学习的代码之前，我们先来讨论一下语言模型的评价方法。\n",
    "\n",
    "语言模型基于给定的已经出现的单词（信息）输出将要出现的单词的概率分布。困惑度（perplexity）常被用作评价语言模型的预测性能的指标。\n",
    "\n",
    "简单地说，困惑度表示“概率的倒数”（这个解释在数据量为 1 时严格一致）。为了说明概率的倒数，我们仍旧考虑 “you say goodbye and i say hello.” 这一语料库。假设在向语言模型“模型 1”传入单词 you 时会输出左图所示的概率分布。此时，下一个出现的单词是 say 的概率为 0.8，这是一个相当不错的预测。取这个概率的倒数，可以计算出困惑度为 $\\frac{1}{0.8} = 1.25$。\n",
    "\n",
    "<img src=\"./fig/possibility_predict.png\" alt=\"possibility_predict\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "而图右侧的模型（“模型 2”）预测出的正确单词的概率为 0.2，这显然是一个很差的预测，此时的困惑度为 $\\frac{1}{0.2} = 5$。\n",
    "\n",
    "总结一下，“模型 1”能准确地预测，困惑度是 1.25；“模型 2”的预测未能命中，困惑度是 5.0。此例表明，困惑度越小越好。\n",
    "\n",
    "那么，如何直观地解释值 1.25 和 5.0 呢？它们可以解释为“分叉度”。所谓分叉度，是指下一个可以选择的选项的数量（下一个可能出现的单词的候选个数）。在刚才的例子中，好的预测模型的分叉度是 1.25，这意味着下一个要出现的单词的候选个数可以控制在 1 个左右。而在差的模型中，下一个单词的候选个数有 5 个。\n",
    "\n",
    "如上面的例子所示，基于困惑度可以评价模型的预测性能。好的模型可以高概率地预测出正确单词，所以困惑度较小（困惑度的最小值是 1.0）；而差的模型只能低概率地预测出正确单词，困惑度较大。\n",
    "\n",
    "以上都是输入数据为 1 个时的困惑度。那么，在输入数据为多个的情况下，结果会怎样呢？我们可以根据下面的式子进行计算。\n",
    "\n",
    "$$ L = -\\frac{1}{N} \\sum_n \\sum_k t_{nk} \\log y_{nk} \\tag{5.12} $$\n",
    "\n",
    "$$ \\text{困惑度} = \\mathrm{e}^L \\tag{5.13} $$\n",
    "\n",
    "这里，假设数据量为 $N$ 个。$\\boldsymbol{t}_n$ 是 one-hot 向量形式的正确解标签，$t_{nk}$ 表示第 $n$ 个数据的第 $k$ 个值，$y_{nk}$ 表示概率分布（神经网络中的 Softmax 的输出）。顺便说一下，$L$ 是神经网络的损失，和式 (1.8) 完全相同，使用这个 $L$ 计算出的 $\\mathrm{e}^L$ 就是困惑度。\n",
    "\n",
    "式子 (5.12) 看上去有些复杂，但是前面我们介绍的数据量为 1 时的“概率的倒数”“分叉度”“候选个数”等在这里也通用。也就是说，困惑度越小，分叉度越小，表明模型越好。\n",
    "\n",
    "在信息论领域，困惑度也称为“平均分叉度”。这可以解释为，数据量为1时的分叉度是数据量为$N$时的分叉度的平均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be998fc",
   "metadata": {},
   "source": [
    "## RNNLM的学习代码\n",
    "下面，我们使用 PTB 数据集进行学习，不过这里仅使用 PTB 数据集（训练数据）的前 1000 个单词。这是因为在本节实现的 RNNLM 中，即便使用所有的训练数据，也得不出好的结果。下一章我们将对它进行改进。下面我们先来看一下学习用的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ade6d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语料库大小：1000，词汇表大小：418\n",
      "| 轮次 1 | 困惑度 334.65\n",
      "| 轮次 2 | 困惑度 231.92\n",
      "| 轮次 3 | 困惑度 215.17\n",
      "| 轮次 4 | 困惑度 211.16\n",
      "| 轮次 5 | 困惑度 203.60\n",
      "| 轮次 6 | 困惑度 201.05\n",
      "| 轮次 7 | 困惑度 197.49\n",
      "| 轮次 8 | 困惑度 196.39\n",
      "| 轮次 9 | 困惑度 191.72\n",
      "| 轮次 10 | 困惑度 192.48\n",
      "| 轮次 11 | 困惑度 189.48\n",
      "| 轮次 12 | 困惑度 192.99\n",
      "| 轮次 13 | 困惑度 190.94\n",
      "| 轮次 14 | 困惑度 191.83\n",
      "| 轮次 15 | 困惑度 190.77\n",
      "| 轮次 16 | 困惑度 186.76\n",
      "| 轮次 17 | 困惑度 184.55\n",
      "| 轮次 18 | 困惑度 182.32\n",
      "| 轮次 19 | 困惑度 183.47\n",
      "| 轮次 20 | 困惑度 184.34\n",
      "| 轮次 21 | 困惑度 182.32\n",
      "| 轮次 22 | 困惑度 178.13\n",
      "| 轮次 23 | 困惑度 175.42\n",
      "| 轮次 24 | 困惑度 176.84\n",
      "| 轮次 25 | 困惑度 173.87\n",
      "| 轮次 26 | 困惑度 174.21\n",
      "| 轮次 27 | 困惑度 169.15\n",
      "| 轮次 28 | 困惑度 167.00\n",
      "| 轮次 29 | 困惑度 163.91\n",
      "| 轮次 30 | 困惑度 157.61\n",
      "| 轮次 31 | 困惑度 158.16\n",
      "| 轮次 32 | 困惑度 153.41\n",
      "| 轮次 33 | 困惑度 152.88\n",
      "| 轮次 34 | 困惑度 147.88\n",
      "| 轮次 35 | 困惑度 146.14\n",
      "| 轮次 36 | 困惑度 140.22\n",
      "| 轮次 37 | 困惑度 135.13\n",
      "| 轮次 38 | 困惑度 132.53\n",
      "| 轮次 39 | 困惑度 126.91\n",
      "| 轮次 40 | 困惑度 123.46\n",
      "| 轮次 41 | 困惑度 121.59\n",
      "| 轮次 42 | 困惑度 114.38\n",
      "| 轮次 43 | 困惑度 109.78\n",
      "| 轮次 44 | 困惑度 105.49\n",
      "| 轮次 45 | 困惑度 103.38\n",
      "| 轮次 46 | 困惑度 99.90\n",
      "| 轮次 47 | 困惑度 95.44\n",
      "| 轮次 48 | 困惑度 89.85\n",
      "| 轮次 49 | 困惑度 86.55\n",
      "| 轮次 50 | 困惑度 83.67\n",
      "| 轮次 51 | 困惑度 80.21\n",
      "| 轮次 52 | 困惑度 76.41\n",
      "| 轮次 53 | 困惑度 72.14\n",
      "| 轮次 54 | 困惑度 69.99\n",
      "| 轮次 55 | 困惑度 66.88\n",
      "| 轮次 56 | 困惑度 61.05\n",
      "| 轮次 57 | 困惑度 57.91\n",
      "| 轮次 58 | 困惑度 55.76\n",
      "| 轮次 59 | 困惑度 52.29\n",
      "| 轮次 60 | 困惑度 48.16\n",
      "| 轮次 61 | 困惑度 45.59\n",
      "| 轮次 62 | 困惑度 43.32\n",
      "| 轮次 63 | 困惑度 41.49\n",
      "| 轮次 64 | 困惑度 39.46\n",
      "| 轮次 65 | 困惑度 37.85\n",
      "| 轮次 66 | 困惑度 35.77\n",
      "| 轮次 67 | 困惑度 34.53\n",
      "| 轮次 68 | 困惑度 31.27\n",
      "| 轮次 69 | 困惑度 30.98\n",
      "| 轮次 70 | 困惑度 28.40\n",
      "| 轮次 71 | 困惑度 27.05\n",
      "| 轮次 72 | 困惑度 24.98\n",
      "| 轮次 73 | 困惑度 24.38\n",
      "| 轮次 74 | 困惑度 23.33\n",
      "| 轮次 75 | 困惑度 22.02\n",
      "| 轮次 76 | 困惑度 20.27\n",
      "| 轮次 77 | 困惑度 19.31\n",
      "| 轮次 78 | 困惑度 18.26\n",
      "| 轮次 79 | 困惑度 16.69\n",
      "| 轮次 80 | 困惑度 15.89\n",
      "| 轮次 81 | 困惑度 15.20\n",
      "| 轮次 82 | 困惑度 14.81\n",
      "| 轮次 83 | 困惑度 13.76\n",
      "| 轮次 84 | 困惑度 13.12\n",
      "| 轮次 85 | 困惑度 12.36\n",
      "| 轮次 86 | 困惑度 12.05\n",
      "| 轮次 87 | 困惑度 11.52\n",
      "| 轮次 88 | 困惑度 10.67\n",
      "| 轮次 89 | 困惑度 9.92\n",
      "| 轮次 90 | 困惑度 10.14\n",
      "| 轮次 91 | 困惑度 9.38\n",
      "| 轮次 92 | 困惑度 8.92\n",
      "| 轮次 93 | 困惑度 8.50\n",
      "| 轮次 94 | 困惑度 8.42\n",
      "| 轮次 95 | 困惑度 7.60\n",
      "| 轮次 96 | 困惑度 6.92\n",
      "| 轮次 97 | 困惑度 6.92\n",
      "| 轮次 98 | 困惑度 6.47\n",
      "| 轮次 99 | 困惑度 6.22\n",
      "| 轮次 100 | 困惑度 6.16\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入父目录的模块\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 设定超参数\n",
    "batch_size = 10 # 批量大小\n",
    "wordvec_size = 100 # 词向量维度\n",
    "hidden_size = 100 # 隐藏层维度\n",
    "time_size = 5  # Truncated BPTT的时间跨度大小\n",
    "lr = 0.1 # 学习率\n",
    "max_epoch = 100 # 最大迭代轮数\n",
    "\n",
    "# 读入训练数据（缩小了数据集）\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000 # 仅使用1000个字符\n",
    "corpus = corpus[:corpus_size] # 仅使用前1000个字符\n",
    "vocab_size = int(max(corpus) + 1) # 词汇表大小\n",
    "\n",
    "xs = corpus[:-1]  # 输入\n",
    "ts = corpus[1:]  # 输出（监督标签）\n",
    "data_size = len(xs) # 数据大小\n",
    "print('语料库大小：%d，词汇表大小：%d' % (corpus_size, vocab_size))\n",
    "\n",
    "# 学习用的参数\n",
    "max_iters = data_size // (batch_size * time_size) # 每轮的迭代次数\n",
    "time_idx = 0 # 时间索引\n",
    "total_loss = 0 # 总损失\n",
    "loss_count = 0 # 损失计数\n",
    "ppl_list = [] # 困惑度列表\n",
    "\n",
    "# 生成模型\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size) # 生成RNN语言模型\n",
    "optimizer = SGD(lr) # 优化器\n",
    "\n",
    "# step1：计算读入mini-batch的各笔样本数据的开始位置\n",
    "jump = (corpus_size - 1) // batch_size # 每笔样本数据的间隔\n",
    "offsets = [i * jump for i in range(batch_size)] # 各笔样本数据的开始位置列表，offsets的长度为batch_size\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        # step2：获取mini-batch\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i') # 初始化输入数据，维度为 (批量大小，时间步数)，(N, T)\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i') # 初始化监督标签，维度为 (批量大小，时间步数)，(N, T)\n",
    "\n",
    "        # 通过时间索引和开始位置，获取mini-batch\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size] # 填入输入数据，维度为 (N, T)，% data_size是为了循环取数据\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size] # 填入监督标签，维度为 (N, T)，% data_size是为了循环取数据\n",
    "            time_idx += 1\n",
    "\n",
    "        # 计算梯度，更新参数\n",
    "        loss = model.forward(batch_x, batch_t) # 前向传播计算损失\n",
    "        model.backward() # 反向传播计算梯度\n",
    "        optimizer.update(model.params, model.grads) # 更新参数\n",
    "        total_loss += loss # 累积损失\n",
    "        loss_count += 1 # 累积损失计数\n",
    "\n",
    "    # step3：各个epoch的困惑度评价\n",
    "    ppl = np.exp(total_loss / loss_count) # 计算困惑度\n",
    "    print('| 轮次 %d | 困惑度 %.2f' % (epoch + 1, ppl)) # 输出当前轮次和困惑度\n",
    "    ppl_list.append(float(ppl)) # 记录困惑度\n",
    "    total_loss, loss_count = 0, 0 # 重置损失和计数\n",
    "\n",
    "# 绘制图形\n",
    "x = np.arange(len(ppl_list))\n",
    "plt.plot(x, ppl_list, label='train')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907587c",
   "metadata": {},
   "source": [
    "以上就是学习用的代码，这和我们之前看到的神经网络的学习基本上是一样的。不过，从宏观上看，仍有两点和之前的学习代码不同，即“数据的输入方式”和“困惑度的计算”。这里，我们将重点关注这两点，并对代码进行说明。\n",
    "\n",
    "首先是数据的输入方式。这里我们使用 Truncated BPTT 进行学习，因此数据需要按顺序输入，并且 mini-batch 的各批次要平移读入数据的开始位置。在代码step1处，计算各批次读入数据的开始位置 `offsets`。`offsets` 的各个元素中存放了读入数据的开始位置（偏移量）。\n",
    "\n",
    "接着，在代码step2处，按顺序读入数据。首先准备容器 `batch_x` 和 `batch_t`，然后依次增加 `time_idx` 变量，将 `time_idx` 处的数据从语料库中取出。这里利用step1中计算好的 `offsets`，各批次增加偏移量。另外，当读入语料库的位置超过语料库大小时，为了回到语料库的开头处，将当前位置除以语料库大小后的余数作为索引使用。\n",
    "\n",
    "最后，基于式 (5.12) 计算困惑度，这在代码step3处完成。为了求每个 epoch 的困惑度，需要计算每个 epoch 的平均损失，然后再据此求困惑度。\n",
    "\n",
    "以上就是对代码的说明，现在我们看一下学习结果。在上面的代码中，各个 epoch 的困惑度的结果都保存在了 `perplexity_list` 中，我们可以将它绘制出来，如下图 所示。\n",
    "\n",
    "<img src=\"./fig/perplexity.png\" alt=\"perplexity\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "由图可知，随着学习的进行，困惑度稳步下降。一开始超过 300 的困惑度到最后接近 1（最小值）了。不过这里使用的是很小的语料库，在实际情况下，当语料库增大时，现在的模型根本无法招架。下一章我们将指出当前 RNNLM 存在的问题，并进行改进。\n",
    "\n",
    "## RNNLM的Trainer类\n",
    "本书提供了用于学习 RNNLM 的 `RnnlmTrainer` 类，其内部封装了刚才的 RNNLM 的学习。将刚才的学习代码重构为 `RnnlmTrainer` 类，结果如下。这里只摘录源代码的一部分。\n",
    "\n",
    "```python\n",
    "from common.trainer import RnnlmTrainer\n",
    "\n",
    "# ...\n",
    "\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "```\n",
    "\n",
    "如上所示，首先使用 `model` 和 `optimizer` 初始化 `RnnlmTrainer` 类，然后调用 `fit()`，完成学习。此时，`RnnlmTrainer` 类的内部将执行上一节进行的一系列操作，具体如下所示。\n",
    "\n",
    "- 按顺序生成 mini-batch\n",
    "- 调用模型的正向传播和反向传播\n",
    "- 使用优化器更新权重\n",
    "- 评价困惑度\n",
    "\n",
    "<code>RnnlmTrainer</code>类与之前章节中介绍的<code>Trainer</code>类有相同的API。神经网络的常规学习使用<code>Trainer</code>类，而RNNLM的学习则使用<code>RnnlmTrainer</code>类。\n",
    "\n",
    "使用 `RnnlmTrainer` 类，可以避免每次写重复的代码。本书的剩余部分都将使用 `RnnlmTrainer` 类学习 RNNLM。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f41c4360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 19 | time 0[s] | perplexity 419.12\n",
      "| epoch 2 |  iter 1 / 19 | time 0[s] | perplexity 357.79\n",
      "| epoch 3 |  iter 1 / 19 | time 0[s] | perplexity 248.00\n",
      "| epoch 4 |  iter 1 / 19 | time 0[s] | perplexity 215.52\n",
      "| epoch 5 |  iter 1 / 19 | time 0[s] | perplexity 205.46\n",
      "| epoch 6 |  iter 1 / 19 | time 0[s] | perplexity 205.19\n",
      "| epoch 7 |  iter 1 / 19 | time 0[s] | perplexity 199.03\n",
      "| epoch 8 |  iter 1 / 19 | time 0[s] | perplexity 200.30\n",
      "| epoch 9 |  iter 1 / 19 | time 0[s] | perplexity 194.26\n",
      "| epoch 10 |  iter 1 / 19 | time 0[s] | perplexity 189.34\n",
      "| epoch 11 |  iter 1 / 19 | time 0[s] | perplexity 191.91\n",
      "| epoch 12 |  iter 1 / 19 | time 0[s] | perplexity 189.27\n",
      "| epoch 13 |  iter 1 / 19 | time 0[s] | perplexity 192.02\n",
      "| epoch 14 |  iter 1 / 19 | time 0[s] | perplexity 187.74\n",
      "| epoch 15 |  iter 1 / 19 | time 0[s] | perplexity 187.17\n",
      "| epoch 16 |  iter 1 / 19 | time 0[s] | perplexity 191.23\n",
      "| epoch 17 |  iter 1 / 19 | time 0[s] | perplexity 188.80\n",
      "| epoch 18 |  iter 1 / 19 | time 0[s] | perplexity 184.65\n",
      "| epoch 19 |  iter 1 / 19 | time 0[s] | perplexity 181.64\n",
      "| epoch 20 |  iter 1 / 19 | time 0[s] | perplexity 182.01\n",
      "| epoch 21 |  iter 1 / 19 | time 0[s] | perplexity 178.73\n",
      "| epoch 22 |  iter 1 / 19 | time 0[s] | perplexity 179.14\n",
      "| epoch 23 |  iter 1 / 19 | time 0[s] | perplexity 182.55\n",
      "| epoch 24 |  iter 1 / 19 | time 0[s] | perplexity 179.29\n",
      "| epoch 25 |  iter 1 / 19 | time 0[s] | perplexity 170.00\n",
      "| epoch 26 |  iter 1 / 19 | time 0[s] | perplexity 176.41\n",
      "| epoch 27 |  iter 1 / 19 | time 0[s] | perplexity 171.77\n",
      "| epoch 28 |  iter 1 / 19 | time 0[s] | perplexity 172.76\n",
      "| epoch 29 |  iter 1 / 19 | time 0[s] | perplexity 167.21\n",
      "| epoch 30 |  iter 1 / 19 | time 0[s] | perplexity 167.47\n",
      "| epoch 31 |  iter 1 / 19 | time 0[s] | perplexity 162.34\n",
      "| epoch 32 |  iter 1 / 19 | time 0[s] | perplexity 157.30\n",
      "| epoch 33 |  iter 1 / 19 | time 0[s] | perplexity 157.27\n",
      "| epoch 34 |  iter 1 / 19 | time 0[s] | perplexity 161.40\n",
      "| epoch 35 |  iter 1 / 19 | time 0[s] | perplexity 153.17\n",
      "| epoch 36 |  iter 1 / 19 | time 0[s] | perplexity 148.48\n",
      "| epoch 37 |  iter 1 / 19 | time 0[s] | perplexity 151.60\n",
      "| epoch 38 |  iter 1 / 19 | time 0[s] | perplexity 141.88\n",
      "| epoch 39 |  iter 1 / 19 | time 0[s] | perplexity 140.40\n",
      "| epoch 40 |  iter 1 / 19 | time 0[s] | perplexity 134.38\n",
      "| epoch 41 |  iter 1 / 19 | time 0[s] | perplexity 131.04\n",
      "| epoch 42 |  iter 1 / 19 | time 0[s] | perplexity 128.83\n",
      "| epoch 43 |  iter 1 / 19 | time 0[s] | perplexity 126.87\n",
      "| epoch 44 |  iter 1 / 19 | time 1[s] | perplexity 119.14\n",
      "| epoch 45 |  iter 1 / 19 | time 1[s] | perplexity 113.26\n",
      "| epoch 46 |  iter 1 / 19 | time 1[s] | perplexity 110.56\n",
      "| epoch 47 |  iter 1 / 19 | time 1[s] | perplexity 110.04\n",
      "| epoch 48 |  iter 1 / 19 | time 1[s] | perplexity 106.44\n",
      "| epoch 49 |  iter 1 / 19 | time 1[s] | perplexity 102.71\n",
      "| epoch 50 |  iter 1 / 19 | time 1[s] | perplexity 93.16\n",
      "| epoch 51 |  iter 1 / 19 | time 1[s] | perplexity 91.74\n",
      "| epoch 52 |  iter 1 / 19 | time 1[s] | perplexity 88.11\n",
      "| epoch 53 |  iter 1 / 19 | time 1[s] | perplexity 84.92\n",
      "| epoch 54 |  iter 1 / 19 | time 1[s] | perplexity 80.14\n",
      "| epoch 55 |  iter 1 / 19 | time 1[s] | perplexity 77.04\n",
      "| epoch 56 |  iter 1 / 19 | time 1[s] | perplexity 75.39\n",
      "| epoch 57 |  iter 1 / 19 | time 1[s] | perplexity 72.32\n",
      "| epoch 58 |  iter 1 / 19 | time 1[s] | perplexity 67.49\n",
      "| epoch 59 |  iter 1 / 19 | time 1[s] | perplexity 64.91\n",
      "| epoch 60 |  iter 1 / 19 | time 1[s] | perplexity 59.48\n",
      "| epoch 61 |  iter 1 / 19 | time 1[s] | perplexity 56.53\n",
      "| epoch 62 |  iter 1 / 19 | time 1[s] | perplexity 55.06\n",
      "| epoch 63 |  iter 1 / 19 | time 1[s] | perplexity 53.89\n",
      "| epoch 64 |  iter 1 / 19 | time 1[s] | perplexity 50.68\n",
      "| epoch 65 |  iter 1 / 19 | time 1[s] | perplexity 46.46\n",
      "| epoch 66 |  iter 1 / 19 | time 1[s] | perplexity 44.90\n",
      "| epoch 67 |  iter 1 / 19 | time 1[s] | perplexity 42.42\n",
      "| epoch 68 |  iter 1 / 19 | time 1[s] | perplexity 40.93\n",
      "| epoch 69 |  iter 1 / 19 | time 1[s] | perplexity 38.94\n",
      "| epoch 70 |  iter 1 / 19 | time 1[s] | perplexity 35.81\n",
      "| epoch 71 |  iter 1 / 19 | time 1[s] | perplexity 35.62\n",
      "| epoch 72 |  iter 1 / 19 | time 1[s] | perplexity 33.29\n",
      "| epoch 73 |  iter 1 / 19 | time 1[s] | perplexity 31.26\n",
      "| epoch 74 |  iter 1 / 19 | time 1[s] | perplexity 29.86\n",
      "| epoch 75 |  iter 1 / 19 | time 1[s] | perplexity 27.75\n",
      "| epoch 76 |  iter 1 / 19 | time 1[s] | perplexity 26.33\n",
      "| epoch 77 |  iter 1 / 19 | time 1[s] | perplexity 25.13\n",
      "| epoch 78 |  iter 1 / 19 | time 1[s] | perplexity 23.33\n",
      "| epoch 79 |  iter 1 / 19 | time 1[s] | perplexity 22.00\n",
      "| epoch 80 |  iter 1 / 19 | time 1[s] | perplexity 20.80\n",
      "| epoch 81 |  iter 1 / 19 | time 1[s] | perplexity 19.32\n",
      "| epoch 82 |  iter 1 / 19 | time 1[s] | perplexity 19.56\n",
      "| epoch 83 |  iter 1 / 19 | time 1[s] | perplexity 17.97\n",
      "| epoch 84 |  iter 1 / 19 | time 1[s] | perplexity 17.46\n",
      "| epoch 85 |  iter 1 / 19 | time 1[s] | perplexity 15.61\n",
      "| epoch 86 |  iter 1 / 19 | time 1[s] | perplexity 15.00\n",
      "| epoch 87 |  iter 1 / 19 | time 2[s] | perplexity 14.41\n",
      "| epoch 88 |  iter 1 / 19 | time 2[s] | perplexity 13.52\n",
      "| epoch 89 |  iter 1 / 19 | time 2[s] | perplexity 13.09\n",
      "| epoch 90 |  iter 1 / 19 | time 2[s] | perplexity 12.03\n",
      "| epoch 91 |  iter 1 / 19 | time 2[s] | perplexity 11.44\n",
      "| epoch 92 |  iter 1 / 19 | time 2[s] | perplexity 11.17\n",
      "| epoch 93 |  iter 1 / 19 | time 2[s] | perplexity 10.38\n",
      "| epoch 94 |  iter 1 / 19 | time 2[s] | perplexity 9.73\n",
      "| epoch 95 |  iter 1 / 19 | time 2[s] | perplexity 9.06\n",
      "| epoch 96 |  iter 1 / 19 | time 2[s] | perplexity 9.43\n",
      "| epoch 97 |  iter 1 / 19 | time 2[s] | perplexity 8.84\n",
      "| epoch 98 |  iter 1 / 19 | time 2[s] | perplexity 8.18\n",
      "| epoch 99 |  iter 1 / 19 | time 2[s] | perplexity 7.82\n",
      "| epoch 100 |  iter 1 / 19 | time 2[s] | perplexity 7.62\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from dataset import ptb\n",
    "from simple_rnnlm import SimpleRnnlm\n",
    "\n",
    "\n",
    "# 设定超参数\n",
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN的隐藏状态向量的元素个数\n",
    "time_size = 5  # RNN的展开大小\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "\n",
    "# 读入训练数据\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000  # 缩小测试用的数据集\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)\n",
    "xs = corpus[:-1]  # 输入\n",
    "ts = corpus[1:]  # 输出（监督标签）\n",
    "\n",
    "# 生成模型\n",
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d385868",
   "metadata": {},
   "source": [
    "## 小结\n",
    "- RNN 具有环路，因此可以在内部记忆隐藏状态\n",
    "- 通过展开 RNN 的循环，可以将其解释为多个 RNN 层连接起来的神经网络，可以通过常规的误差反向传播法进行学习（= BPTT）\n",
    "- 在学习长时序数据时，要生成长度适中的数据块，进行以块为单位的 BPTT 学习（= Truncated BPTT）\n",
    "- Truncated BPTT 只截断反向传播的连接\n",
    "- 在 Truncated BPTT 中，为了维持正向传播的连接，需要按顺序输入数据\n",
    "- 语言模型将单词序列解释为概率\n",
    "- 理论上，使用 RNN 层的条件语言模型可以记忆所有已出现单词的信息"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
