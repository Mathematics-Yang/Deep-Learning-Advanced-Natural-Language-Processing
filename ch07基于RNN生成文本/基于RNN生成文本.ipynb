{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c42b621a",
   "metadata": {},
   "source": [
    "# 第七章 &nbsp; &nbsp; 基于RNN生成文本 \n",
    "在第 5 章和第 6 章中，我们仔细研究了 RNN 和 LSTM 的结构及其实现。现在我们已经在代码层面理解了它们。在本章，RNN 和 LSTM 将大显身手，我们将利用 LSTM 实现几个有趣的应用。\n",
    "\n",
    "首先，本章将使用语言模型进行文本生成。具体来说，就是使用在语料库上训练好的语言模型生成新的文本。然后，我们将了解如何使用改进过的语言模型生成更加自然的文本。通过这项工作，我们可以（简单地）体验基于 AI 的文本创作。\n",
    "\n",
    "另外，本章还会介绍一种结构名为 seq2seq 的新神经网络。seq2seq 是 “(from) sequence to sequence”（从时序到时序）的意思，即将一个时序数据转换为另一个时序数据。本章我们将看到，通过组合两个 RNN，可以轻松实现 seq2seq。seq2seq 可以应用于多个应用，比如机器翻译、聊天机器人和邮件自动回复等。通过理解这个简单但聪明强大的 seq2seq，应用深度学习的可能性将进一步扩大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e9760b",
   "metadata": {},
   "source": [
    "## 使用语言模型生成文本\n",
    "我们已经用几章的篇幅讨论了语言模型。如前所述，语言模型可用于各种各样的应用，其中具有代表性的例子有机器翻译、语音识别和文本生成。这里，我们将使用语言模型来生成文本。\n",
    "\n",
    "## 使用RNN生成文本的步骤\n",
    "在上一章中，我们使用 LSTM 层实现了语言模型，这个语言模型的网络结构如下图所示。顺便说一下，我们还实现了整体处理（$T$ 个）时序数据的 `Time LSTM` 层和 `Time Affine` 层。\n",
    "\n",
    "<img src=\"./fig/language_model_before.png\" alt=\"language_model_before\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "现在我们来说明一下语言模型生成文本的顺序。这里仍以 “you say goodbye and i say hello.” 这一在语料库上学习好的语言模型为例，考虑将单词 `i` 赋给这个语言模型的情况。此时，这个语言模型输出下图中的概率分布。\n",
    "\n",
    "<img src=\"./fig/language_model_next_output.png\" alt=\"language_model_next_output\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "语言模型根据已经出现的单词输出下一个出现的单词的概率分布。在上图的例子中，语言模型输出了当给定单词 `i` 时下一个出现的单词的概率分布。那么，它如何生成下一个新单词呢？\n",
    "\n",
    "一种可能的方法是选择概率最高的单词。在这种情况下，因为选择的是概率最高的单词，所以结果能唯一确定。也就是说，这是一种“确定性的”方法。另一种方法是“概率性地”进行选择。根据概率分布进行选择，这样概率高的单词容易被选到，概率低的单词难以被选到。在这种情况下，被选到的单词（被采样到的单词）每次都不一样。\n",
    "\n",
    "这里我们想让每次生成的文本有所不同，这样一来，生成的文本富有变化，会更有趣。因此，我们通过后一种方法（概率性地选择的方法）来选择单词。回到我们的例子中，如下图所示，假设（概率性地）选择了单词 `say`。\n",
    "\n",
    "<img src=\"./fig/sample_by_possibility.png\" alt=\"sample_by_possibility\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "图中显示了根据概率分布进行采样后结果为 `say` 的例子。在图中的概率分布中，`say` 的概率最高，所以它被采样到的概率也最高。不过请注意，这里选到 `say` 并不是必然的（不是确定性的），而是概率性的。因此，`say` 以外的其他单词根据出现的概率也可能被采样到。\n",
    "\n",
    "“确定性的”是指（算法的）结果是唯一确定的，是可预测的。在上例中，假设选择概率最高的单词，那么这就是一种确定性的算法。而“概率性的”算法则概率性地确定结果，因此每次实验时选到的单词都会有所变化（或者说，存在变化的可能性）。\n",
    "\n",
    "接下来，采样第 2 个单词。这只需要重复一下刚才的操作。也就是说，将生成的单词 `say` 输入语言模型，获得单词的概率分布，然后再根据这个概率分布采样下一个出现的单词，如图所示。\n",
    "\n",
    "<img src=\"./fig/output_and_sample.png\" alt=\"output_and_sample\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "之后根据需要重复此过程即可（或者直到出现 `<eos>` 这一结尾记号）。这样一来，我们就可以生成新的文本。\n",
    "\n",
    "这里需要注意的是，像上面这样生成的新文本是训练数据中没有的新生成的文本。因为语言模型并不是背诵了训练数据，而是学习了训练数据中单词的排列模式。如果语言模型通过语料库正确学习了单词的出现模式，我们就可以期待该语言模型生成的文本对人类而言是自然的、有意义的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98355091",
   "metadata": {},
   "source": [
    "## 文本生成的实现\n",
    "下面我们进行文本生成的实现。这里基于上一章实现的 `Rnnlm` 类，来创建继承自它的 `RnnlmGen` 类，然后向这个类添加生成文本的方法。\n",
    "\n",
    "类的继承是指继承已有类，创建新的类。在 Python 中，可以通过 <code>class New(Base):</code> 继承 Base 类，创建 New 类。\n",
    "\n",
    "`RnnlmGen` 类的实现如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76e5eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from rnnlm import Rnnlm\n",
    "from better_rnnlm import BetterRnnlm \n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100): # 生成文本\n",
    "        \"\"\"\n",
    "        start_id: 起始单词的ID\n",
    "        skip_ids: 采样时跳过的单词ID列表\n",
    "        sample_size: 采样的单词数\n",
    "        该函数从start_id开始，逐步采样单词，直到采样到sample_size个单词为止。\n",
    "        采样时会跳过skip_ids中的单词ID。\n",
    "        采样的单词ID列表作为函数的返回值。\n",
    "        \"\"\"\n",
    "        word_ids = [start_id] # 生成的单词ID列表\n",
    "\n",
    "        x = start_id # 当前输入单词ID\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1) # 整理成形状为1 × 1的数组\n",
    "            score = self.predict(x) # 计算下一个单词的得分\n",
    "            p = softmax(score.flatten()) # 计算下一个单词的概率分布\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p) # 根据概率分布p采样下一个单词\n",
    "            if (skip_ids is None) or (sampled not in skip_ids): # 如果采样的单词不在skip_ids中\n",
    "                x = sampled # 将采样的单词作为下一个输入单词\n",
    "                word_ids.append(int(x)) # 将采样的单词ID添加到结果列表中\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c # 返回LSTM的隐藏状态和记忆状态\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state) # 设置LSTM的隐藏状态和记忆状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dde1e7",
   "metadata": {},
   "source": [
    "这个类用 `generate(start_id, skip_ids, sample_size)` 生成文本。此处，参数 `start_id` 是第 1 个单词 ID，`sample_size` 表示要采样的单词数量。另外，参数 `skip_ids` 是单词 ID 列表（比如，`[12, 20]`），它指定的单词将不被采样。这个参数用于排除 PTB 数据集中的 `<unk>`、`N` 等被预处理过的单词。\n",
    "\n",
    "PTB数据集对原始文本进行了预处理，稀有单词被&lt;unk&gt;替换，数字被N替换。另外，我们用&lt;eos&gt;作为文本的分隔符。\n",
    "\n",
    "`generate()` 方法首先通过 `model.predict(x)` 输出各个单词的得分（得分是正规化之前的值），然后基于 `p = softmax(score)`，使用 Softmax 函数对得分进行正规化，这样就获得了我们想要的概率分布。接下来，使用 `np.random.choice()`，根据这个概率分布 `p` 采样下一个单词。关于 `np.random.choice()`，我们已经在之前的小节说明过了。\n",
    "\n",
    "model的predict()方法进行的是mini-batch处理，所以输入x必须是二维数组。因此，即使在只输入1个单词ID的情况下，也要将它的批大小视为1，并将其整理成形状为1 × 1的NumPy数组。\n",
    "\n",
    "现在，使用这个 `RnnlmGen` 类进行文本生成。这里先在完全没有学习的状态（即权重参数是随机初始值的状态）下生成文本，代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76344e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you can call it it gets and how low and tomorrow say like red is too long a good against take into share groups.\n",
      " sun lost to prevent a bit filled falling.\n",
      " unilever pfeiffer 's rights of families are slow and replaced agricole doctors co. 's u.s. sales is to have lack of convert additional limit for all.\n",
      " recently it may have had shown mergers in the first branch of two pale workers only predict mr. lee is n't able to make any computers in this 30-day lesser effort to present food to the law.\n",
      " mr.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "from rnnlm_gen import RnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train') # 读取PTB数据集\n",
    "vocab_size = len(word_to_id) # 词典大小\n",
    "corpus_size = len(corpus) # 语料库大小\n",
    "\n",
    "model = RnnlmGen() # 创建RnnlmGen的实例\n",
    "model.load_params('../ch06Gated RNN/Rnnlm.pkl') # 读取学习好的模型参数\n",
    "\n",
    "# 设定start单词和skip单词\n",
    "start_word = 'you' # 起始单词\n",
    "start_id = word_to_id[start_word] # 起始单词的ID\n",
    "skip_words = ['N', '<unk>', '$'] # 采样时跳过的单词，如数字、未知单词等\n",
    "skip_ids = [word_to_id[w] for w in skip_words] # 采样时跳过的单词ID列表\n",
    "\n",
    "# 文本生成\n",
    "word_ids = model.generate(start_id, skip_ids) # 生成单词ID列表\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids]) # 用空格连接所有单词，形成连续的文本字符串\n",
    "txt = txt.replace(' <eos>', '.\\n') # 将<eos>替换为句号和换行符\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbe4ebd",
   "metadata": {},
   "source": [
    "这里，第 1 个单词是 you，我们将它的单词 ID 设为 `start_id`，来进行文本生成。另外，指定不参与采样的单词为 `['N', '<unk>', '$']`。生成文本的 `generate()` 方法返回单词 ID 列表，因此需要将单词 ID 列表转化为句子。这可以通过 `txt = ' '.join([id_to_word[i] for i in word_ids])` 这行代码进行。`join()` 方法通过 “‘分隔符’.join(列表)” 这种形式连接单词。下面我们来看一个具体的例子。\n",
    "\n",
    "```python\n",
    ">>> ' '.join(['you', 'say', 'goodbye'])\n",
    "'you say goodbye'\n",
    "```\n",
    "\n",
    "运行一下上面的代码，结果如下。\n",
    "\n",
    "you setback best raised fill steelworkers montgomery kohlberg told beam worthy allied ban swedish aichi mather promptly ramada explicit leslie bets discovery considering campaigns bottom petrie warm large-scale frequent temple grumman bennett ...\n",
    "\n",
    "\n",
    "如你所见，输出的文本是一堆乱七八糟的单词。不过这可以理解，因为这里的模型权重使用的是随机初始值，所以输出了没有意义的文本。那么，如果换成学习好的语言模型，结果会怎样呢？我们利用上一章学习好的权重来进行文本生成。为此，使用 `model.load_params('../ch06Gated RNN/Rnnlm.pkl')` 读入上一章学习好的权重参数，并生成文本。我们来看一下生成的文本（每次的结果都不一样）。\n",
    "\n",
    "you 'll include one of them a good problems.  \n",
    "moreover so if not gene 's corr experience with the heat of bridges a new deficits model is non-violent what it 's a rule must exploit it.  \n",
    "there 's no tires industry could occur.  \n",
    "beyond my hours where he is n't going home says and japanese letter.  \n",
    "knight transplants d.c. turmoil with one-third of voters.  \n",
    "the justice department is ...\n",
    "\n",
    "虽然上面的结果中可以看到多处语法错误和意思不通的地方，不过也有几处读起来已经比较像句子了。仔细看的话，这个模型正确生成了主语和动词的组合，比如 “you'll include...” “there's no tires...” “knight transplants...” 等。再者，它在一定程度上理解了形容词和名词的使用方法，比如 “good problems” “japanese letter” 等。另外，开头的 “you'll include one of them a good problems.” 也是一个含义通顺的句子。\n",
    "\n",
    "如上所述，上面的实验生成的文本在某种程度上可以说是正确的，不过结果中仍有许多不自然的地方，改进空间很大。虽然不存在 “完美的文章”，但是至少我们可以追求更自然的文章。为此，我们应该怎么做呢？当然是使用更好的语言模型！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb4708",
   "metadata": {},
   "source": [
    "## 更好的文本生成\n",
    "如果有更好的语言模型，就可能有更好的文本。在上一章中，我们改进了简单的 RNNLM，实现了 “更好的 RNNLM”，将模型的困惑度从 136 降至 75。现在，我们看一下这个 “更好的 RNNLM” 生成文本的能力。\n",
    "\n",
    "在上一章中，我们进行了 `BetterRnnlm` 类的学习，并将学习好的权重保存为了文件。这里的实验需要用到这个学习好的权重文件，我们可以从出版社网站的本书主页获取。将这个权重文件放到本书源代码的 `ch06Gated RNN` 目录下，即可运行本实验的代码。\n",
    "\n",
    "在上一章中，我们将更好的语言模型实现为了 `BetterRnnlm` 类。这里，像刚才一样，继承这个类，并使之有生成文本的能力。`BetterRnnlmGen` 类的实现和刚刚的 `RnnlmGen` 类完全一样，此处省略具体说明。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19151377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are designed to spread from the industrial area where the initial exhibition was completed but are n't sent to a cure.\n",
      " it does n't seem to be determined.\n",
      " sheraton a louisville ky. calif. firm said that a series of common losses of the restraints were scheduled to set up with monthly settlements in leipzig indonesia and portugal.\n",
      " at mr. johnson 's sr. bears fax an lawsuit on the move is the first to move before saying he says people will be caught in the starting the position if he bought three or two there to be\n",
      "--------------------------------------------------\n",
      "the meaning of life is hiring to honor ted flom.\n",
      " the best says mrs. paterson says you 're going a big so more shouted in all mr. says referring to the fact that we do n't know how much it will be done.\n",
      " jack golden moore.\n",
      " columbia s.c.\n",
      " you 're shown practices they 're in the country 's door in the third and fourth world.\n",
      " dragging a fact that you 'm a novel who was eager to do with him must not make the right to handle.\n",
      " bulk readers are protected.\n",
      " but he told former chief walter\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "from common.np import *\n",
    "from rnnlm_gen import BetterRnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train') # 读取PTB数据集\n",
    "vocab_size = len(word_to_id) # 词典大小\n",
    "corpus_size = len(corpus) # 语料库大小\n",
    "\n",
    "\n",
    "model = BetterRnnlmGen() # 创建BetterRnnlmGen的实例\n",
    "model.load_params('../ch06Gated RNN/BetterRnnlm.pkl') # 读取学习好的模型参数\n",
    "\n",
    "# 设定start字符和skip字符\n",
    "start_word = 'you' # 起始单词\n",
    "start_id = word_to_id[start_word] # 起始单词的ID\n",
    "skip_words = ['N', '<unk>', '$'] # 采样时跳过的单词，如数字、未知单词等\n",
    "skip_ids = [word_to_id[w] for w in skip_words] # 采样时跳过的单词ID列表\n",
    "# 文本生成\n",
    "word_ids = model.generate(start_id, skip_ids) # 生成单词ID列表\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids]) # 用空格连接所有单词，形成连续的文本字符串\n",
    "txt = txt.replace(' <eos>', '.\\n') # 将<eos>替换为句号和换行符\n",
    "\n",
    "print(txt) \n",
    "\n",
    "\n",
    "model.reset_state() # 重置LSTM的隐藏状态和记忆状态\n",
    "\n",
    "start_words = 'the meaning of life is' # 起始单词序列\n",
    "start_ids = [word_to_id[w] for w in start_words.split(' ')]  # 起始单词ID列表\n",
    "\n",
    "for x in start_ids[:-1]: # 除了最后一个单词外，逐个输入起始单词\n",
    "    x = np.array(x).reshape(1, 1) # 整理成形状为1 × 1的数组\n",
    "    model.predict(x) # 逐个输入起始单词\n",
    "\n",
    "word_ids = model.generate(start_ids[-1], skip_ids) # 从最后一个起始单词开始生成单词ID列表\n",
    "word_ids = start_ids[:-1] + word_ids # 将起始单词ID列表和生成的单词ID列表连接起来\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids]) # 用空格连接所有单词，形成连续的文本字符串\n",
    "txt = txt.replace(' <eos>', '.\\n') # 将<eos>替换为句号和换行符\n",
    "print('-' * 50) # 分隔线\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26263e7",
   "metadata": {},
   "source": [
    "现在，我们让这个更好的语言模型生成文本。和之前一样，第 1 个单词是 `you`。这样一来，下述文本会被生成。\n",
    "\n",
    "you 've seen two families and the women and two other women of students.  \n",
    "the principles of investors that prompted a bipartisan rule of which had a withdrawn target of black men or legislators interfere with the number of plants can do to carry it together.  \n",
    "the appeal was to deny steady increases in the operation of dna and educational damage in the 1950s.  \n",
    "...\n",
    "\n",
    "可以看出，这个模型生成了比之前更自然的文本（可能有些主观）。最开始的句子 “you’ve seen two families and the women...” 正确使用了主语、动词和宾语，并且正确学习了 `and` 的使用方法（`two families and the women`）。其他部分读起来总体上也算说得过去。\n",
    "\n",
    "虽然这里生成的文本仍然存在若干问题（特别是语义方面），但是从某种程度上来说，这个更好的语言模型生成了更加自然的文本。通过进一步改进这个模型，使用更大规模的语料库，应该能创造出更加自然的文本。\n",
    "\n",
    "最后，我们尝试给这个更好的语言模型输入 “the meaning of life is”，让它生成后续的单词。为了做这个实验，我们按顺序向模型输入 `['the', 'meaning', 'of', 'life']`，进行正向传播。此时不使用任何输出的结果，只是让 LSTM 层记住这些单词的信息。然后，以单词 `is` 作为开始位置，生成 “the meaning of life is” 的后续内容。\n",
    "\n",
    "每次实验生成的文本都不太一样，这里介绍一个有意思的结果。\n",
    "\n",
    "``the meaning of life is not a good version of paintings.``\n",
    "\n",
    "如上所述，语言模型给出的回答是 “人生的意义并不是一种状态良好的绘画”。虽然搞不懂什么才是 “状态良好的绘画”，不过说不定这其中有什么深刻的意义。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999db9cb",
   "metadata": {},
   "source": [
    "## seq2seq模型\n",
    "这个世界充满了时序数据。文本数据、音频数据和视频数据都是时序数据。另外，还存在许多需要将一种时序数据转换为另一种时序数据的任务，比如机器翻译、语音识别等。其他的还有进行对话的聊天机器人应用、将源代码转为机器语言的编译器等。\n",
    "\n",
    "像这样，世界上存在许多输入输出均为时序数据的任务。从现在开始，我们会考察将时序数据转换为其他时序数据的模型。作为它的实现方法，我们将介绍使用两个 RNN 的 seq2seq 模型。\n",
    "\n",
    "## seq2seq的原理\n",
    "seq2seq 模型也称为 Encoder-Decoder 模型。顾名思义，这个模型有两个模块——Encoder（编码器）和 Decoder（解码器）。编码器对输入数据进行编码，解码器对被编码的数据进行解码。\n",
    "\n",
    "编码是基于某些既定规则的信息转换过程。以字符码为例，将字符 “A” 转换为 “1000001”（二进制）就是一个编码的例子。而解码则将被编码的信息还原到它的原始形态。仍以字符码为例，这相当于将位模式的 “1000001” 转换为字符 “A”。\n",
    "\n",
    "现在，我们举一个具体的例子来说明 seq2seq 的机制。这里考虑将日语翻译为英语，比如将 “吾輩は猫である” 翻译为 “I am a cat”。此时，如下图所示，seq2seq 基于编码器和解码器进行时序数据的转换。\n",
    "\n",
    "<img src=\"./fig/encoder_decoder_example.png\" alt=\"encoder_decoder_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，编码器首先对 “吾輩は猫である” 这句话进行编码，然后将编码好的信息传递给解码器，由解码器生成目标文本。此时，编码器编码的信息浓缩了翻译所必需的信息，解码器基于这个浓缩的信息生成目标文本。\n",
    "\n",
    "以上就是 seq2seq 的全貌图。编码器和解码器协作，将一个时序数据转换为另一个时序数据。另外，在这些编码器和解码器内部可以使用 RNN。下面我们来看一下细节。首先来看编码器，它的层结构如下图所示。\n",
    "\n",
    "<img src=\"./fig/encoder.png\" alt=\"encoder\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "由上图可以看出，编码器利用 RNN 将时序数据转换为隐藏状态 $\\boldsymbol{h}$。这里的 RNN 使用的是 LSTM，不过也可以使用 “简单 RNN” 或者 GRU 等。另外，这里考虑的是将日语句子分割为单词进行输入的情况。\n",
    "\n",
    "上图的编码器输出的向量 $\\boldsymbol{h}$ 是 LSTM 层的最后一个隐藏状态，其中编码了翻译输入文本所需的信息。这里的重点是，LSTM 的隐藏状态 $\\boldsymbol{h}$ 是一个固定长度的向量。说到底，编码就是将任意长度的文本转换为一个固定长度的向量。\n",
    "\n",
    "<img src=\"./fig/encoder_example.png\" alt=\"encoder_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，编码器将文本转换为固定长度的向量。那么，解码器是如何 “处理” 这个编码好的向量，从而生成目标文本的呢？其实，我们已经知道答案了。因为我们只需要直接使用上一节讨论的进行文本生成的模型即可，如下图所示。\n",
    "\n",
    "<img src=\"./fig/encoder_layer.png\" alt=\"encoder_layer\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "从图中可以看出，解码器的结构和上一节的神经网络完全相同。不过它和上一节的模型存在一点差异，就是 LSTM 层会接收向量 $\\boldsymbol{h}$。在上一节的语言模型中，LSTM 层不接收任何信息（硬要说的话，也可以说 LSTM 的隐藏状态接收 “0 向量”）。这个唯一的、微小的改变使得普通的语言模型进化为可以驾驭翻译的解码器。\n",
    "\n",
    "图中使用了&lt;eos&gt;这一分隔符（特殊符号）。这个分隔符被用作通知解码器开始生成文本的信号。另外，解码器采样到&lt;eos&gt;出现为止，所以它也是结束信号。也就是说，分隔符&lt;eos&gt;可以用来指示解码器的“开始 / 结束”。在其他文献中，也有使用&lt;go&gt;、&lt;start&gt;或者“_”（下划线）作为分隔符的例子。\n",
    "\n",
    "现在我们连接编码器和解码器，并给出它的层结构，具体如下图所示。\n",
    "\n",
    "<img src=\"./fig/seq2seq_layer.png\" alt=\"seq2seq_layer\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，seq2seq 由两个 LSTM 层构成，即编码器的 LSTM 和解码器的 LSTM。此时，LSTM 层的隐藏状态是编码器和解码器的 “桥梁”。在正向传播时，编码器的编码信息通过 LSTM 层的隐藏状态传递给解码器；在反向传播时，解码器的梯度通过这个 “桥梁” 传递给编码器。\n",
    "\n",
    "---\n",
    "\n",
    "编码器的核心目标是把任意长度的输入序列，压缩成一个能代表核心语义的“信息包”。而h恰好具备这个属性，c则不适合。\n",
    "- **h的特性**：编码器LSTM的最后一个h，是经过每一步输入（如日语单词）迭代更新后的“最终状态”。它融合了整个输入序列的**关键语义和时序逻辑**，比如“吾輩は猫である”中“主语是我、宾语是猫、判断句结构”这些核心信息，都被浓缩在h里。可以理解为h是对输入序列的“精炼总结”。\n",
    "- **c的特性**：编码器的c是“长期记忆仓库”，里面不仅有核心语义，还可能保留了一些**中间冗余信息**（比如输入序列中不重要的助词、语气词痕迹）。这些冗余信息对解码器来说是“噪音”，会干扰生成目标序列的准确性，所以不适合直接传递。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7010f4",
   "metadata": {},
   "source": [
    "## 时序数据转换的简单尝试\n",
    "下面我们来实现 seq2seq，不过在此之前，首先说明一下我们要处理的问题。这里我们将 “加法” 视为一个时序转换问题。具体来说，如图所示，在 seq2seq 学习后，如果输入字符串 “57 + 5”，seq2seq 要能正确回答 “62”。顺便说一下，这种为了评价机器学习而创建的简单问题，称为 “toy problem”。\n",
    "\n",
    "<img src=\"./fig/seq2seq_addition.png\" alt=\"seq2seq_addition\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "在我们看来，这里做的加法运算是非常简单的问题，但是 seq2seq 对加法（更确切地说是加法的逻辑）一无所知。seq2seq 从加法的例子（样本）中学习出现的字符模式，这样真的可以学习到加法运算的规则吗？这正是本次实验的看头。\n",
    "\n",
    "顺便说一下，在之前的 word2vec 和语言模型中，我们都把文本以单词为单位进行了分割，但并非必须这样做。对于本节的这个问题，我们将不以单词为单位，而是以字符为单位进行分割。在以字符为单位进行分割的情况下，“57 + 5”这样的输入会被处理为 ['5', '7', '+', '5'] 这样的列表。\n",
    "\n",
    "## 可变长度的时序数据\n",
    "我们将“加法”视为字符（数字）列表。这里需要注意的是，不同的加法问题（“57 + 5”或者 “628 + 521” 等）及其回答（“62”或者 “1149” 等）的字符数是不同的。比如，“57 + 5”共有 4 个字符，而 “628 + 521” 共有 7 个字符。\n",
    "\n",
    "如此，在加法问题中，每个样本在时间方向上的大小不同。也就是说，加法问题处理的是可变长度的时序数据。因此，在神经网络的学习中，在进行 mini-batch 处理时，需要想一些应对办法。\n",
    "\n",
    "在使用批数据进行学习时，会一起处理多个样本。此时，（在我们的实现中）需要保证一个批次内各个样本的数据形状是一致的。\n",
    "\n",
    "在基于 mini-batch 学习可变长度的时序数据时，最简单的方法是使用填充（padding）。所谓填充，就是用无效（无意义）数据填入原始数据，从而使数据长度对齐。就上面这个加法的例子来说，如图所示，在多余位置插入无效字符（这里是空白字符），从而使所有输入数据的长度对齐。\n",
    "\n",
    "<img src=\"./fig/mini_batch_padding.png\" alt=\"mini_batch_padding\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "本次的问题处理的是 0～999 的两个数的加法。因此，包括 “+” 在内，输入的最大字符数是 7。另外，加法的结果最大是 4 个字符（最大为 “999 + 999 = 1998”）。因此，对监督数据也进行类似的填充，从而对齐所有样本数据的长度。另外，在本次的问题中，在输出的开始处加上了分隔符 “_”（下划线），使得输出数据的字符数统一为 5。这个分隔符作为通知解码器开始生成文本的信号使用。\n",
    "\n",
    "对于解码器的输出，可以在监督标签中插入表示字符输出结束的分隔符（比如 “_62_” 或 “_1149_”）。但是，简单起见，这里我们不使用表示字符输出结束的分隔符。也就是说，在解码器生成字符串时，始终输出固定数量的字符（这里是包括开始处的 “_” 在内的 5 个字符）。\n",
    "\n",
    "像这样，通过填充对齐数据的大小，可以处理可变长度的时序数据。但是，因为使用了填充，seq2seq 需要处理原本不存在的填充用字符，所以如果追求严谨，使用填充时需要向 seq2seq 添加一些填充专用的处理。比如，在解码器中输入填充时，不应计算其损失（这可以通过向 Softmax with Loss 层添加 mask 功能来解决）。再比如，在编码器中输入填充时，LSTM 层应按原样输出上一时刻的输入。这样一来，LSTM 层就可以像不存在填充一样对输入数据进行编码。\n",
    "\n",
    "这里的内容有一些复杂，大家即使无法理解也没有关系。为了便于理解，本章我们将填充用字符（空白字符）作为普通数据处理，不进行特别处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d93d06",
   "metadata": {},
   "source": [
    "## 加法数据集\n",
    "这里介绍的加法的学习数据预先存放在了 `dataset/addition.txt` 中。如图所示，这个文本文件中含有 50 000 个加法样本。这份学习数据的制作参考了 Keras 的 seq2seq 的实现。\n",
    "\n",
    "<img src=\"./fig/addition_dataset.png\" alt=\"addition_dataset\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "为了使用 Python 轻松处理 seq2seq 的学习数据（文本文件），本书提供了一个专用模块（`dataset/sequence.py`），这个模块有 `load_data()` 和 `get_vocab()` 两个方法。\n",
    "\n",
    "`load_data(file_name, seed)` 读入由 `file_name` 指定的文本文件，并将文本转换为字符 ID，返回训练数据和测试数据。该方法内部设有随机数种子 `seed` 以打乱数据，分割训练数据和测试数据。另外，`get_vocab()` 方法返回字符与 ID 的映射字典（实际上返回 `char_to_id` 和 `id_to_char`）。现在我们来看一下实际的使用示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92b806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 7) (45000, 5)\n",
      "(5000, 7) (5000, 5)\n",
      "[ 3  0  2  0  0 11  5]\n",
      "[ 6  0 11  7  5]\n",
      "71+118 \n",
      "_189 \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "from dataset import sequence\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt', seed=1984) # 读取加法运算数据集\n",
    "char_to_id, id_to_char = sequence.get_vocab() # 获取字符和ID的对应关系\n",
    "\n",
    "print(x_train.shape, t_train.shape) \n",
    "print(x_test.shape, t_test.shape)\n",
    "# (45000, 7) (45000, 5)\n",
    "# (5000, 7) (5000, 5)\n",
    "\n",
    "print(x_train[0])\n",
    "print(t_train[0])\n",
    "# [ 3  0  2  0  0 11  5]\n",
    "# [ 6  0 11  7  5]\n",
    "\n",
    "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
    "print(''.join([id_to_char[c] for c in t_train[0]]))\n",
    "# 71+118\n",
    "# _189"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad97957",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "简单来说，字符的ID分配遵循“先到先得”原则，具体逻辑可以拆解为两点：\n",
    "\n",
    "1. **首次出现即分配ID**\n",
    "   当`_update_vocab`函数遍历文本时，会检查当前字符是否已存在于`char_to_id`字典中。如果不存在，就立即为其分配一个新ID，ID值等于当前字典的长度（从0开始递增）。\n",
    "   - 例如，数据集中第一个出现的字符（比如“1”）会被分配ID=0，第二个新字符（比如“+”）分配ID=1，以此类推。\n",
    "\n",
    "2. **后续出现不重复分配**\n",
    "   同一字符后续再次出现时（比如在其他问题或答案中），由于已存在于字典中，不会重新分配新ID，直接沿用首次分配的ID。\n",
    "   - 例如，“1”在第一个问题中被分配ID=0后，后续所有问题或答案中的“1”，都会统一使用ID=0。\n",
    "\n",
    "这种构建方式的核心是“按首次出现顺序分配唯一ID”，不依赖字符本身的含义（如数字大小、是否为运算符），仅由数据集中的出现顺序决定。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c94eb91",
   "metadata": {},
   "source": [
    "像这样，使用 `sequence` 模块，可以轻松地读入 seq2seq 用的数据。这里，`x_train` 和 `t_train` 存放的是字符 ID。另外，字符 ID 和字符之间的映射可以使用 `char_to_id` 和 `id_to_char`。\n",
    "\n",
    "数据集原本应分成训练用、验证用和测试用3份。用训练数据进行学习，用验证数据进行调参，最后再用测试数据评价模型的能力。而简单起见，这里只分成训练数据和测试数据2份，用它们进行模型的训练和评价。\n",
    "\n",
    "## seq2seq的实现\n",
    "seq2seq 是组合了两个 RNN 的神经网络。这里我们首先将这两个 RNN 实现为 `Encoder` 类和 `Decoder` 类，然后将这两个类组合起来，来实现 `seq2seq` 类。我们先从 `Encoder` 类开始介绍。\n",
    "\n",
    "## Encoder类\n",
    "如图所示，`Encoder` 类接收字符串，将其转化为向量 $\\boldsymbol{h}$。\n",
    "\n",
    "<img src=\"./fig/encoder_input_and_output.png\" alt=\"encoder_input_and_output\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如前所述，我们使用 RNN 实现编码器。这里，使用 LSTM 层实现下图的层结构。\n",
    "\n",
    "<img src=\"./fig/encoder_layer_example.png\" alt=\"encoder_layer_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，`Encoder` 类由 `Embedding` 层和 `LSTM` 层组成。`Embedding` 层将字符（字符 ID）转化为字符向量，然后将字符向量输入 `LSTM` 层。\n",
    "\n",
    "`LSTM` 层向右（时间方向）输出隐藏状态和记忆单元，向上输出隐藏状态。这里，因为上方不存在层，所以丢弃 `LSTM` 层向上的输出。如图 7-14 所示，在编码器处理完最后一个字符后，输出 `LSTM` 层的隐藏状态 $\\boldsymbol{h}$。然后，这个隐藏状态 $\\boldsymbol{h}$ 被传递给解码器。\n",
    "\n",
    "编码器只将LSTM的隐藏状态传递给解码器。尽管也可以把LSTM的记忆单元传递给解码器，但我们通常不太会把LSTM的记忆单元传递给其他层。这是因为，LSTM的记忆单元被设计为只给自身使用。\n",
    "\n",
    "顺便说一下，我们已经将时间方向上进行整体处理的层实现为了 `Time LSTM` 层和 `Time Embedding` 层。使用这些 `Time` 层，我们的编码器将如图所示。\n",
    "\n",
    "<img src=\"./fig/time_encoder.png\" alt=\"time_encoder\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "`Encoder` 类如下所示。这个 `Encoder` 类有初始化 `__init__()`、正向传播 `forward()` 和反向传播 `backward()` 这 3 个方法。首先，我们来看一下初始化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c29803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "from common.time_layers import *\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词典大小、词向量维度、隐藏状态维度\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f') # 词嵌入矩阵\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f') # LSTM的输入权重\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f') # LSTM的隐藏状态权重\n",
    "        lstm_b = np.zeros(4 * H).astype('f') # LSTM的偏置\n",
    "        \n",
    "        self.embed_W = TimeEmbedding(embed_W) # 词嵌入层\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False) # LSTM层\n",
    "\n",
    "        self.params = self.embed_W.params + self.lstm.params # 所有参数\n",
    "        self.grads = self.embed_W.grads + self.lstm.grads # 所有梯度\n",
    "        self.hs = None # LSTM的隐藏状态序列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385499b0",
   "metadata": {},
   "source": [
    "初始化方法接收 `vocab_size`、`wordvec_size` 和 `hidden_size` 这 3 个参数。`vocab_size` 是词汇量，相当于字符的种类。顺便说一下，这次共有 13 种字符（数字 0~9、“+”、“ ”（空白字符）、“_”）。此外，`wordvec_size` 对应于字符向量的维数，`hidden_size` 对应于 LSTM 层的隐藏状态的维数。\n",
    "\n",
    "这个初始化方法进行权重参数的初始化和层的生成。最后，将权重参数和梯度分别归纳在成员变量 `params` 和 `grads` 的列表中。因为这次并不保持 `Time LSTM` 层的状态，所以设定 `stateful=False`。\n",
    "\n",
    "第5章和第6章的语言模型处理的是只有一个长时序数据的问题。那时我们设定Time LSTM层的参数 <code>stateful=True</code>，以在保持隐藏状态的同时，处理长时序数据。而这次是有多个短时序数据的问题。因此，针对每个问题重设LSTM的隐藏状态（为0向量）。\n",
    "\n",
    "接着来看 `forward()` 方法和 `backward()` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddeb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, xs):\n",
    "    xs = self.embed.forward(xs) # 词嵌入层的前向传播，将单词ID转换为词向量，形状为 (N, T, D)\n",
    "    hs = self.lstm.forward(xs) # LSTM层的前向传播，形状为 (N, T, H)\n",
    "    self.hs = hs # 保存LSTM的隐藏状态序列\n",
    "    return hs[:, -1, :] # 返回最后一个时间步的隐藏状态\n",
    "\n",
    "def backward(self, dh):\n",
    "    dhs = np.zeros_like(self.hs) # 初始化隐藏状态序列的梯度，形状与self.hs相同，即 (N, T, H)\n",
    "    dhs[:, -1, :] = dh # 只在最后一个时间步设置梯度，其他时间步为0\n",
    "    dout = self.lstm.backward(dhs) # LSTM层的反向传播，得到词嵌入层的梯度，形状为 (N, T, D)\n",
    "    dout = self.embed.backward(dout) # 词嵌入层的反向传播，得到输入的梯度，形状为 (N, T, D)\n",
    "    return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9bd63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "from common.time_layers import *\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词典大小、词向量维度、隐藏状态维度\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f') # 词嵌入矩阵\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f') # LSTM的输入权重\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f') # LSTM的隐藏状态权重\n",
    "        lstm_b = np.zeros(4 * H).astype('f') # LSTM的偏置\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W) # 词嵌入层\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False) # LSTM层\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params # 所有参数\n",
    "        self.grads = self.embed.grads + self.lstm.grads # 所有梯度\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs) # 词嵌入层的前向传播，将单词ID转换为词向量，形状为 (N, T, D)\n",
    "        hs = self.lstm.forward(xs) # LSTM层的前向传播，形状为 (N, T, H)\n",
    "        self.hs = hs # 保存LSTM的隐藏状态序列\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs) # 初始化隐藏状态序列的梯度，形状与self.hs相同，即 (N, T, H)\n",
    "        dhs[:, -1, :] = dh  # 只在最后一个时间步设置梯度，其他时间步为0\n",
    "\n",
    "        dout = self.lstm.backward(dhs) # LSTM层的反向传播，得到词嵌入层的梯度，形状为 (N, T, D)\n",
    "        dout = self.embed.backward(dout) # 词嵌入层的反向传播，得到输入的梯度，形状为 (N, T, D)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7976810",
   "metadata": {},
   "source": [
    "编码器的正向传播调用 `Time Embedding` 层和 `Time LSTM` 层的 `forward()` 方法，然后取出 `Time LSTM` 层的最后一个时刻的隐藏状态，将它作为编码器的 `forward()` 方法的输出。\n",
    "\n",
    "在编码器的反向传播中，LSTM 层的最后一个隐藏状态的梯度是 `dh`，这个 `dh` 是从解码器传来的梯度。在反向传播的实现中，先生成元素为 0 的张量 `dhs`，再将 `dh` 存放到这个 `dhs` 中的对应位置。剩下的就是调用 `Time Embedding` 层和 `Time LSTM` 层的 `backward()` 方法。以上就是 `Encoder` 类的实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df9305",
   "metadata": {},
   "source": [
    "## Decoder类\n",
    "下面，我们继续 `Decoder` 类的实现。如下图所示，`Decoder` 类接收 `Encoder` 类输出的 $\\boldsymbol{h}$，输出目标字符串。\n",
    "\n",
    "<img src=\"./fig/encoder_and_decoder.png\" alt=\"encoder_and_decoder\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如前所述，解码器可以由 RNN 实现。和编码器一样，这里也使用 LSTM 层，此时解码器的层结构如下图所示。\n",
    "\n",
    "<img src=\"./fig/decoder_learning.png\" alt=\"decoder_learning\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "上图显示了解码器在学习时的层结构。这里使用了监督数据 _62 进行学习，此时输入数据是 `['_', '6', '2', ' ']`，对应的输出是 `['6', '2', ' ', ' ']`。\n",
    "\n",
    "在使用RNN进行文本生成时，学习时和生成时的数据输入方法不同。在学习时，因为已经知道正确解，所以可以整体地输入时序方向上的数据。相对地，在推理时（生成新字符串时），则只能输入第1个通知开始的分隔符（本次为“_”）。然后，基于输出采样1个字符，并将这个采样出来的字符作为下一个输入，如此重复该过程。\n",
    "\n",
    "顺便说一句，在之前的小节，在进行文本生成时，我们基于 Softmax 函数的概率分布进行了采样，因此生成的文本会随机变动。因为这次的问题是加法，所以我们想消除这种概率性的 “波动”，生成 “确定性的” 答案。为此，这次我们仅选择得分最高的字符。也就是说，是 “确定性” 地选择，而不是 “概率性” 地选择。下图显示了解码器生成字符串的过程。\n",
    "\n",
    "<img src=\"./fig/decoder_softmax.png\" alt=\"decoder_softmax\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，这里出现了新的 `argmax` 节点，这是获取最大值的索引（本例中是字符 ID）的节点。图中的结构和上一节展示的文本生成时的结构相同。不过这次没有使用 `Softmax` 层，而是从 `Affine` 层输出的得分中选择了最大值的字符 ID。\n",
    "\n",
    "Softmax层对输入的向量进行正规化。此时，向量元素的值虽然被改变，但是它们的大小关系没有变化。因此，在上图的情况下，可以省略Softmax层。\n",
    "\n",
    "如上所述，在解码器中，在学习时和在生成时处理 `Softmax` 层的方式是不一样的。因此，`Softmax with Loss` 层交给此后实现的 `Seq2seq` 类处理。如下图所示，`Decoder` 类仅承担 `Time Softmax with Loss` 层之前的部分。\n",
    "\n",
    "<img src=\"./fig/decoder.png\" alt=\"decoder\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "由上图可以看出，`Decoder` 类由 `Time Embedding`、`Time LSTM` 和 `Time Affine` 这 3 个层构成。下面，我们来看一下 `Decoder` 层的实现。这里一起给出它的初始化 `__init__()` 方法、正向传播 `forward()` 方法和反向传播 `backward()` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274f23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词典大小、词向量维度、隐藏状态维度\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f') # 词嵌入矩阵\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f') # LSTM的输入权重\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f') # LSTM的隐藏状态权重\n",
    "        lstm_b = np.zeros(4 * H).astype('f') # LSTM的偏置\n",
    "\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f') # 仿射变换的权重\n",
    "        affine_b = np.zeros(V).astype('f') # 仿射变换的偏置\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W) # 词嵌入层\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True) # LSTM层\n",
    "        self.affine = TimeAffine(affine_W, affine_b) # 仿射变换层\n",
    "\n",
    "        self.params, self.grads = [], [] # 所有参数和梯度\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h) # 设置LSTM的隐藏状态\n",
    "        out = self.embed.forward(xs) # 词嵌入层的前向传播，将单词ID转换为词向量，形状为 (N, T, D)\n",
    "        out = self.lstm.forward(out) # LSTM层的前向传播，形状为 (N, T, H)\n",
    "        score = self.affine.forward(out) # 仿射变换层的前向传播，形状为 (N, T, V)\n",
    "        return score\n",
    "    \n",
    "    def backwawrd(self, dscore):\n",
    "        dout = self.affine.backward(dscore) # 仿射变换层的反向传播，得到LSTM层的梯度，形状为 (N, T, H)\n",
    "        dout = self.lstm.backward(dout) # LSTM层的反向传播，得到词嵌入层的梯度，形状为 (N, T, D)\n",
    "        dout = self.embed.backward(dout) # 词嵌入层的反向传播，得到输入的梯度，形状为 (N, T, D)\n",
    "        dh = self.lstm.dh # LSTM的隐藏状态梯度\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a358cbb",
   "metadata": {},
   "source": [
    "这里仅对反向传播进行一些补充说明。在 `backward()` 的实现中，从上方的 `Softmax with Loss` 层接收梯度 `dscore`，然后按 `Time Affine` 层、`Time LSTM` 层和 `Time Embedding` 层的顺序传播梯度。`Time LSTM` 层将时间方向上的梯度保存在 `Time LSTM` 层的成员变量 `dh` 中，因此取出时间方向上的梯度 `dh`，将其作为 `Decoder` 类的 `backward()` 的输出。\n",
    "\n",
    "如前所述，`Decoder` 类在学习时和在生成文本时的行为不同。上面的 `forward()` 方法是假定在学习时使用的。我们将 `Decoder` 类生成文本时的方法实现为 `generate()`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e033dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(self, h, start_id, sample_size):\n",
    "    sampled = [] # 采样的单词ID列表\n",
    "    sample_id = start_id # 当前采样的单词ID\n",
    "    self.lstm.set_state(h) # 设置LSTM的隐藏状态\n",
    "\n",
    "    for _ in range(sample_size):\n",
    "        x = np.array(sample_id).reshape((1, 1)) # 整理成形状为1 × 1的数组\n",
    "        out = self.embed.forward(x) # 词嵌入层的前向传播，形状为 (1, 1, D)\n",
    "        out = self.lstm.forward(out) # LSTM层的前向传播，形状为 (1, 1, H)\n",
    "        score = self.affine.forward(out) # 仿射变换层的前向传播，形状为 (1, 1, V)\n",
    "\n",
    "        sample_id = np.argmax(score.flatten()) # 选择概率最高的单词ID\n",
    "        sampled.append(int(sample_id)) # 将采样的单词ID添加到结果列表中\n",
    "\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d745aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词典大小、词向量维度、隐藏状态维度\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f') # 词嵌入矩阵\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f') # LSTM的输入权重\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f') # LSTM的隐藏状态权重\n",
    "        lstm_b = np.zeros(4 * H).astype('f') # LSTM的偏置\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f') # 仿射变换的权重\n",
    "        affine_b = np.zeros(V).astype('f')  # 仿射变换的偏置\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W) # 词嵌入层\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True) # LSTM层\n",
    "        self.affine = TimeAffine(affine_W, affine_b) # 仿射变换层\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h) # 设置LSTM的隐藏状态\n",
    "\n",
    "        out = self.embed.forward(xs) # 词嵌入层的前向传播，将单词ID转换为词向量，形状为 (N, T, D)\n",
    "        out = self.lstm.forward(out) # LSTM层的前向传播，形状为 (N, T, H)\n",
    "        score = self.affine.forward(out) # 仿射变换层的前向传播，形状为 (N, T, V)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore) # 仿射变换层的反向传播，得到LSTM层的梯度，形状为 (N, T, H)\n",
    "        dout = self.lstm.backward(dout) # LSTM层的反向传播，得到词嵌入层的梯度，形状为 (N, T, D)\n",
    "        dout = self.embed.backward(dout) # 词嵌入层的反向传播，得到输入的梯度，形状为 (N, T, D)\n",
    "        dh = self.lstm.dh # LSTM的隐藏状态梯度\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = [] # 采样的单词ID列表\n",
    "        sample_id = start_id # 当前采样的单词ID\n",
    "        self.lstm.set_state(h) # 设置LSTM的隐藏状态\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1)) # 整理成形状为1 × 1的数组\n",
    "            out = self.embed.forward(x) # 词嵌入层的前向传播，形状为 (1, 1, D)\n",
    "            out = self.lstm.forward(out) # LSTM层的前向传播，形状为 (1, 1, H)\n",
    "            score = self.affine.forward(out) # 仿射变换层的前向传播，形状为 (1, 1, V)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten()) # 选择概率最高的单词ID\n",
    "            sampled.append(int(sample_id)) # 将采样的单词ID添加到结果列表中\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e179edc",
   "metadata": {},
   "source": [
    "这个 `generate()` 方法有 3 个参数，分别是从编码器接收的隐藏状态 `h`、最开始输入的字符 ID `start_id` 和生成的字符数量 `sample_size`。这里重复如下操作：输入一个字符，选择 `Affine` 层输出的得分中最大值的字符 ID。以上就是 `Decoder` 类的实现。\n",
    "\n",
    "在这次的问题中，需要将编码器的输出h设定给解码器的Time LSTM层。此时，通过设置Time LSTM层为stateful，可以不重设隐藏状态，在保持编码器的h的同时，进行正向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc4ba8",
   "metadata": {},
   "source": [
    "## Seq2seq类\n",
    "最后来看 `Seq2seq` 类的实现。话虽如此，这里需要做的只是将 `Encoder` 类和 `Decoder` 类连接在一起，然后使用 `Time Softmax with Loss` 层计算损失而已。`Seq2seq` 类的实现如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d2ae2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词典大小、词向量维度、隐藏状态维度\n",
    "        self.encoder = Encoder(V, D, H) # 编码器\n",
    "        self.decoder = Decoder(V, D, H) # 解码器\n",
    "        self.softmax = TimeSoftmaxWithLoss() # 时序版Softmax损失层\n",
    " \n",
    "        self.params = self.encoder.params + self.decoder.params # 所有参数\n",
    "        self.grads = self.encoder.grads + self.decoder.grads # 所有梯度\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:] # 解码器的输入和目标\n",
    "\n",
    "        h = self.encoder.forward(xs) # 编码器的前向传播，获取隐藏状态\n",
    "        score = self.decoder.forward(decoder_xs, h) # 解码器的前向传播，计算得分\n",
    "        loss = self.softmax.forward(score, decoder_ts) # 计算损失\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout) # 反向传播通过Softmax损失层\n",
    "        dh = self.decoder.backward(dout) # 反向传播通过解码器\n",
    "        dout = self.encoder.backward(dh) # 反向传播通过编码器\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs) # 编码器的前向传播，获取隐藏状态\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size) # 解码器生成单词ID列表\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34eab1e",
   "metadata": {},
   "source": [
    "`Encoder` 和 `Decoder` 的各类中已经实现了主要的处理，因此这里只是将它们组合起来。以上就是 `Seq2seq` 类的实现。下面我们使用这个 `Seq2seq` 类，来挑战一下加法问题。\n",
    "\n",
    "## seq2seq的评价\n",
    "Seq2seq 的学习和基础神经网络的学习具有相同的流程。基础神经网络的学习流程如下：\n",
    "1. 从训练数据中选择一个 mini-batch\n",
    "2. 基于 mini-batch 计算梯度\n",
    "3. 使用梯度更新权重\n",
    "\n",
    "这里使用之前章节说明过的 `Trainer` 类进行上述操作。另外，seq2seq 针对每个 epoch 求解测试数据（生成字符串），并计算正确率。seq2seq 的学习代码如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50eaa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.56\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.53\n",
      "| epoch 1 |  iter 41 / 351 | time 0[s] | loss 2.17\n",
      "| epoch 1 |  iter 61 / 351 | time 1[s] | loss 1.96\n",
      "| epoch 1 |  iter 81 / 351 | time 1[s] | loss 1.92\n",
      "| epoch 1 |  iter 101 / 351 | time 2[s] | loss 1.87\n",
      "| epoch 1 |  iter 121 / 351 | time 2[s] | loss 1.85\n",
      "| epoch 1 |  iter 141 / 351 | time 3[s] | loss 1.83\n",
      "| epoch 1 |  iter 161 / 351 | time 3[s] | loss 1.79\n",
      "| epoch 1 |  iter 181 / 351 | time 3[s] | loss 1.77\n",
      "| epoch 1 |  iter 201 / 351 | time 4[s] | loss 1.77\n",
      "| epoch 1 |  iter 221 / 351 | time 4[s] | loss 1.76\n",
      "| epoch 1 |  iter 241 / 351 | time 5[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 5[s] | loss 1.76\n",
      "| epoch 1 |  iter 281 / 351 | time 6[s] | loss 1.75\n",
      "| epoch 1 |  iter 301 / 351 | time 6[s] | loss 1.74\n",
      "| epoch 1 |  iter 321 / 351 | time 6[s] | loss 1.75\n",
      "| epoch 1 |  iter 341 / 351 | time 7[s] | loss 1.74\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 1000\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 1000\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1000\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 1000\n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 100 \n",
      "---\n",
      "验证集准确率 0.180%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.74\n",
      "| epoch 2 |  iter 21 / 351 | time 0[s] | loss 1.73\n",
      "| epoch 2 |  iter 41 / 351 | time 0[s] | loss 1.74\n",
      "| epoch 2 |  iter 61 / 351 | time 1[s] | loss 1.74\n",
      "| epoch 2 |  iter 81 / 351 | time 1[s] | loss 1.73\n",
      "| epoch 2 |  iter 101 / 351 | time 2[s] | loss 1.73\n",
      "| epoch 2 |  iter 121 / 351 | time 2[s] | loss 1.72\n",
      "| epoch 2 |  iter 141 / 351 | time 2[s] | loss 1.71\n",
      "| epoch 2 |  iter 161 / 351 | time 3[s] | loss 1.71\n",
      "| epoch 2 |  iter 181 / 351 | time 3[s] | loss 1.71\n",
      "| epoch 2 |  iter 201 / 351 | time 4[s] | loss 1.70\n",
      "| epoch 2 |  iter 221 / 351 | time 4[s] | loss 1.71\n",
      "| epoch 2 |  iter 241 / 351 | time 4[s] | loss 1.70\n",
      "| epoch 2 |  iter 261 / 351 | time 5[s] | loss 1.69\n",
      "| epoch 2 |  iter 281 / 351 | time 5[s] | loss 1.69\n",
      "| epoch 2 |  iter 301 / 351 | time 6[s] | loss 1.69\n",
      "| epoch 2 |  iter 321 / 351 | time 6[s] | loss 1.68\n",
      "| epoch 2 |  iter 341 / 351 | time 7[s] | loss 1.67\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 994 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 400 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1544\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 400 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 400 \n",
      "---\n",
      "验证集准确率 0.220%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.66\n",
      "| epoch 3 |  iter 21 / 351 | time 0[s] | loss 1.66\n",
      "| epoch 3 |  iter 41 / 351 | time 0[s] | loss 1.65\n",
      "| epoch 3 |  iter 61 / 351 | time 1[s] | loss 1.63\n",
      "| epoch 3 |  iter 81 / 351 | time 1[s] | loss 1.62\n",
      "| epoch 3 |  iter 101 / 351 | time 2[s] | loss 1.62\n",
      "| epoch 3 |  iter 121 / 351 | time 2[s] | loss 1.60\n",
      "| epoch 3 |  iter 141 / 351 | time 2[s] | loss 1.59\n",
      "| epoch 3 |  iter 161 / 351 | time 3[s] | loss 1.57\n",
      "| epoch 3 |  iter 181 / 351 | time 3[s] | loss 1.57\n",
      "| epoch 3 |  iter 201 / 351 | time 4[s] | loss 1.56\n",
      "| epoch 3 |  iter 221 / 351 | time 4[s] | loss 1.54\n",
      "| epoch 3 |  iter 241 / 351 | time 5[s] | loss 1.52\n",
      "| epoch 3 |  iter 261 / 351 | time 5[s] | loss 1.52\n",
      "| epoch 3 |  iter 281 / 351 | time 5[s] | loss 1.52\n",
      "| epoch 3 |  iter 301 / 351 | time 6[s] | loss 1.50\n",
      "| epoch 3 |  iter 321 / 351 | time 6[s] | loss 1.49\n",
      "| epoch 3 |  iter 341 / 351 | time 7[s] | loss 1.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 108 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1001\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 648 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 138 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 448 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1373\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 348 \n",
      "---\n",
      "验证集准确率 0.560%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.47\n",
      "| epoch 4 |  iter 21 / 351 | time 0[s] | loss 1.46\n",
      "| epoch 4 |  iter 41 / 351 | time 0[s] | loss 1.44\n",
      "| epoch 4 |  iter 61 / 351 | time 1[s] | loss 1.43\n",
      "| epoch 4 |  iter 81 / 351 | time 1[s] | loss 1.42\n",
      "| epoch 4 |  iter 101 / 351 | time 2[s] | loss 1.41\n",
      "| epoch 4 |  iter 121 / 351 | time 3[s] | loss 1.40\n",
      "| epoch 4 |  iter 141 / 351 | time 4[s] | loss 1.40\n",
      "| epoch 4 |  iter 161 / 351 | time 5[s] | loss 1.38\n",
      "| epoch 4 |  iter 181 / 351 | time 6[s] | loss 1.38\n",
      "| epoch 4 |  iter 201 / 351 | time 7[s] | loss 1.37\n",
      "| epoch 4 |  iter 221 / 351 | time 8[s] | loss 1.35\n",
      "| epoch 4 |  iter 241 / 351 | time 10[s] | loss 1.33\n",
      "| epoch 4 |  iter 261 / 351 | time 11[s] | loss 1.33\n",
      "| epoch 4 |  iter 281 / 351 | time 12[s] | loss 1.33\n",
      "| epoch 4 |  iter 301 / 351 | time 13[s] | loss 1.32\n",
      "| epoch 4 |  iter 321 / 351 | time 14[s] | loss 1.31\n",
      "| epoch 4 |  iter 341 / 351 | time 15[s] | loss 1.30\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 146 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1189\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 866 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1002\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1406\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 202 \n",
      "---\n",
      "验证集准确率 1.060%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.28\n",
      "| epoch 5 |  iter 21 / 351 | time 1[s] | loss 1.29\n",
      "| epoch 5 |  iter 41 / 351 | time 2[s] | loss 1.28\n",
      "| epoch 5 |  iter 61 / 351 | time 3[s] | loss 1.27\n",
      "| epoch 5 |  iter 81 / 351 | time 4[s] | loss 1.27\n",
      "| epoch 5 |  iter 101 / 351 | time 5[s] | loss 1.26\n",
      "| epoch 5 |  iter 121 / 351 | time 6[s] | loss 1.26\n",
      "| epoch 5 |  iter 141 / 351 | time 7[s] | loss 1.27\n",
      "| epoch 5 |  iter 161 / 351 | time 8[s] | loss 1.26\n",
      "| epoch 5 |  iter 181 / 351 | time 9[s] | loss 1.25\n",
      "| epoch 5 |  iter 201 / 351 | time 11[s] | loss 1.23\n",
      "| epoch 5 |  iter 221 / 351 | time 12[s] | loss 1.22\n",
      "| epoch 5 |  iter 241 / 351 | time 13[s] | loss 1.21\n",
      "| epoch 5 |  iter 261 / 351 | time 14[s] | loss 1.21\n",
      "| epoch 5 |  iter 281 / 351 | time 15[s] | loss 1.21\n",
      "| epoch 5 |  iter 301 / 351 | time 16[s] | loss 1.20\n",
      "| epoch 5 |  iter 321 / 351 | time 17[s] | loss 1.19\n",
      "| epoch 5 |  iter 341 / 351 | time 18[s] | loss 1.18\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 145 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1168\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 192 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 431 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 895 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1015\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1493\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 891 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 221 \n",
      "---\n",
      "验证集准确率 2.260%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 1.17\n",
      "| epoch 6 |  iter 21 / 351 | time 1[s] | loss 1.17\n",
      "| epoch 6 |  iter 41 / 351 | time 2[s] | loss 1.18\n",
      "| epoch 6 |  iter 61 / 351 | time 3[s] | loss 1.17\n",
      "| epoch 6 |  iter 81 / 351 | time 4[s] | loss 1.16\n",
      "| epoch 6 |  iter 101 / 351 | time 5[s] | loss 1.16\n",
      "| epoch 6 |  iter 121 / 351 | time 6[s] | loss 1.15\n",
      "| epoch 6 |  iter 141 / 351 | time 7[s] | loss 1.14\n",
      "| epoch 6 |  iter 161 / 351 | time 8[s] | loss 1.14\n",
      "| epoch 6 |  iter 181 / 351 | time 9[s] | loss 1.13\n",
      "| epoch 6 |  iter 201 / 351 | time 10[s] | loss 1.19\n",
      "| epoch 6 |  iter 221 / 351 | time 12[s] | loss 1.19\n",
      "| epoch 6 |  iter 241 / 351 | time 13[s] | loss 1.17\n",
      "| epoch 6 |  iter 261 / 351 | time 14[s] | loss 1.13\n",
      "| epoch 6 |  iter 281 / 351 | time 15[s] | loss 1.12\n",
      "| epoch 6 |  iter 301 / 351 | time 16[s] | loss 1.11\n",
      "| epoch 6 |  iter 321 / 351 | time 17[s] | loss 1.11\n",
      "| epoch 6 |  iter 341 / 351 | time 18[s] | loss 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1169\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 660 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 412 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 846 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1412\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 846 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 207 \n",
      "---\n",
      "验证集准确率 2.720%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 1.11\n",
      "| epoch 7 |  iter 21 / 351 | time 1[s] | loss 1.10\n",
      "| epoch 7 |  iter 41 / 351 | time 2[s] | loss 1.09\n",
      "| epoch 7 |  iter 61 / 351 | time 3[s] | loss 1.10\n",
      "| epoch 7 |  iter 81 / 351 | time 4[s] | loss 1.10\n",
      "| epoch 7 |  iter 101 / 351 | time 5[s] | loss 1.10\n",
      "| epoch 7 |  iter 121 / 351 | time 6[s] | loss 1.09\n",
      "| epoch 7 |  iter 141 / 351 | time 7[s] | loss 1.08\n",
      "| epoch 7 |  iter 161 / 351 | time 8[s] | loss 1.08\n",
      "| epoch 7 |  iter 181 / 351 | time 9[s] | loss 1.07\n",
      "| epoch 7 |  iter 201 / 351 | time 10[s] | loss 1.07\n",
      "| epoch 7 |  iter 221 / 351 | time 12[s] | loss 1.07\n",
      "| epoch 7 |  iter 241 / 351 | time 13[s] | loss 1.05\n",
      "| epoch 7 |  iter 261 / 351 | time 13[s] | loss 1.06\n",
      "| epoch 7 |  iter 281 / 351 | time 14[s] | loss 1.08\n",
      "| epoch 7 |  iter 301 / 351 | time 15[s] | loss 1.07\n",
      "| epoch 7 |  iter 321 / 351 | time 16[s] | loss 1.05\n",
      "| epoch 7 |  iter 341 / 351 | time 17[s] | loss 1.05\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1166\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 418 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 893 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1058\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1465\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 228 \n",
      "---\n",
      "验证集准确率 3.280%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 1.09\n",
      "| epoch 8 |  iter 21 / 351 | time 1[s] | loss 1.06\n",
      "| epoch 8 |  iter 41 / 351 | time 2[s] | loss 1.06\n",
      "| epoch 8 |  iter 61 / 351 | time 3[s] | loss 1.03\n",
      "| epoch 8 |  iter 81 / 351 | time 4[s] | loss 1.03\n",
      "| epoch 8 |  iter 101 / 351 | time 5[s] | loss 1.05\n",
      "| epoch 8 |  iter 121 / 351 | time 6[s] | loss 1.04\n",
      "| epoch 8 |  iter 141 / 351 | time 7[s] | loss 1.04\n",
      "| epoch 8 |  iter 161 / 351 | time 8[s] | loss 1.08\n",
      "| epoch 8 |  iter 181 / 351 | time 9[s] | loss 1.06\n",
      "| epoch 8 |  iter 201 / 351 | time 10[s] | loss 1.06\n",
      "| epoch 8 |  iter 221 / 351 | time 11[s] | loss 1.05\n",
      "| epoch 8 |  iter 241 / 351 | time 13[s] | loss 1.02\n",
      "| epoch 8 |  iter 261 / 351 | time 14[s] | loss 1.02\n",
      "| epoch 8 |  iter 281 / 351 | time 15[s] | loss 1.02\n",
      "| epoch 8 |  iter 301 / 351 | time 16[s] | loss 1.01\n",
      "| epoch 8 |  iter 321 / 351 | time 17[s] | loss 1.02\n",
      "| epoch 8 |  iter 341 / 351 | time 18[s] | loss 1.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1166\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 681 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 158 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 411 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1073\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1449\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 227 \n",
      "---\n",
      "验证集准确率 4.000%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 1.04\n",
      "| epoch 9 |  iter 21 / 351 | time 1[s] | loss 1.04\n",
      "| epoch 9 |  iter 41 / 351 | time 2[s] | loss 1.03\n",
      "| epoch 9 |  iter 61 / 351 | time 3[s] | loss 1.03\n",
      "| epoch 9 |  iter 81 / 351 | time 4[s] | loss 1.00\n",
      "| epoch 9 |  iter 101 / 351 | time 5[s] | loss 0.99\n",
      "| epoch 9 |  iter 121 / 351 | time 6[s] | loss 1.01\n",
      "| epoch 9 |  iter 141 / 351 | time 7[s] | loss 1.00\n",
      "| epoch 9 |  iter 161 / 351 | time 8[s] | loss 0.99\n",
      "| epoch 9 |  iter 181 / 351 | time 9[s] | loss 0.99\n",
      "| epoch 9 |  iter 201 / 351 | time 11[s] | loss 0.98\n",
      "| epoch 9 |  iter 221 / 351 | time 12[s] | loss 0.99\n",
      "| epoch 9 |  iter 241 / 351 | time 13[s] | loss 1.00\n",
      "| epoch 9 |  iter 261 / 351 | time 14[s] | loss 1.02\n",
      "| epoch 9 |  iter 281 / 351 | time 15[s] | loss 1.01\n",
      "| epoch 9 |  iter 301 / 351 | time 16[s] | loss 1.00\n",
      "| epoch 9 |  iter 321 / 351 | time 17[s] | loss 0.98\n",
      "| epoch 9 |  iter 341 / 351 | time 18[s] | loss 0.97\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1128\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 158 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 418 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 858 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 228 \n",
      "---\n",
      "验证集准确率 5.160%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.95\n",
      "| epoch 10 |  iter 21 / 351 | time 1[s] | loss 0.96\n",
      "| epoch 10 |  iter 41 / 351 | time 2[s] | loss 0.96\n",
      "| epoch 10 |  iter 61 / 351 | time 3[s] | loss 0.97\n",
      "| epoch 10 |  iter 81 / 351 | time 4[s] | loss 0.96\n",
      "| epoch 10 |  iter 101 / 351 | time 5[s] | loss 0.98\n",
      "| epoch 10 |  iter 121 / 351 | time 6[s] | loss 0.98\n",
      "| epoch 10 |  iter 141 / 351 | time 7[s] | loss 0.97\n",
      "| epoch 10 |  iter 161 / 351 | time 8[s] | loss 0.96\n",
      "| epoch 10 |  iter 181 / 351 | time 9[s] | loss 0.97\n",
      "| epoch 10 |  iter 201 / 351 | time 10[s] | loss 0.96\n",
      "| epoch 10 |  iter 221 / 351 | time 11[s] | loss 0.95\n",
      "| epoch 10 |  iter 241 / 351 | time 13[s] | loss 0.95\n",
      "| epoch 10 |  iter 261 / 351 | time 14[s] | loss 0.96\n",
      "| epoch 10 |  iter 281 / 351 | time 15[s] | loss 0.96\n",
      "| epoch 10 |  iter 301 / 351 | time 16[s] | loss 1.01\n",
      "| epoch 10 |  iter 321 / 351 | time 17[s] | loss 0.97\n",
      "| epoch 10 |  iter 341 / 351 | time 18[s] | loss 0.95\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1160\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 660 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 170 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 865 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 240 \n",
      "---\n",
      "验证集准确率 6.020%\n",
      "| epoch 11 |  iter 1 / 351 | time 0[s] | loss 0.93\n",
      "| epoch 11 |  iter 21 / 351 | time 1[s] | loss 0.95\n",
      "| epoch 11 |  iter 41 / 351 | time 2[s] | loss 0.95\n",
      "| epoch 11 |  iter 61 / 351 | time 3[s] | loss 0.97\n",
      "| epoch 11 |  iter 81 / 351 | time 4[s] | loss 0.94\n",
      "| epoch 11 |  iter 101 / 351 | time 5[s] | loss 0.95\n",
      "| epoch 11 |  iter 121 / 351 | time 6[s] | loss 0.95\n",
      "| epoch 11 |  iter 141 / 351 | time 7[s] | loss 0.97\n",
      "| epoch 11 |  iter 161 / 351 | time 8[s] | loss 0.95\n",
      "| epoch 11 |  iter 181 / 351 | time 9[s] | loss 0.94\n",
      "| epoch 11 |  iter 201 / 351 | time 10[s] | loss 0.93\n",
      "| epoch 11 |  iter 221 / 351 | time 11[s] | loss 0.96\n",
      "| epoch 11 |  iter 241 / 351 | time 12[s] | loss 0.95\n",
      "| epoch 11 |  iter 261 / 351 | time 13[s] | loss 0.94\n",
      "| epoch 11 |  iter 281 / 351 | time 14[s] | loss 0.93\n",
      "| epoch 11 |  iter 301 / 351 | time 15[s] | loss 0.93\n",
      "| epoch 11 |  iter 321 / 351 | time 17[s] | loss 0.94\n",
      "| epoch 11 |  iter 341 / 351 | time 18[s] | loss 0.94\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1121\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 858 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 219 \n",
      "---\n",
      "验证集准确率 6.260%\n",
      "| epoch 12 |  iter 1 / 351 | time 0[s] | loss 0.93\n",
      "| epoch 12 |  iter 21 / 351 | time 0[s] | loss 0.92\n",
      "| epoch 12 |  iter 41 / 351 | time 1[s] | loss 0.92\n",
      "| epoch 12 |  iter 61 / 351 | time 2[s] | loss 0.93\n",
      "| epoch 12 |  iter 81 / 351 | time 3[s] | loss 0.92\n",
      "| epoch 12 |  iter 101 / 351 | time 4[s] | loss 0.92\n",
      "| epoch 12 |  iter 121 / 351 | time 5[s] | loss 0.92\n",
      "| epoch 12 |  iter 141 / 351 | time 6[s] | loss 0.92\n",
      "| epoch 12 |  iter 161 / 351 | time 6[s] | loss 0.91\n",
      "| epoch 12 |  iter 181 / 351 | time 7[s] | loss 0.92\n",
      "| epoch 12 |  iter 201 / 351 | time 8[s] | loss 0.94\n",
      "| epoch 12 |  iter 221 / 351 | time 9[s] | loss 0.93\n",
      "| epoch 12 |  iter 241 / 351 | time 10[s] | loss 0.91\n",
      "| epoch 12 |  iter 261 / 351 | time 11[s] | loss 0.94\n",
      "| epoch 12 |  iter 281 / 351 | time 12[s] | loss 0.97\n",
      "| epoch 12 |  iter 301 / 351 | time 13[s] | loss 0.91\n",
      "| epoch 12 |  iter 321 / 351 | time 14[s] | loss 0.92\n",
      "| epoch 12 |  iter 341 / 351 | time 15[s] | loss 0.91\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1124\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 671 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 229 \n",
      "---\n",
      "验证集准确率 7.440%\n",
      "| epoch 13 |  iter 1 / 351 | time 0[s] | loss 0.89\n",
      "| epoch 13 |  iter 21 / 351 | time 1[s] | loss 0.93\n",
      "| epoch 13 |  iter 41 / 351 | time 1[s] | loss 0.93\n",
      "| epoch 13 |  iter 61 / 351 | time 2[s] | loss 0.93\n",
      "| epoch 13 |  iter 81 / 351 | time 4[s] | loss 0.96\n",
      "| epoch 13 |  iter 101 / 351 | time 4[s] | loss 0.93\n",
      "| epoch 13 |  iter 121 / 351 | time 6[s] | loss 0.93\n",
      "| epoch 13 |  iter 141 / 351 | time 7[s] | loss 0.92\n",
      "| epoch 13 |  iter 161 / 351 | time 7[s] | loss 0.94\n",
      "| epoch 13 |  iter 181 / 351 | time 8[s] | loss 0.92\n",
      "| epoch 13 |  iter 201 / 351 | time 8[s] | loss 0.89\n",
      "| epoch 13 |  iter 221 / 351 | time 9[s] | loss 0.88\n",
      "| epoch 13 |  iter 241 / 351 | time 9[s] | loss 0.92\n",
      "| epoch 13 |  iter 261 / 351 | time 9[s] | loss 0.96\n",
      "| epoch 13 |  iter 281 / 351 | time 10[s] | loss 0.91\n",
      "| epoch 13 |  iter 301 / 351 | time 10[s] | loss 0.93\n",
      "| epoch 13 |  iter 321 / 351 | time 11[s] | loss 0.90\n",
      "| epoch 13 |  iter 341 / 351 | time 11[s] | loss 0.92\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1121\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 659 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1019\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 859 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 239 \n",
      "---\n",
      "验证集准确率 4.360%\n",
      "| epoch 14 |  iter 1 / 351 | time 0[s] | loss 0.94\n",
      "| epoch 14 |  iter 21 / 351 | time 0[s] | loss 0.88\n",
      "| epoch 14 |  iter 41 / 351 | time 0[s] | loss 0.89\n",
      "| epoch 14 |  iter 61 / 351 | time 1[s] | loss 0.90\n",
      "| epoch 14 |  iter 81 / 351 | time 1[s] | loss 0.92\n",
      "| epoch 14 |  iter 101 / 351 | time 2[s] | loss 0.91\n",
      "| epoch 14 |  iter 121 / 351 | time 2[s] | loss 0.88\n",
      "| epoch 14 |  iter 141 / 351 | time 2[s] | loss 0.89\n",
      "| epoch 14 |  iter 161 / 351 | time 3[s] | loss 0.89\n",
      "| epoch 14 |  iter 181 / 351 | time 3[s] | loss 0.88\n",
      "| epoch 14 |  iter 201 / 351 | time 4[s] | loss 0.90\n",
      "| epoch 14 |  iter 221 / 351 | time 4[s] | loss 0.91\n",
      "| epoch 14 |  iter 241 / 351 | time 4[s] | loss 0.88\n",
      "| epoch 14 |  iter 261 / 351 | time 5[s] | loss 0.89\n",
      "| epoch 14 |  iter 281 / 351 | time 6[s] | loss 0.88\n",
      "| epoch 14 |  iter 301 / 351 | time 6[s] | loss 0.91\n",
      "| epoch 14 |  iter 321 / 351 | time 7[s] | loss 0.92\n",
      "| epoch 14 |  iter 341 / 351 | time 7[s] | loss 0.90\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1128\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 685 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 172 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 425 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1072\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 875 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 245 \n",
      "---\n",
      "验证集准确率 4.840%\n",
      "| epoch 15 |  iter 1 / 351 | time 0[s] | loss 0.88\n",
      "| epoch 15 |  iter 21 / 351 | time 0[s] | loss 0.89\n",
      "| epoch 15 |  iter 41 / 351 | time 1[s] | loss 0.88\n",
      "| epoch 15 |  iter 61 / 351 | time 1[s] | loss 0.91\n",
      "| epoch 15 |  iter 81 / 351 | time 2[s] | loss 0.89\n",
      "| epoch 15 |  iter 101 / 351 | time 2[s] | loss 0.87\n",
      "| epoch 15 |  iter 121 / 351 | time 3[s] | loss 0.89\n",
      "| epoch 15 |  iter 141 / 351 | time 3[s] | loss 0.89\n",
      "| epoch 15 |  iter 161 / 351 | time 4[s] | loss 0.89\n",
      "| epoch 15 |  iter 181 / 351 | time 4[s] | loss 0.90\n",
      "| epoch 15 |  iter 201 / 351 | time 5[s] | loss 0.87\n",
      "| epoch 15 |  iter 221 / 351 | time 5[s] | loss 0.87\n",
      "| epoch 15 |  iter 241 / 351 | time 6[s] | loss 0.87\n",
      "| epoch 15 |  iter 261 / 351 | time 6[s] | loss 0.88\n",
      "| epoch 15 |  iter 281 / 351 | time 7[s] | loss 0.86\n",
      "| epoch 15 |  iter 301 / 351 | time 8[s] | loss 0.87\n",
      "| epoch 15 |  iter 321 / 351 | time 8[s] | loss 0.86\n",
      "| epoch 15 |  iter 341 / 351 | time 9[s] | loss 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1136\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 424 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 862 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 242 \n",
      "---\n",
      "验证集准确率 7.680%\n",
      "| epoch 16 |  iter 1 / 351 | time 0[s] | loss 0.84\n",
      "| epoch 16 |  iter 21 / 351 | time 0[s] | loss 0.86\n",
      "| epoch 16 |  iter 41 / 351 | time 1[s] | loss 0.86\n",
      "| epoch 16 |  iter 61 / 351 | time 1[s] | loss 0.90\n",
      "| epoch 16 |  iter 81 / 351 | time 2[s] | loss 0.89\n",
      "| epoch 16 |  iter 101 / 351 | time 2[s] | loss 0.87\n",
      "| epoch 16 |  iter 121 / 351 | time 3[s] | loss 0.88\n",
      "| epoch 16 |  iter 141 / 351 | time 3[s] | loss 0.88\n",
      "| epoch 16 |  iter 161 / 351 | time 4[s] | loss 0.88\n",
      "| epoch 16 |  iter 181 / 351 | time 4[s] | loss 0.88\n",
      "| epoch 16 |  iter 201 / 351 | time 5[s] | loss 0.88\n",
      "| epoch 16 |  iter 221 / 351 | time 5[s] | loss 0.85\n",
      "| epoch 16 |  iter 241 / 351 | time 6[s] | loss 0.85\n",
      "| epoch 16 |  iter 261 / 351 | time 7[s] | loss 0.85\n",
      "| epoch 16 |  iter 281 / 351 | time 7[s] | loss 0.84\n",
      "| epoch 16 |  iter 301 / 351 | time 8[s] | loss 0.85\n",
      "| epoch 16 |  iter 321 / 351 | time 8[s] | loss 0.84\n",
      "| epoch 16 |  iter 341 / 351 | time 9[s] | loss 0.86\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 159 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1126\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 155 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 412 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 846 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1039\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 858 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 227 \n",
      "---\n",
      "验证集准确率 2.260%\n",
      "| epoch 17 |  iter 1 / 351 | time 0[s] | loss 0.95\n",
      "| epoch 17 |  iter 21 / 351 | time 0[s] | loss 0.87\n",
      "| epoch 17 |  iter 41 / 351 | time 1[s] | loss 0.88\n",
      "| epoch 17 |  iter 61 / 351 | time 1[s] | loss 0.87\n",
      "| epoch 17 |  iter 81 / 351 | time 2[s] | loss 0.87\n",
      "| epoch 17 |  iter 101 / 351 | time 2[s] | loss 0.86\n",
      "| epoch 17 |  iter 121 / 351 | time 3[s] | loss 0.84\n",
      "| epoch 17 |  iter 141 / 351 | time 3[s] | loss 0.88\n",
      "| epoch 17 |  iter 161 / 351 | time 4[s] | loss 0.87\n",
      "| epoch 17 |  iter 181 / 351 | time 4[s] | loss 0.86\n",
      "| epoch 17 |  iter 201 / 351 | time 5[s] | loss 0.84\n",
      "| epoch 17 |  iter 221 / 351 | time 5[s] | loss 0.83\n",
      "| epoch 17 |  iter 241 / 351 | time 6[s] | loss 0.84\n",
      "| epoch 17 |  iter 261 / 351 | time 6[s] | loss 0.83\n",
      "| epoch 17 |  iter 281 / 351 | time 7[s] | loss 0.83\n",
      "| epoch 17 |  iter 301 / 351 | time 8[s] | loss 0.83\n",
      "| epoch 17 |  iter 321 / 351 | time 8[s] | loss 0.84\n",
      "| epoch 17 |  iter 341 / 351 | time 9[s] | loss 0.83\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1128\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 412 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 867 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 229 \n",
      "---\n",
      "验证集准确率 8.140%\n",
      "| epoch 18 |  iter 1 / 351 | time 0[s] | loss 0.87\n",
      "| epoch 18 |  iter 21 / 351 | time 0[s] | loss 0.83\n",
      "| epoch 18 |  iter 41 / 351 | time 1[s] | loss 0.84\n",
      "| epoch 18 |  iter 61 / 351 | time 1[s] | loss 0.84\n",
      "| epoch 18 |  iter 81 / 351 | time 2[s] | loss 0.84\n",
      "| epoch 18 |  iter 101 / 351 | time 2[s] | loss 0.84\n",
      "| epoch 18 |  iter 121 / 351 | time 3[s] | loss 0.91\n",
      "| epoch 18 |  iter 141 / 351 | time 3[s] | loss 0.87\n",
      "| epoch 18 |  iter 161 / 351 | time 4[s] | loss 0.83\n",
      "| epoch 18 |  iter 181 / 351 | time 4[s] | loss 0.85\n",
      "| epoch 18 |  iter 201 / 351 | time 5[s] | loss 0.86\n",
      "| epoch 18 |  iter 221 / 351 | time 5[s] | loss 0.86\n",
      "| epoch 18 |  iter 241 / 351 | time 6[s] | loss 0.85\n",
      "| epoch 18 |  iter 261 / 351 | time 6[s] | loss 0.83\n",
      "| epoch 18 |  iter 281 / 351 | time 7[s] | loss 0.83\n",
      "| epoch 18 |  iter 301 / 351 | time 7[s] | loss 0.82\n",
      "| epoch 18 |  iter 321 / 351 | time 8[s] | loss 0.85\n",
      "| epoch 18 |  iter 341 / 351 | time 9[s] | loss 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 867 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 869 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 237 \n",
      "---\n",
      "验证集准确率 10.300%\n",
      "| epoch 19 |  iter 1 / 351 | time 0[s] | loss 0.79\n",
      "| epoch 19 |  iter 21 / 351 | time 0[s] | loss 0.80\n",
      "| epoch 19 |  iter 41 / 351 | time 1[s] | loss 0.81\n",
      "| epoch 19 |  iter 61 / 351 | time 1[s] | loss 0.84\n",
      "| epoch 19 |  iter 81 / 351 | time 2[s] | loss 0.86\n",
      "| epoch 19 |  iter 101 / 351 | time 2[s] | loss 0.81\n",
      "| epoch 19 |  iter 121 / 351 | time 3[s] | loss 0.80\n",
      "| epoch 19 |  iter 141 / 351 | time 3[s] | loss 0.83\n",
      "| epoch 19 |  iter 161 / 351 | time 4[s] | loss 0.82\n",
      "| epoch 19 |  iter 181 / 351 | time 4[s] | loss 0.81\n",
      "| epoch 19 |  iter 201 / 351 | time 5[s] | loss 0.82\n",
      "| epoch 19 |  iter 221 / 351 | time 5[s] | loss 0.81\n",
      "| epoch 19 |  iter 241 / 351 | time 6[s] | loss 0.84\n",
      "| epoch 19 |  iter 261 / 351 | time 6[s] | loss 0.83\n",
      "| epoch 19 |  iter 281 / 351 | time 7[s] | loss 0.83\n",
      "| epoch 19 |  iter 301 / 351 | time 8[s] | loss 0.85\n",
      "| epoch 19 |  iter 321 / 351 | time 8[s] | loss 0.82\n",
      "| epoch 19 |  iter 341 / 351 | time 9[s] | loss 0.83\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1127\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 846 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1047\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1404\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 244 \n",
      "---\n",
      "验证集准确率 6.760%\n",
      "| epoch 20 |  iter 1 / 351 | time 0[s] | loss 0.83\n",
      "| epoch 20 |  iter 21 / 351 | time 0[s] | loss 0.81\n",
      "| epoch 20 |  iter 41 / 351 | time 1[s] | loss 0.85\n",
      "| epoch 20 |  iter 61 / 351 | time 1[s] | loss 0.82\n",
      "| epoch 20 |  iter 81 / 351 | time 2[s] | loss 0.82\n",
      "| epoch 20 |  iter 101 / 351 | time 2[s] | loss 0.80\n",
      "| epoch 20 |  iter 121 / 351 | time 3[s] | loss 0.81\n",
      "| epoch 20 |  iter 141 / 351 | time 3[s] | loss 0.82\n",
      "| epoch 20 |  iter 161 / 351 | time 4[s] | loss 0.84\n",
      "| epoch 20 |  iter 181 / 351 | time 4[s] | loss 0.82\n",
      "| epoch 20 |  iter 201 / 351 | time 5[s] | loss 0.82\n",
      "| epoch 20 |  iter 221 / 351 | time 6[s] | loss 0.80\n",
      "| epoch 20 |  iter 241 / 351 | time 6[s] | loss 0.80\n",
      "| epoch 20 |  iter 261 / 351 | time 7[s] | loss 0.81\n",
      "| epoch 20 |  iter 281 / 351 | time 7[s] | loss 0.81\n",
      "| epoch 20 |  iter 301 / 351 | time 8[s] | loss 0.80\n",
      "| epoch 20 |  iter 321 / 351 | time 8[s] | loss 0.84\n",
      "| epoch 20 |  iter 341 / 351 | time 9[s] | loss 0.81\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 670 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1424\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 870 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 239 \n",
      "---\n",
      "验证集准确率 11.080%\n",
      "| epoch 21 |  iter 1 / 351 | time 0[s] | loss 0.77\n",
      "| epoch 21 |  iter 21 / 351 | time 0[s] | loss 0.81\n",
      "| epoch 21 |  iter 41 / 351 | time 1[s] | loss 0.79\n",
      "| epoch 21 |  iter 61 / 351 | time 1[s] | loss 0.79\n",
      "| epoch 21 |  iter 81 / 351 | time 2[s] | loss 0.83\n",
      "| epoch 21 |  iter 101 / 351 | time 2[s] | loss 0.93\n",
      "| epoch 21 |  iter 121 / 351 | time 3[s] | loss 0.90\n",
      "| epoch 21 |  iter 141 / 351 | time 3[s] | loss 0.89\n",
      "| epoch 21 |  iter 161 / 351 | time 4[s] | loss 0.84\n",
      "| epoch 21 |  iter 181 / 351 | time 5[s] | loss 0.83\n",
      "| epoch 21 |  iter 201 / 351 | time 5[s] | loss 0.81\n",
      "| epoch 21 |  iter 221 / 351 | time 6[s] | loss 0.79\n",
      "| epoch 21 |  iter 241 / 351 | time 6[s] | loss 0.78\n",
      "| epoch 21 |  iter 261 / 351 | time 7[s] | loss 0.78\n",
      "| epoch 21 |  iter 281 / 351 | time 7[s] | loss 0.83\n",
      "| epoch 21 |  iter 301 / 351 | time 8[s] | loss 0.84\n",
      "| epoch 21 |  iter 321 / 351 | time 9[s] | loss 0.83\n",
      "| epoch 21 |  iter 341 / 351 | time 9[s] | loss 0.81\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 417 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1404\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 852 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 235 \n",
      "---\n",
      "验证集准确率 7.760%\n",
      "| epoch 22 |  iter 1 / 351 | time 0[s] | loss 0.82\n",
      "| epoch 22 |  iter 21 / 351 | time 0[s] | loss 0.79\n",
      "| epoch 22 |  iter 41 / 351 | time 1[s] | loss 0.80\n",
      "| epoch 22 |  iter 61 / 351 | time 1[s] | loss 0.79\n",
      "| epoch 22 |  iter 81 / 351 | time 2[s] | loss 0.82\n",
      "| epoch 22 |  iter 101 / 351 | time 2[s] | loss 0.80\n",
      "| epoch 22 |  iter 121 / 351 | time 3[s] | loss 0.79\n",
      "| epoch 22 |  iter 141 / 351 | time 3[s] | loss 0.79\n",
      "| epoch 22 |  iter 161 / 351 | time 4[s] | loss 0.82\n",
      "| epoch 22 |  iter 181 / 351 | time 4[s] | loss 0.83\n",
      "| epoch 22 |  iter 201 / 351 | time 5[s] | loss 0.81\n",
      "| epoch 22 |  iter 221 / 351 | time 5[s] | loss 0.81\n",
      "| epoch 22 |  iter 241 / 351 | time 6[s] | loss 0.79\n",
      "| epoch 22 |  iter 261 / 351 | time 6[s] | loss 0.77\n",
      "| epoch 22 |  iter 281 / 351 | time 7[s] | loss 0.79\n",
      "| epoch 22 |  iter 301 / 351 | time 7[s] | loss 0.80\n",
      "| epoch 22 |  iter 321 / 351 | time 8[s] | loss 0.80\n",
      "| epoch 22 |  iter 341 / 351 | time 9[s] | loss 0.78\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1150\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 167 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 427 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 850 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 242 \n",
      "---\n",
      "验证集准确率 8.840%\n",
      "| epoch 23 |  iter 1 / 351 | time 0[s] | loss 0.76\n",
      "| epoch 23 |  iter 21 / 351 | time 0[s] | loss 0.81\n",
      "| epoch 23 |  iter 41 / 351 | time 1[s] | loss 0.78\n",
      "| epoch 23 |  iter 61 / 351 | time 1[s] | loss 0.78\n",
      "| epoch 23 |  iter 81 / 351 | time 2[s] | loss 0.77\n",
      "| epoch 23 |  iter 101 / 351 | time 2[s] | loss 0.78\n",
      "| epoch 23 |  iter 121 / 351 | time 3[s] | loss 0.81\n",
      "| epoch 23 |  iter 141 / 351 | time 3[s] | loss 0.77\n",
      "| epoch 23 |  iter 161 / 351 | time 4[s] | loss 0.77\n",
      "| epoch 23 |  iter 181 / 351 | time 4[s] | loss 0.78\n",
      "| epoch 23 |  iter 201 / 351 | time 5[s] | loss 0.78\n",
      "| epoch 23 |  iter 221 / 351 | time 5[s] | loss 0.78\n",
      "| epoch 23 |  iter 241 / 351 | time 6[s] | loss 0.80\n",
      "| epoch 23 |  iter 261 / 351 | time 6[s] | loss 0.83\n",
      "| epoch 23 |  iter 281 / 351 | time 7[s] | loss 0.86\n",
      "| epoch 23 |  iter 301 / 351 | time 8[s] | loss 0.80\n",
      "| epoch 23 |  iter 321 / 351 | time 8[s] | loss 0.79\n",
      "| epoch 23 |  iter 341 / 351 | time 9[s] | loss 0.77\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1130\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1404\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 860 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 235 \n",
      "---\n",
      "验证集准确率 11.740%\n",
      "| epoch 24 |  iter 1 / 351 | time 0[s] | loss 0.72\n",
      "| epoch 24 |  iter 21 / 351 | time 0[s] | loss 0.78\n",
      "| epoch 24 |  iter 41 / 351 | time 1[s] | loss 0.77\n",
      "| epoch 24 |  iter 61 / 351 | time 1[s] | loss 0.78\n",
      "| epoch 24 |  iter 81 / 351 | time 2[s] | loss 0.76\n",
      "| epoch 24 |  iter 101 / 351 | time 2[s] | loss 0.78\n",
      "| epoch 24 |  iter 121 / 351 | time 3[s] | loss 0.79\n",
      "| epoch 24 |  iter 141 / 351 | time 3[s] | loss 0.81\n",
      "| epoch 24 |  iter 161 / 351 | time 4[s] | loss 0.81\n",
      "| epoch 24 |  iter 181 / 351 | time 4[s] | loss 0.77\n",
      "| epoch 24 |  iter 201 / 351 | time 5[s] | loss 0.77\n",
      "| epoch 24 |  iter 221 / 351 | time 5[s] | loss 0.77\n",
      "| epoch 24 |  iter 241 / 351 | time 6[s] | loss 0.75\n",
      "| epoch 24 |  iter 261 / 351 | time 6[s] | loss 0.77\n",
      "| epoch 24 |  iter 281 / 351 | time 7[s] | loss 0.77\n",
      "| epoch 24 |  iter 301 / 351 | time 7[s] | loss 0.76\n",
      "| epoch 24 |  iter 321 / 351 | time 8[s] | loss 0.78\n",
      "| epoch 24 |  iter 341 / 351 | time 9[s] | loss 0.76\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1141\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 417 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 229 \n",
      "---\n",
      "验证集准确率 11.540%\n",
      "| epoch 25 |  iter 1 / 351 | time 0[s] | loss 0.72\n",
      "| epoch 25 |  iter 21 / 351 | time 0[s] | loss 0.75\n",
      "| epoch 25 |  iter 41 / 351 | time 1[s] | loss 0.75\n",
      "| epoch 25 |  iter 61 / 351 | time 1[s] | loss 0.77\n",
      "| epoch 25 |  iter 81 / 351 | time 2[s] | loss 0.79\n",
      "| epoch 25 |  iter 101 / 351 | time 2[s] | loss 0.80\n",
      "| epoch 25 |  iter 121 / 351 | time 3[s] | loss 0.79\n",
      "| epoch 25 |  iter 141 / 351 | time 3[s] | loss 0.79\n",
      "| epoch 25 |  iter 161 / 351 | time 4[s] | loss 0.79\n",
      "| epoch 25 |  iter 181 / 351 | time 4[s] | loss 0.79\n",
      "| epoch 25 |  iter 201 / 351 | time 5[s] | loss 0.78\n",
      "| epoch 25 |  iter 221 / 351 | time 5[s] | loss 0.78\n",
      "| epoch 25 |  iter 241 / 351 | time 6[s] | loss 0.80\n",
      "| epoch 25 |  iter 261 / 351 | time 6[s] | loss 0.78\n",
      "| epoch 25 |  iter 281 / 351 | time 7[s] | loss 0.78\n",
      "| epoch 25 |  iter 301 / 351 | time 7[s] | loss 0.79\n",
      "| epoch 25 |  iter 321 / 351 | time 8[s] | loss 0.79\n",
      "| epoch 25 |  iter 341 / 351 | time 9[s] | loss 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1136\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 671 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 426 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1049\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1418\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 869 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 246 \n",
      "---\n",
      "验证集准确率 7.820%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # 忽略警告信息\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "# 读入数据集\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt') # 读取加法运算数据集\n",
    "char_to_id, id_to_char = sequence.get_vocab() # 获取字符和ID的对应关系\n",
    "\n",
    "# 是否反转输入序列（有时反转输入可以提高Seq2Seq模型的性能）\n",
    "is_reverse = False  # 可以改为True尝试\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1] # 反转输入序列，[:: -1]表示步长为-1，即从后向前取元素\n",
    "# =========================================================\n",
    "\n",
    "# 设定超参数\n",
    "vocab_size = len(char_to_id) # 词典大小\n",
    "wordvec_size = 16 # 词向量维度\n",
    "hidden_size = 128 # 隐藏状态维度\n",
    "batch_size = 128 # 批量大小\n",
    "max_epoch = 25 # 最大训练轮数\n",
    "max_grad = 5.0 # 用于梯度裁剪的阈值\n",
    "\n",
    "# 选择使用基础Seq2Seq还是Peeky Seq2Seq模型 ========================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# ================================================================\n",
    "optimizer = Adam() # Adam优化器\n",
    "trainer = Trainer(model, optimizer) # 训练器\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad) # 训练一个epoch\n",
    "\n",
    "    correct_num = 0 # 预测正确的样本数\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]] # 取出一个样本，question的形状为(1, 7)，correct的形状为(1, 5)\n",
    "        verbose = i < 10 # 前10个样本打印详细信息\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse) # 评估样本\n",
    "\n",
    "    acc = float(correct_num) / len(x_test) # 计算准确率\n",
    "    acc_list.append(acc) # 记录准确率\n",
    "    print('验证集准确率 %.3f%%' % (acc * 100)) # 打印验证集准确率\n",
    "\n",
    "# 绘制图形\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('训练轮数')\n",
    "plt.ylabel('验证集准确率')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b8fa1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Embedding层的维度（即词向量维度）与词典大小之间并没有“必须更小”的严格规则，两者的关系需要结合具体任务和数据特点来分析：\n",
    "\n",
    "### 1. 通常情况：词向量维度 < 词典大小\n",
    "在大多数NLP任务中（如文本分类、机器翻译），我们会看到词向量维度（如128、256）远小于词典大小（如几万、几十万）。这是因为：\n",
    "- **降维作用**：Embedding层的核心功能之一是将高维离散的词ID（维度等于词典大小）映射到低维连续空间，用更紧凑的向量表达语义，减少计算量。\n",
    "- **泛化能力**：低维向量能更好地学习词与词之间的关联（如“国王-男人+女人≈女王”），而高维向量容易过拟合到具体词语。\n",
    "\n",
    "比如代码中的加法任务：\n",
    "- 词典大小（`vocab_size`）很小（可能只有0-9、+、=等十几个字符）\n",
    "- 词向量维度（16）略大于词典大小，但依然合理（因为任务简单，不需要严格降维）\n",
    "\n",
    "\n",
    "### 2. 特殊情况：词向量维度 ≥ 词典大小\n",
    "在以下场景中，词向量维度可以等于或大于词典大小：\n",
    "- **小词典任务**：当词典规模很小（如代码中的加法问题，只有十几个字符），词向量维度稍大（如16）反而能提升表达能力，且不会增加太多计算成本。\n",
    "- **需要精细区分的场景**：如果词语之间的差异非常重要（如专业术语库），较大的词向量维度可以保留更多细节。\n",
    "- **预训练模型**：某些预训练Embedding（如GloVe的大尺寸版本）可能会使用与词典大小接近的维度（如40万词对应300维）。\n",
    "\n",
    "\n",
    "### 总结\n",
    "词向量维度与词典大小的关系不是绝对的，核心原则是：\n",
    "- **小词典任务**：维度可以接近或略大于词典大小（只要不引发过拟合）\n",
    "- **大词典任务**：维度通常远小于词典大小（兼顾效率和泛化能力）\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab772d98",
   "metadata": {},
   "source": [
    "这里显示的代码和基础神经网络的学习用代码是一样的，不过这里采用正确率（正确回答了多少问题）作为评价指标。具体来说，就是针对每个 epoch 对正确回答了测试数据中的多少问题进行统计。\n",
    "\n",
    "为了测量上述实现的正确率，我们使用 `common/util.py` 中的 `eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse)` 方法。这个方法向模型输入问题，生成字符串，并判断它是否与答案相符。如果模型给出的答案正确，则返回 1；如果错误，则返回 0。\n",
    "\n",
    "<code>eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse)</code> 方法有6个参数。首先是模型<code>model</code>、问题（字符ID数组）<code>question</code>、正确解（字符ID列表）<code>correct</code>。之后是进行字符ID与字符映射的字典 <code>id_to_char</code>、指定是否显示结果的 <code>verbose</code>、指定是否反转输入语句的 <code>is_reverse</code>。如果设置 <code>verbose = True</code>，则结果会显示在终端上。这次的实验仅显示最初的10份测试数据。另外，关于参数 <code>is_reverse</code>，我们稍后再解释。\n",
    "\n",
    "运行上述代码后，下图所示的结果会显示在终端（控制台）上。\n",
    "\n",
    "<img src=\"./fig/addition_result.png\" alt=\"addition_result\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，在终端上，每个 epoch 显示一次结果。每行有 “Q 600 + 257” 这样的问题语句，它的下方是 “T 857” 这样的正确答案。这里，“☒864” 是我们的模型给出的答案。如果我们的模型给出了正确答案，则终端上会显示 “☑864”。\n",
    "\n",
    "我们再看一下随着学习的进行，上面的结果会发生什么样的变化。下图给出了一个例子。\n",
    "\n",
    "<img src=\"./fig/result_change.png\" alt=\"result_change\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "图中展示了随着学习的进行而出现的几个结果。从结果中可知，seq2seq 最开始没能顺利回答问题。但是，随着学习不断进行，它在慢慢靠近正确答案，然后变得可以正确回答一些问题。下面，我们来绘制一下每个 epoch 的正确率，结果如下图所示。\n",
    "\n",
    "<img src=\"./fig/correct.png\" alt=\"correct\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "由图可知，随着学习的积累，正确率稳步提高。本次的实验只进行了 25 次，最后的正确率约为 10%。从图中的变化趋势可知，如果继续学习，正确率应该还会进一步上升。不过，为了能更好地学习相同的问题（加法问题），这里我们暂停本次学习，对 seq2seq 进行一些改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7e434",
   "metadata": {},
   "source": [
    "## seq2seq的改进\n",
    "本节我们对上一节的 seq2seq 进行改进，以改进学习的进展。为了达成该目标，可以使用一些比较有前景的技术。本节我们展示其中的两个方案，并基于实验确认它们的效果。\n",
    "\n",
    "## 反转输入数据（Reverse）\n",
    "第一个改进方案是非常简单的技巧。如下图所示，反转输入数据的顺序。\n",
    "\n",
    "<img src=\"./fig/Reverse.png\" alt=\"Reverse\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "这个反转输入数据的技巧是文献中提出来的。据研究，在许多情况下，使用这个技巧后，学习进展得更快，最终的精度也有提高。现在我们来做一下实验。\n",
    "\n",
    "为了反转输入数据，对于上一节的学习用代码，在读入数据集之后，我们追加下面的代码。\n",
    "\n",
    "```python\n",
    "# 读入数据集\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "\n",
    "...\n",
    "\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a51269e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.56\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.52\n",
      "| epoch 1 |  iter 41 / 351 | time 1[s] | loss 2.17\n",
      "| epoch 1 |  iter 61 / 351 | time 1[s] | loss 1.96\n",
      "| epoch 1 |  iter 81 / 351 | time 2[s] | loss 1.91\n",
      "| epoch 1 |  iter 101 / 351 | time 2[s] | loss 1.87\n",
      "| epoch 1 |  iter 121 / 351 | time 3[s] | loss 1.86\n",
      "| epoch 1 |  iter 141 / 351 | time 3[s] | loss 1.84\n",
      "| epoch 1 |  iter 161 / 351 | time 4[s] | loss 1.80\n",
      "| epoch 1 |  iter 181 / 351 | time 4[s] | loss 1.78\n",
      "| epoch 1 |  iter 201 / 351 | time 5[s] | loss 1.77\n",
      "| epoch 1 |  iter 221 / 351 | time 6[s] | loss 1.77\n",
      "| epoch 1 |  iter 241 / 351 | time 6[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 7[s] | loss 1.75\n",
      "| epoch 1 |  iter 281 / 351 | time 7[s] | loss 1.74\n",
      "| epoch 1 |  iter 301 / 351 | time 8[s] | loss 1.74\n",
      "| epoch 1 |  iter 321 / 351 | time 8[s] | loss 1.74\n",
      "| epoch 1 |  iter 341 / 351 | time 9[s] | loss 1.73\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 1001\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 1001\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1000\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 1001\n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 703 \n",
      "---\n",
      "验证集准确率 0.120%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.73\n",
      "| epoch 2 |  iter 21 / 351 | time 0[s] | loss 1.72\n",
      "| epoch 2 |  iter 41 / 351 | time 1[s] | loss 1.72\n",
      "| epoch 2 |  iter 61 / 351 | time 1[s] | loss 1.72\n",
      "| epoch 2 |  iter 81 / 351 | time 2[s] | loss 1.70\n",
      "| epoch 2 |  iter 101 / 351 | time 2[s] | loss 1.70\n",
      "| epoch 2 |  iter 121 / 351 | time 3[s] | loss 1.69\n",
      "| epoch 2 |  iter 141 / 351 | time 3[s] | loss 1.68\n",
      "| epoch 2 |  iter 161 / 351 | time 4[s] | loss 1.67\n",
      "| epoch 2 |  iter 181 / 351 | time 4[s] | loss 1.66\n",
      "| epoch 2 |  iter 201 / 351 | time 5[s] | loss 1.66\n",
      "| epoch 2 |  iter 221 / 351 | time 5[s] | loss 1.65\n",
      "| epoch 2 |  iter 241 / 351 | time 6[s] | loss 1.63\n",
      "| epoch 2 |  iter 261 / 351 | time 6[s] | loss 1.62\n",
      "| epoch 2 |  iter 281 / 351 | time 7[s] | loss 1.61\n",
      "| epoch 2 |  iter 301 / 351 | time 7[s] | loss 1.60\n",
      "| epoch 2 |  iter 321 / 351 | time 8[s] | loss 1.58\n",
      "| epoch 2 |  iter 341 / 351 | time 9[s] | loss 1.56\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 690 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 1000\n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 470 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 700 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1444\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 700 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 370 \n",
      "---\n",
      "验证集准确率 0.400%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.52\n",
      "| epoch 3 |  iter 21 / 351 | time 0[s] | loss 1.53\n",
      "| epoch 3 |  iter 41 / 351 | time 1[s] | loss 1.51\n",
      "| epoch 3 |  iter 61 / 351 | time 1[s] | loss 1.49\n",
      "| epoch 3 |  iter 81 / 351 | time 2[s] | loss 1.47\n",
      "| epoch 3 |  iter 101 / 351 | time 2[s] | loss 1.45\n",
      "| epoch 3 |  iter 121 / 351 | time 3[s] | loss 1.44\n",
      "| epoch 3 |  iter 141 / 351 | time 3[s] | loss 1.42\n",
      "| epoch 3 |  iter 161 / 351 | time 4[s] | loss 1.40\n",
      "| epoch 3 |  iter 181 / 351 | time 4[s] | loss 1.38\n",
      "| epoch 3 |  iter 201 / 351 | time 5[s] | loss 1.37\n",
      "| epoch 3 |  iter 221 / 351 | time 5[s] | loss 1.35\n",
      "| epoch 3 |  iter 241 / 351 | time 6[s] | loss 1.33\n",
      "| epoch 3 |  iter 261 / 351 | time 7[s] | loss 1.32\n",
      "| epoch 3 |  iter 281 / 351 | time 7[s] | loss 1.30\n",
      "| epoch 3 |  iter 301 / 351 | time 8[s] | loss 1.29\n",
      "| epoch 3 |  iter 321 / 351 | time 8[s] | loss 1.28\n",
      "| epoch 3 |  iter 341 / 351 | time 9[s] | loss 1.27\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1148\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 662 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 382 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 818 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1008\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1434\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 838 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 202 \n",
      "---\n",
      "验证集准确率 1.940%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.26\n",
      "| epoch 4 |  iter 21 / 351 | time 0[s] | loss 1.25\n",
      "| epoch 4 |  iter 41 / 351 | time 1[s] | loss 1.23\n",
      "| epoch 4 |  iter 61 / 351 | time 1[s] | loss 1.22\n",
      "| epoch 4 |  iter 81 / 351 | time 2[s] | loss 1.20\n",
      "| epoch 4 |  iter 101 / 351 | time 2[s] | loss 1.19\n",
      "| epoch 4 |  iter 121 / 351 | time 3[s] | loss 1.18\n",
      "| epoch 4 |  iter 141 / 351 | time 3[s] | loss 1.17\n",
      "| epoch 4 |  iter 161 / 351 | time 4[s] | loss 1.15\n",
      "| epoch 4 |  iter 181 / 351 | time 4[s] | loss 1.13\n",
      "| epoch 4 |  iter 201 / 351 | time 5[s] | loss 1.12\n",
      "| epoch 4 |  iter 221 / 351 | time 5[s] | loss 1.11\n",
      "| epoch 4 |  iter 241 / 351 | time 6[s] | loss 1.09\n",
      "| epoch 4 |  iter 261 / 351 | time 6[s] | loss 1.08\n",
      "| epoch 4 |  iter 281 / 351 | time 7[s] | loss 1.07\n",
      "| epoch 4 |  iter 301 / 351 | time 7[s] | loss 1.07\n",
      "| epoch 4 |  iter 321 / 351 | time 8[s] | loss 1.05\n",
      "| epoch 4 |  iter 341 / 351 | time 9[s] | loss 1.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1196\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 419 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 896 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1010\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1496\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 239 \n",
      "---\n",
      "验证集准确率 5.780%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.01\n",
      "| epoch 5 |  iter 21 / 351 | time 0[s] | loss 1.01\n",
      "| epoch 5 |  iter 41 / 351 | time 1[s] | loss 1.00\n",
      "| epoch 5 |  iter 61 / 351 | time 1[s] | loss 0.99\n",
      "| epoch 5 |  iter 81 / 351 | time 2[s] | loss 0.97\n",
      "| epoch 5 |  iter 101 / 351 | time 2[s] | loss 0.95\n",
      "| epoch 5 |  iter 121 / 351 | time 3[s] | loss 0.95\n",
      "| epoch 5 |  iter 141 / 351 | time 3[s] | loss 0.94\n",
      "| epoch 5 |  iter 161 / 351 | time 4[s] | loss 0.93\n",
      "| epoch 5 |  iter 181 / 351 | time 4[s] | loss 0.93\n",
      "| epoch 5 |  iter 201 / 351 | time 5[s] | loss 0.91\n",
      "| epoch 5 |  iter 221 / 351 | time 5[s] | loss 0.89\n",
      "| epoch 5 |  iter 241 / 351 | time 6[s] | loss 0.89\n",
      "| epoch 5 |  iter 261 / 351 | time 6[s] | loss 0.88\n",
      "| epoch 5 |  iter 281 / 351 | time 7[s] | loss 0.87\n",
      "| epoch 5 |  iter 301 / 351 | time 7[s] | loss 0.86\n",
      "| epoch 5 |  iter 321 / 351 | time 8[s] | loss 0.85\n",
      "| epoch 5 |  iter 341 / 351 | time 9[s] | loss 0.84\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1192\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 860 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1066\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1414\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 232 \n",
      "---\n",
      "验证集准确率 12.460%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 0.86\n",
      "| epoch 6 |  iter 21 / 351 | time 0[s] | loss 0.82\n",
      "| epoch 6 |  iter 41 / 351 | time 1[s] | loss 0.82\n",
      "| epoch 6 |  iter 61 / 351 | time 1[s] | loss 0.81\n",
      "| epoch 6 |  iter 81 / 351 | time 2[s] | loss 0.80\n",
      "| epoch 6 |  iter 101 / 351 | time 2[s] | loss 0.80\n",
      "| epoch 6 |  iter 121 / 351 | time 3[s] | loss 0.79\n",
      "| epoch 6 |  iter 141 / 351 | time 3[s] | loss 0.78\n",
      "| epoch 6 |  iter 161 / 351 | time 4[s] | loss 0.77\n",
      "| epoch 6 |  iter 181 / 351 | time 4[s] | loss 0.77\n",
      "| epoch 6 |  iter 201 / 351 | time 5[s] | loss 0.78\n",
      "| epoch 6 |  iter 221 / 351 | time 5[s] | loss 0.76\n",
      "| epoch 6 |  iter 241 / 351 | time 6[s] | loss 0.75\n",
      "| epoch 6 |  iter 261 / 351 | time 7[s] | loss 0.74\n",
      "| epoch 6 |  iter 281 / 351 | time 7[s] | loss 0.73\n",
      "| epoch 6 |  iter 301 / 351 | time 8[s] | loss 0.73\n",
      "| epoch 6 |  iter 321 / 351 | time 8[s] | loss 0.72\n",
      "| epoch 6 |  iter 341 / 351 | time 9[s] | loss 0.72\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1141\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1061\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1391\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 234 \n",
      "---\n",
      "验证集准确率 14.260%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.71\n",
      "| epoch 7 |  iter 21 / 351 | time 0[s] | loss 0.71\n",
      "| epoch 7 |  iter 41 / 351 | time 1[s] | loss 0.70\n",
      "| epoch 7 |  iter 61 / 351 | time 1[s] | loss 0.70\n",
      "| epoch 7 |  iter 81 / 351 | time 2[s] | loss 0.68\n",
      "| epoch 7 |  iter 101 / 351 | time 2[s] | loss 0.68\n",
      "| epoch 7 |  iter 121 / 351 | time 3[s] | loss 0.67\n",
      "| epoch 7 |  iter 141 / 351 | time 3[s] | loss 0.67\n",
      "| epoch 7 |  iter 161 / 351 | time 4[s] | loss 0.67\n",
      "| epoch 7 |  iter 181 / 351 | time 4[s] | loss 0.66\n",
      "| epoch 7 |  iter 201 / 351 | time 5[s] | loss 0.66\n",
      "| epoch 7 |  iter 221 / 351 | time 5[s] | loss 0.66\n",
      "| epoch 7 |  iter 241 / 351 | time 6[s] | loss 0.64\n",
      "| epoch 7 |  iter 261 / 351 | time 6[s] | loss 0.65\n",
      "| epoch 7 |  iter 281 / 351 | time 7[s] | loss 0.64\n",
      "| epoch 7 |  iter 301 / 351 | time 7[s] | loss 0.63\n",
      "| epoch 7 |  iter 321 / 351 | time 8[s] | loss 0.63\n",
      "| epoch 7 |  iter 341 / 351 | time 8[s] | loss 0.62\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1144\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 239 \n",
      "---\n",
      "验证集准确率 17.500%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 0.66\n",
      "| epoch 8 |  iter 21 / 351 | time 0[s] | loss 0.61\n",
      "| epoch 8 |  iter 41 / 351 | time 1[s] | loss 0.62\n",
      "| epoch 8 |  iter 61 / 351 | time 1[s] | loss 0.61\n",
      "| epoch 8 |  iter 81 / 351 | time 2[s] | loss 0.61\n",
      "| epoch 8 |  iter 101 / 351 | time 2[s] | loss 0.61\n",
      "| epoch 8 |  iter 121 / 351 | time 3[s] | loss 0.60\n",
      "| epoch 8 |  iter 141 / 351 | time 3[s] | loss 0.60\n",
      "| epoch 8 |  iter 161 / 351 | time 4[s] | loss 0.59\n",
      "| epoch 8 |  iter 181 / 351 | time 4[s] | loss 0.58\n",
      "| epoch 8 |  iter 201 / 351 | time 5[s] | loss 0.59\n",
      "| epoch 8 |  iter 221 / 351 | time 6[s] | loss 0.60\n",
      "| epoch 8 |  iter 241 / 351 | time 6[s] | loss 0.59\n",
      "| epoch 8 |  iter 261 / 351 | time 7[s] | loss 0.58\n",
      "| epoch 8 |  iter 281 / 351 | time 7[s] | loss 0.59\n",
      "| epoch 8 |  iter 301 / 351 | time 8[s] | loss 0.58\n",
      "| epoch 8 |  iter 321 / 351 | time 8[s] | loss 0.57\n",
      "| epoch 8 |  iter 341 / 351 | time 9[s] | loss 0.57\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1134\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 759 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 238 \n",
      "---\n",
      "验证集准确率 23.080%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 0.55\n",
      "| epoch 9 |  iter 21 / 351 | time 0[s] | loss 0.56\n",
      "| epoch 9 |  iter 41 / 351 | time 1[s] | loss 0.56\n",
      "| epoch 9 |  iter 61 / 351 | time 1[s] | loss 0.55\n",
      "| epoch 9 |  iter 81 / 351 | time 2[s] | loss 0.54\n",
      "| epoch 9 |  iter 101 / 351 | time 2[s] | loss 0.55\n",
      "| epoch 9 |  iter 121 / 351 | time 3[s] | loss 0.55\n",
      "| epoch 9 |  iter 141 / 351 | time 3[s] | loss 0.54\n",
      "| epoch 9 |  iter 161 / 351 | time 4[s] | loss 0.55\n",
      "| epoch 9 |  iter 181 / 351 | time 4[s] | loss 0.53\n",
      "| epoch 9 |  iter 201 / 351 | time 5[s] | loss 0.54\n",
      "| epoch 9 |  iter 221 / 351 | time 5[s] | loss 0.54\n",
      "| epoch 9 |  iter 241 / 351 | time 6[s] | loss 0.53\n",
      "| epoch 9 |  iter 261 / 351 | time 7[s] | loss 0.53\n",
      "| epoch 9 |  iter 281 / 351 | time 7[s] | loss 0.54\n",
      "| epoch 9 |  iter 301 / 351 | time 8[s] | loss 0.54\n",
      "| epoch 9 |  iter 321 / 351 | time 8[s] | loss 0.53\n",
      "| epoch 9 |  iter 341 / 351 | time 9[s] | loss 0.53\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 854 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 238 \n",
      "---\n",
      "验证集准确率 26.520%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.50\n",
      "| epoch 10 |  iter 21 / 351 | time 0[s] | loss 0.51\n",
      "| epoch 10 |  iter 41 / 351 | time 1[s] | loss 0.52\n",
      "| epoch 10 |  iter 61 / 351 | time 1[s] | loss 0.55\n",
      "| epoch 10 |  iter 81 / 351 | time 2[s] | loss 0.52\n",
      "| epoch 10 |  iter 101 / 351 | time 2[s] | loss 0.51\n",
      "| epoch 10 |  iter 121 / 351 | time 3[s] | loss 0.50\n",
      "| epoch 10 |  iter 141 / 351 | time 3[s] | loss 0.51\n",
      "| epoch 10 |  iter 161 / 351 | time 4[s] | loss 0.52\n",
      "| epoch 10 |  iter 181 / 351 | time 4[s] | loss 0.53\n",
      "| epoch 10 |  iter 201 / 351 | time 5[s] | loss 0.50\n",
      "| epoch 10 |  iter 221 / 351 | time 5[s] | loss 0.50\n",
      "| epoch 10 |  iter 241 / 351 | time 6[s] | loss 0.50\n",
      "| epoch 10 |  iter 261 / 351 | time 7[s] | loss 0.50\n",
      "| epoch 10 |  iter 281 / 351 | time 7[s] | loss 0.49\n",
      "| epoch 10 |  iter 301 / 351 | time 8[s] | loss 0.48\n",
      "| epoch 10 |  iter 321 / 351 | time 8[s] | loss 0.48\n",
      "| epoch 10 |  iter 341 / 351 | time 9[s] | loss 0.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 664 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 235 \n",
      "---\n",
      "验证集准确率 29.820%\n",
      "| epoch 11 |  iter 1 / 351 | time 0[s] | loss 0.47\n",
      "| epoch 11 |  iter 21 / 351 | time 0[s] | loss 0.48\n",
      "| epoch 11 |  iter 41 / 351 | time 1[s] | loss 0.48\n",
      "| epoch 11 |  iter 61 / 351 | time 1[s] | loss 0.48\n",
      "| epoch 11 |  iter 81 / 351 | time 2[s] | loss 0.47\n",
      "| epoch 11 |  iter 101 / 351 | time 2[s] | loss 0.47\n",
      "| epoch 11 |  iter 121 / 351 | time 3[s] | loss 0.47\n",
      "| epoch 11 |  iter 141 / 351 | time 3[s] | loss 0.47\n",
      "| epoch 11 |  iter 161 / 351 | time 4[s] | loss 0.48\n",
      "| epoch 11 |  iter 181 / 351 | time 4[s] | loss 0.48\n",
      "| epoch 11 |  iter 201 / 351 | time 5[s] | loss 0.47\n",
      "| epoch 11 |  iter 221 / 351 | time 5[s] | loss 0.47\n",
      "| epoch 11 |  iter 241 / 351 | time 6[s] | loss 0.46\n",
      "| epoch 11 |  iter 261 / 351 | time 7[s] | loss 0.46\n",
      "| epoch 11 |  iter 281 / 351 | time 7[s] | loss 0.46\n",
      "| epoch 11 |  iter 301 / 351 | time 8[s] | loss 0.48\n",
      "| epoch 11 |  iter 321 / 351 | time 8[s] | loss 0.45\n",
      "| epoch 11 |  iter 341 / 351 | time 9[s] | loss 0.45\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1426\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 238 \n",
      "---\n",
      "验证集准确率 28.480%\n",
      "| epoch 12 |  iter 1 / 351 | time 0[s] | loss 0.46\n",
      "| epoch 12 |  iter 21 / 351 | time 0[s] | loss 0.45\n",
      "| epoch 12 |  iter 41 / 351 | time 1[s] | loss 0.45\n",
      "| epoch 12 |  iter 61 / 351 | time 1[s] | loss 0.46\n",
      "| epoch 12 |  iter 81 / 351 | time 2[s] | loss 0.45\n",
      "| epoch 12 |  iter 101 / 351 | time 2[s] | loss 0.46\n",
      "| epoch 12 |  iter 121 / 351 | time 3[s] | loss 0.46\n",
      "| epoch 12 |  iter 141 / 351 | time 4[s] | loss 0.46\n",
      "| epoch 12 |  iter 161 / 351 | time 4[s] | loss 0.45\n",
      "| epoch 12 |  iter 181 / 351 | time 5[s] | loss 0.44\n",
      "| epoch 12 |  iter 201 / 351 | time 5[s] | loss 0.45\n",
      "| epoch 12 |  iter 221 / 351 | time 6[s] | loss 0.44\n",
      "| epoch 12 |  iter 241 / 351 | time 6[s] | loss 0.43\n",
      "| epoch 12 |  iter 261 / 351 | time 7[s] | loss 0.43\n",
      "| epoch 12 |  iter 281 / 351 | time 7[s] | loss 0.44\n",
      "| epoch 12 |  iter 301 / 351 | time 8[s] | loss 0.45\n",
      "| epoch 12 |  iter 321 / 351 | time 9[s] | loss 0.44\n",
      "| epoch 12 |  iter 341 / 351 | time 9[s] | loss 0.43\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1051\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 237 \n",
      "---\n",
      "验证集准确率 36.640%\n",
      "| epoch 13 |  iter 1 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 13 |  iter 21 / 351 | time 0[s] | loss 0.43\n",
      "| epoch 13 |  iter 41 / 351 | time 1[s] | loss 0.42\n",
      "| epoch 13 |  iter 61 / 351 | time 1[s] | loss 0.42\n",
      "| epoch 13 |  iter 81 / 351 | time 2[s] | loss 0.42\n",
      "| epoch 13 |  iter 101 / 351 | time 2[s] | loss 0.44\n",
      "| epoch 13 |  iter 121 / 351 | time 3[s] | loss 0.43\n",
      "| epoch 13 |  iter 141 / 351 | time 3[s] | loss 0.41\n",
      "| epoch 13 |  iter 161 / 351 | time 4[s] | loss 0.42\n",
      "| epoch 13 |  iter 181 / 351 | time 4[s] | loss 0.42\n",
      "| epoch 13 |  iter 201 / 351 | time 5[s] | loss 0.42\n",
      "| epoch 13 |  iter 221 / 351 | time 6[s] | loss 0.43\n",
      "| epoch 13 |  iter 241 / 351 | time 6[s] | loss 0.43\n",
      "| epoch 13 |  iter 261 / 351 | time 7[s] | loss 0.41\n",
      "| epoch 13 |  iter 281 / 351 | time 7[s] | loss 0.42\n",
      "| epoch 13 |  iter 301 / 351 | time 8[s] | loss 0.41\n",
      "| epoch 13 |  iter 321 / 351 | time 8[s] | loss 0.43\n",
      "| epoch 13 |  iter 341 / 351 | time 9[s] | loss 0.40\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 424 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 239 \n",
      "---\n",
      "验证集准确率 39.420%\n",
      "| epoch 14 |  iter 1 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 14 |  iter 21 / 351 | time 0[s] | loss 0.41\n",
      "| epoch 14 |  iter 41 / 351 | time 1[s] | loss 0.41\n",
      "| epoch 14 |  iter 61 / 351 | time 1[s] | loss 0.40\n",
      "| epoch 14 |  iter 81 / 351 | time 2[s] | loss 0.40\n",
      "| epoch 14 |  iter 101 / 351 | time 2[s] | loss 0.41\n",
      "| epoch 14 |  iter 121 / 351 | time 3[s] | loss 0.39\n",
      "| epoch 14 |  iter 141 / 351 | time 3[s] | loss 0.39\n",
      "| epoch 14 |  iter 161 / 351 | time 4[s] | loss 0.38\n",
      "| epoch 14 |  iter 181 / 351 | time 4[s] | loss 0.38\n",
      "| epoch 14 |  iter 201 / 351 | time 5[s] | loss 0.38\n",
      "| epoch 14 |  iter 221 / 351 | time 5[s] | loss 0.38\n",
      "| epoch 14 |  iter 241 / 351 | time 6[s] | loss 0.39\n",
      "| epoch 14 |  iter 261 / 351 | time 6[s] | loss 0.40\n",
      "| epoch 14 |  iter 281 / 351 | time 7[s] | loss 0.41\n",
      "| epoch 14 |  iter 301 / 351 | time 7[s] | loss 0.39\n",
      "| epoch 14 |  iter 321 / 351 | time 8[s] | loss 0.39\n",
      "| epoch 14 |  iter 341 / 351 | time 9[s] | loss 0.39\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1426\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 235 \n",
      "---\n",
      "验证集准确率 36.680%\n",
      "| epoch 15 |  iter 1 / 351 | time 0[s] | loss 0.38\n",
      "| epoch 15 |  iter 21 / 351 | time 0[s] | loss 0.39\n",
      "| epoch 15 |  iter 41 / 351 | time 1[s] | loss 0.39\n",
      "| epoch 15 |  iter 61 / 351 | time 1[s] | loss 0.38\n",
      "| epoch 15 |  iter 81 / 351 | time 2[s] | loss 0.38\n",
      "| epoch 15 |  iter 101 / 351 | time 2[s] | loss 0.38\n",
      "| epoch 15 |  iter 121 / 351 | time 3[s] | loss 0.38\n",
      "| epoch 15 |  iter 141 / 351 | time 3[s] | loss 0.38\n",
      "| epoch 15 |  iter 161 / 351 | time 4[s] | loss 0.38\n",
      "| epoch 15 |  iter 181 / 351 | time 4[s] | loss 0.38\n",
      "| epoch 15 |  iter 201 / 351 | time 5[s] | loss 0.38\n",
      "| epoch 15 |  iter 221 / 351 | time 5[s] | loss 0.39\n",
      "| epoch 15 |  iter 241 / 351 | time 6[s] | loss 0.38\n",
      "| epoch 15 |  iter 261 / 351 | time 7[s] | loss 0.37\n",
      "| epoch 15 |  iter 281 / 351 | time 7[s] | loss 0.37\n",
      "| epoch 15 |  iter 301 / 351 | time 8[s] | loss 0.39\n",
      "| epoch 15 |  iter 321 / 351 | time 8[s] | loss 0.39\n",
      "| epoch 15 |  iter 341 / 351 | time 9[s] | loss 0.37\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 667 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 164 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 420 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1431\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 237 \n",
      "---\n",
      "验证集准确率 41.100%\n",
      "| epoch 16 |  iter 1 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 16 |  iter 21 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 16 |  iter 41 / 351 | time 1[s] | loss 0.36\n",
      "| epoch 16 |  iter 61 / 351 | time 1[s] | loss 0.36\n",
      "| epoch 16 |  iter 81 / 351 | time 2[s] | loss 0.37\n",
      "| epoch 16 |  iter 101 / 351 | time 2[s] | loss 0.36\n",
      "| epoch 16 |  iter 121 / 351 | time 3[s] | loss 0.37\n",
      "| epoch 16 |  iter 141 / 351 | time 3[s] | loss 0.36\n",
      "| epoch 16 |  iter 161 / 351 | time 4[s] | loss 0.37\n",
      "| epoch 16 |  iter 181 / 351 | time 4[s] | loss 0.36\n",
      "| epoch 16 |  iter 201 / 351 | time 5[s] | loss 0.38\n",
      "| epoch 16 |  iter 221 / 351 | time 5[s] | loss 0.38\n",
      "| epoch 16 |  iter 241 / 351 | time 6[s] | loss 0.36\n",
      "| epoch 16 |  iter 261 / 351 | time 6[s] | loss 0.35\n",
      "| epoch 16 |  iter 281 / 351 | time 7[s] | loss 0.35\n",
      "| epoch 16 |  iter 301 / 351 | time 8[s] | loss 0.35\n",
      "| epoch 16 |  iter 321 / 351 | time 8[s] | loss 0.35\n",
      "| epoch 16 |  iter 341 / 351 | time 9[s] | loss 0.37\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 237 \n",
      "---\n",
      "验证集准确率 42.700%\n",
      "| epoch 17 |  iter 1 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 17 |  iter 21 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 17 |  iter 41 / 351 | time 1[s] | loss 0.36\n",
      "| epoch 17 |  iter 61 / 351 | time 1[s] | loss 0.35\n",
      "| epoch 17 |  iter 81 / 351 | time 2[s] | loss 0.36\n",
      "| epoch 17 |  iter 101 / 351 | time 2[s] | loss 0.34\n",
      "| epoch 17 |  iter 121 / 351 | time 3[s] | loss 0.34\n",
      "| epoch 17 |  iter 141 / 351 | time 3[s] | loss 0.34\n",
      "| epoch 17 |  iter 161 / 351 | time 4[s] | loss 0.34\n",
      "| epoch 17 |  iter 181 / 351 | time 4[s] | loss 0.35\n",
      "| epoch 17 |  iter 201 / 351 | time 5[s] | loss 0.35\n",
      "| epoch 17 |  iter 221 / 351 | time 5[s] | loss 0.34\n",
      "| epoch 17 |  iter 241 / 351 | time 6[s] | loss 0.35\n",
      "| epoch 17 |  iter 261 / 351 | time 6[s] | loss 0.36\n",
      "| epoch 17 |  iter 281 / 351 | time 7[s] | loss 0.37\n",
      "| epoch 17 |  iter 301 / 351 | time 8[s] | loss 0.37\n",
      "| epoch 17 |  iter 321 / 351 | time 8[s] | loss 0.37\n",
      "| epoch 17 |  iter 341 / 351 | time 9[s] | loss 0.36\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1051\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 42.860%\n",
      "| epoch 18 |  iter 1 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 18 |  iter 21 / 351 | time 0[s] | loss 0.36\n",
      "| epoch 18 |  iter 41 / 351 | time 1[s] | loss 0.35\n",
      "| epoch 18 |  iter 61 / 351 | time 1[s] | loss 0.35\n",
      "| epoch 18 |  iter 81 / 351 | time 2[s] | loss 0.34\n",
      "| epoch 18 |  iter 101 / 351 | time 2[s] | loss 0.34\n",
      "| epoch 18 |  iter 121 / 351 | time 3[s] | loss 0.33\n",
      "| epoch 18 |  iter 141 / 351 | time 3[s] | loss 0.33\n",
      "| epoch 18 |  iter 161 / 351 | time 4[s] | loss 0.34\n",
      "| epoch 18 |  iter 181 / 351 | time 4[s] | loss 0.33\n",
      "| epoch 18 |  iter 201 / 351 | time 5[s] | loss 0.33\n",
      "| epoch 18 |  iter 221 / 351 | time 5[s] | loss 0.33\n",
      "| epoch 18 |  iter 241 / 351 | time 6[s] | loss 0.33\n",
      "| epoch 18 |  iter 261 / 351 | time 7[s] | loss 0.33\n",
      "| epoch 18 |  iter 281 / 351 | time 7[s] | loss 0.33\n",
      "| epoch 18 |  iter 301 / 351 | time 8[s] | loss 0.33\n",
      "| epoch 18 |  iter 321 / 351 | time 8[s] | loss 0.35\n",
      "| epoch 18 |  iter 341 / 351 | time 9[s] | loss 0.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1425\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 237 \n",
      "---\n",
      "验证集准确率 40.640%\n",
      "| epoch 19 |  iter 1 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 19 |  iter 21 / 351 | time 0[s] | loss 0.34\n",
      "| epoch 19 |  iter 41 / 351 | time 1[s] | loss 0.34\n",
      "| epoch 19 |  iter 61 / 351 | time 1[s] | loss 0.34\n",
      "| epoch 19 |  iter 81 / 351 | time 2[s] | loss 0.34\n",
      "| epoch 19 |  iter 101 / 351 | time 2[s] | loss 0.32\n",
      "| epoch 19 |  iter 121 / 351 | time 3[s] | loss 0.31\n",
      "| epoch 19 |  iter 141 / 351 | time 3[s] | loss 0.33\n",
      "| epoch 19 |  iter 161 / 351 | time 4[s] | loss 0.31\n",
      "| epoch 19 |  iter 181 / 351 | time 4[s] | loss 0.30\n",
      "| epoch 19 |  iter 201 / 351 | time 5[s] | loss 0.31\n",
      "| epoch 19 |  iter 221 / 351 | time 6[s] | loss 0.31\n",
      "| epoch 19 |  iter 241 / 351 | time 6[s] | loss 0.32\n",
      "| epoch 19 |  iter 261 / 351 | time 7[s] | loss 0.33\n",
      "| epoch 19 |  iter 281 / 351 | time 7[s] | loss 0.32\n",
      "| epoch 19 |  iter 301 / 351 | time 8[s] | loss 0.32\n",
      "| epoch 19 |  iter 321 / 351 | time 8[s] | loss 0.33\n",
      "| epoch 19 |  iter 341 / 351 | time 9[s] | loss 0.33\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 238 \n",
      "---\n",
      "验证集准确率 47.540%\n",
      "| epoch 20 |  iter 1 / 351 | time 0[s] | loss 0.32\n",
      "| epoch 20 |  iter 21 / 351 | time 0[s] | loss 0.35\n",
      "| epoch 20 |  iter 41 / 351 | time 1[s] | loss 0.33\n",
      "| epoch 20 |  iter 61 / 351 | time 1[s] | loss 0.33\n",
      "| epoch 20 |  iter 81 / 351 | time 2[s] | loss 0.31\n",
      "| epoch 20 |  iter 101 / 351 | time 2[s] | loss 0.31\n",
      "| epoch 20 |  iter 121 / 351 | time 3[s] | loss 0.33\n",
      "| epoch 20 |  iter 141 / 351 | time 3[s] | loss 0.32\n",
      "| epoch 20 |  iter 161 / 351 | time 4[s] | loss 0.33\n",
      "| epoch 20 |  iter 181 / 351 | time 4[s] | loss 0.31\n",
      "| epoch 20 |  iter 201 / 351 | time 5[s] | loss 0.30\n",
      "| epoch 20 |  iter 221 / 351 | time 5[s] | loss 0.32\n",
      "| epoch 20 |  iter 241 / 351 | time 6[s] | loss 0.33\n",
      "| epoch 20 |  iter 261 / 351 | time 6[s] | loss 0.35\n",
      "| epoch 20 |  iter 281 / 351 | time 7[s] | loss 0.36\n",
      "| epoch 20 |  iter 301 / 351 | time 8[s] | loss 0.34\n",
      "| epoch 20 |  iter 321 / 351 | time 8[s] | loss 0.32\n",
      "| epoch 20 |  iter 341 / 351 | time 9[s] | loss 0.32\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1051\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 49.960%\n",
      "| epoch 21 |  iter 1 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 21 |  iter 21 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 21 |  iter 41 / 351 | time 1[s] | loss 0.30\n",
      "| epoch 21 |  iter 61 / 351 | time 1[s] | loss 0.30\n",
      "| epoch 21 |  iter 81 / 351 | time 2[s] | loss 0.32\n",
      "| epoch 21 |  iter 101 / 351 | time 2[s] | loss 0.32\n",
      "| epoch 21 |  iter 121 / 351 | time 3[s] | loss 0.31\n",
      "| epoch 21 |  iter 141 / 351 | time 3[s] | loss 0.30\n",
      "| epoch 21 |  iter 161 / 351 | time 4[s] | loss 0.31\n",
      "| epoch 21 |  iter 181 / 351 | time 4[s] | loss 0.31\n",
      "| epoch 21 |  iter 201 / 351 | time 5[s] | loss 0.31\n",
      "| epoch 21 |  iter 221 / 351 | time 5[s] | loss 0.32\n",
      "| epoch 21 |  iter 241 / 351 | time 6[s] | loss 0.31\n",
      "| epoch 21 |  iter 261 / 351 | time 7[s] | loss 0.29\n",
      "| epoch 21 |  iter 281 / 351 | time 7[s] | loss 0.30\n",
      "| epoch 21 |  iter 301 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 21 |  iter 321 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 21 |  iter 341 / 351 | time 9[s] | loss 0.29\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 859 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 51.000%\n",
      "| epoch 22 |  iter 1 / 351 | time 0[s] | loss 0.32\n",
      "| epoch 22 |  iter 21 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 22 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 22 |  iter 61 / 351 | time 1[s] | loss 0.29\n",
      "| epoch 22 |  iter 81 / 351 | time 2[s] | loss 0.29\n",
      "| epoch 22 |  iter 101 / 351 | time 2[s] | loss 0.28\n",
      "| epoch 22 |  iter 121 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 22 |  iter 141 / 351 | time 3[s] | loss 0.31\n",
      "| epoch 22 |  iter 161 / 351 | time 4[s] | loss 0.31\n",
      "| epoch 22 |  iter 181 / 351 | time 4[s] | loss 0.30\n",
      "| epoch 22 |  iter 201 / 351 | time 5[s] | loss 0.28\n",
      "| epoch 22 |  iter 221 / 351 | time 5[s] | loss 0.32\n",
      "| epoch 22 |  iter 241 / 351 | time 6[s] | loss 0.33\n",
      "| epoch 22 |  iter 261 / 351 | time 7[s] | loss 0.32\n",
      "| epoch 22 |  iter 281 / 351 | time 7[s] | loss 0.31\n",
      "| epoch 22 |  iter 301 / 351 | time 8[s] | loss 0.30\n",
      "| epoch 22 |  iter 321 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 22 |  iter 341 / 351 | time 9[s] | loss 0.31\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1430\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 865 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 238 \n",
      "---\n",
      "验证集准确率 47.740%\n",
      "| epoch 23 |  iter 1 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 23 |  iter 21 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 23 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 23 |  iter 61 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 23 |  iter 81 / 351 | time 2[s] | loss 0.29\n",
      "| epoch 23 |  iter 101 / 351 | time 2[s] | loss 0.27\n",
      "| epoch 23 |  iter 121 / 351 | time 3[s] | loss 0.28\n",
      "| epoch 23 |  iter 141 / 351 | time 3[s] | loss 0.28\n",
      "| epoch 23 |  iter 161 / 351 | time 4[s] | loss 0.30\n",
      "| epoch 23 |  iter 181 / 351 | time 4[s] | loss 0.30\n",
      "| epoch 23 |  iter 201 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 23 |  iter 221 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 23 |  iter 241 / 351 | time 6[s] | loss 0.28\n",
      "| epoch 23 |  iter 261 / 351 | time 6[s] | loss 0.28\n",
      "| epoch 23 |  iter 281 / 351 | time 7[s] | loss 0.30\n",
      "| epoch 23 |  iter 301 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 23 |  iter 321 / 351 | time 8[s] | loss 0.29\n",
      "| epoch 23 |  iter 341 / 351 | time 9[s] | loss 0.28\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1142\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1429\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 866 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 238 \n",
      "---\n",
      "验证集准确率 45.180%\n",
      "| epoch 24 |  iter 1 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 24 |  iter 21 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 24 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 24 |  iter 61 / 351 | time 1[s] | loss 0.29\n",
      "| epoch 24 |  iter 81 / 351 | time 2[s] | loss 0.30\n",
      "| epoch 24 |  iter 101 / 351 | time 2[s] | loss 0.29\n",
      "| epoch 24 |  iter 121 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 24 |  iter 141 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 24 |  iter 161 / 351 | time 4[s] | loss 0.28\n",
      "| epoch 24 |  iter 181 / 351 | time 4[s] | loss 0.29\n",
      "| epoch 24 |  iter 201 / 351 | time 5[s] | loss 0.28\n",
      "| epoch 24 |  iter 221 / 351 | time 5[s] | loss 0.28\n",
      "| epoch 24 |  iter 241 / 351 | time 6[s] | loss 0.29\n",
      "| epoch 24 |  iter 261 / 351 | time 7[s] | loss 0.29\n",
      "| epoch 24 |  iter 281 / 351 | time 7[s] | loss 0.29\n",
      "| epoch 24 |  iter 301 / 351 | time 8[s] | loss 0.28\n",
      "| epoch 24 |  iter 321 / 351 | time 8[s] | loss 0.27\n",
      "| epoch 24 |  iter 341 / 351 | time 9[s] | loss 0.29\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 421 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1054\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 237 \n",
      "---\n",
      "验证集准确率 51.840%\n",
      "| epoch 25 |  iter 1 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 25 |  iter 21 / 351 | time 0[s] | loss 0.29\n",
      "| epoch 25 |  iter 41 / 351 | time 1[s] | loss 0.28\n",
      "| epoch 25 |  iter 61 / 351 | time 1[s] | loss 0.26\n",
      "| epoch 25 |  iter 81 / 351 | time 2[s] | loss 0.26\n",
      "| epoch 25 |  iter 101 / 351 | time 2[s] | loss 0.27\n",
      "| epoch 25 |  iter 121 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 25 |  iter 141 / 351 | time 3[s] | loss 0.28\n",
      "| epoch 25 |  iter 161 / 351 | time 4[s] | loss 0.28\n",
      "| epoch 25 |  iter 181 / 351 | time 4[s] | loss 0.28\n",
      "| epoch 25 |  iter 201 / 351 | time 5[s] | loss 0.27\n",
      "| epoch 25 |  iter 221 / 351 | time 5[s] | loss 0.29\n",
      "| epoch 25 |  iter 241 / 351 | time 6[s] | loss 0.27\n",
      "| epoch 25 |  iter 261 / 351 | time 6[s] | loss 0.28\n",
      "| epoch 25 |  iter 281 / 351 | time 7[s] | loss 0.28\n",
      "| epoch 25 |  iter 301 / 351 | time 7[s] | loss 0.27\n",
      "| epoch 25 |  iter 321 / 351 | time 8[s] | loss 0.28\n",
      "| epoch 25 |  iter 341 / 351 | time 9[s] | loss 0.28\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1426\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 54.080%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # 忽略警告信息\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 读入数据集\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt') # 读取加法运算数据集\n",
    "char_to_id, id_to_char = sequence.get_vocab() # 获取字符和ID的对应关系\n",
    "\n",
    "# 是否反转输入序列（有时反转输入可以提高Seq2Seq模型的性能）\n",
    "is_reverse = True  # 可以改为True尝试\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1] # 反转输入序列，[:: -1]表示步长为-1，即从后向前取元素\n",
    "# =========================================================\n",
    "\n",
    "# 设定超参数\n",
    "vocab_size = len(char_to_id) # 词典大小\n",
    "wordvec_size = 16 # 词向量维度\n",
    "hidden_size = 128 # 隐藏状态维度\n",
    "batch_size = 128 # 批量大小\n",
    "max_epoch = 25 # 最大训练轮数\n",
    "max_grad = 5.0 # 用于梯度裁剪的阈值\n",
    "\n",
    "# 选择使用基础Seq2Seq还是Peeky Seq2Seq模型 ========================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# ================================================================\n",
    "optimizer = Adam() # Adam优化器\n",
    "trainer = Trainer(model, optimizer) # 训练器\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad) # 训练一个epoch\n",
    "\n",
    "    correct_num = 0 # 预测正确的样本数\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]] # 取出一个样本，question的形状为(1, 7)，correct的形状为(1, 5)\n",
    "        verbose = i < 10 # 前10个样本打印详细信息\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse) # 评估样本\n",
    "\n",
    "    acc = float(correct_num) / len(x_test) # 计算准确率\n",
    "    acc_list.append(acc) # 记录准确率\n",
    "    print('验证集准确率 %.3f%%' % (acc * 100)) # 打印验证集准确率\n",
    "\n",
    "# 绘制图形\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('训练轮数')\n",
    "plt.ylabel('验证集准确率')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188aa03",
   "metadata": {},
   "source": [
    "如上所示，可以使用 `x_train[:, ::-1]` 反转数组的排列。那么，通过反转输入数据，正确率可以上升多少呢？结果如图所示。\n",
    "\n",
    "<img src=\"./fig/Reverse_result.png\" alt=\"Reverse_result\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "从图中可知，仅仅通过反转输入数据，学习的进展就得到了改善！在 25 个 epoch 时，正确率为 50% 左右。再次重复一遍，这里和上一次（图中的 baseline）的差异只是将数据反转了一下。仅仅这样，就产生了这么大的差异，真是令人吃惊。当然，虽然反转数据的效果因任务而异，但是通常都会有好的结果。\n",
    "\n",
    "为什么反转数据后，学习进展变快，精度提高了呢？虽然理论上不是很清楚，但是直观上可以认为，反转数据后梯度的传播可以更平滑。比如，考虑将 “吾輩 は 猫 で ある”翻译成 “I am a cat” 这一问题，单词 “吾輩” 和单词 “I” 之间有转换关系。此时，从 “吾輩” 到 “I” 的路程必须经过 “は”“猫”“で”“ある” 这 4 个单词的 LSTM 层。因此，在反向传播时，梯度从 “I” 抵达 “吾輩”，也要受到这个距离的影响。\n",
    "\n",
    "那么，如果反转输入语句，也就是变为 “ある で 猫 は 吾輩”，结果会怎样呢？此时，“吾輩” 和 “I” 彼此相邻，梯度可以直接传递。如此，因为通过反转，输入语句的开始部分和对应的转换后的单词之间的距离变近（这样的情况变多），所以梯度的传播变得更容易，学习效率也更高。不过，在反转输入数据后，单词之间的 “平均” 距离并不会发生改变。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12fd7d",
   "metadata": {},
   "source": [
    "## 偷窥（Peeky）\n",
    "接下来是 seq2seq 的第二个改进。在进入正题之前，我们再看一下编码器的作用。如前所述，编码器将输入语句转换为固定长度的向量 $\\boldsymbol{h}$，这个 $\\boldsymbol{h}$ 集中了解码器所需的全部信息。也就是说，它是解码器唯一的信息源。但是，如图所示，当前的 seq2seq 只有最开始时刻的 LSTM 层利用了 $\\boldsymbol{h}$。我们能更加充分地利用这个 $\\boldsymbol{h}$ 吗？\n",
    "\n",
    "<img src=\"./fig/LSTM_h.png\" alt=\"LSTM_h\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "为了达成该目标，seq2seq 的第二个改进方案就应运而生了。具体来说，就是将这个集中了重要信息的编码器的输出 $\\boldsymbol{h}$ 分配给解码器的其他层。我们的解码器可以考虑图中的网络结构。\n",
    "\n",
    "<img src=\"./fig/decoder_change.png\" alt=\"decoder_change\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，将编码器的输出 $\\boldsymbol{h}$ 分配给所有时刻的 `Affine` 层和 `LSTM` 层。比较可知，之前 `LSTM` 层专用的重要信息 $\\boldsymbol{h}$ 现在在多个层（在这个例子中有 8 个层）中共享了。重要的信息不是一个人专有，而是多人共享，这样我们或许可以做出更加正确的判断。\n",
    "\n",
    "这里的改进是将编码好的信息分配给解码器的其他层，这可以解释为其他层也能“偷窥”到编码信息。因为“偷窥”的英语是 <code>peek</code>，所以将这个改进了的解码器称为 <code>Peeky Decoder</code>。同理，将使用了 <code>Peeky Decoder</code> 的 seq2seq 称为 <code>Peeky seq2seq</code>。\n",
    "\n",
    "在上图中，有两个向量同时被输入到了 `LSTM` 层和 `Affine` 层，这实际上表示两个向量的拼接（`concatenate`）。因此，在刚才的图中，如果使用 `concat` 节点拼接两个向量，则正确的计算图可以绘制成下图。\n",
    "\n",
    "<img src=\"./fig/concat.png\" alt=\"concat\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "下面给出 `PeekyDecoder` 类的实现。这里仅显示初始化 `__init__()` 方法和正向传播 `forward()` 方法。因为没有特别难的地方，所以这里省略了反向传播 `backward()` 方法和文本生成 `generate()` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6a0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "from common.time_layers import *\n",
    "from seq2seq import Seq2seq, Encoder\n",
    "\n",
    "\n",
    "class PeekyDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size # 词典大小、词向量维度、隐藏状态维度\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f') # 词嵌入矩阵\n",
    "        lstm_Wx = (rn(H + D, 4 * H) / np.sqrt(H + D)).astype('f') # LSTM的输入权重\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f') # LSTM的隐藏状态权重\n",
    "        lstm_b = np.zeros(4 * H).astype('f') # LSTM的偏置\n",
    "        affine_W = (rn(H + H, V) / np.sqrt(H + H)).astype('f') # 仿射变换的权重\n",
    "        affine_b = np.zeros(V).astype('f') # 仿射变换的偏置\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W) # 词嵌入层\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True) # LSTM层\n",
    "        self.affine = TimeAffine(affine_W, affine_b) # 仿射变换层\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        N, T = xs.shape # xs的形状为 (N, T)\n",
    "        N, H = h.shape # h的形状为 (N, H)\n",
    "\n",
    "        self.lstm.set_state(h) # 设置LSTM的隐藏状态\n",
    "\n",
    "        out = self.embed.forward(xs) # 词嵌入层的前向传播，将单词ID转换为词向量，形状为 (N, T, D)\n",
    "        hs = np.repeat(h, T, axis=0).reshape(N, T, H) # h在时间轴上重复，形状为 (N, T, H)\n",
    "        out = np.concatenate((hs, out), axis=2) # 将hs和out在特征维度上连接，形状为 (N, T, H + D)\n",
    "\n",
    "        out = self.lstm.forward(out) # LSTM层的前向传播，形状为 (N, T, H)\n",
    "        out = np.concatenate((hs, out), axis=2) # 将hs和out在特征维度上连接，形状为 (N, T, H + H)\n",
    "\n",
    "        score = self.affine.forward(out) # 仿射变换层的前向传播，形状为 (N, T, V)\n",
    "        self.cache = H\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        H = self.cache # 从缓存中获取隐藏状态的维度\n",
    "\n",
    "        dout = self.affine.backward(dscore) # 仿射变换层的反向传播，得到LSTM层的梯度，形状为 (N, T, H + H)\n",
    "        dout, dhs0 = dout[:, :, H:], dout[:, :, :H] # 分离出LSTM的输出梯度和h的梯度\n",
    "        dout = self.lstm.backward(dout) # LSTM层的反向传播，得到词嵌入层的梯度，形状为 (N, T, D + H)\n",
    "        dembed, dhs1 = dout[:, :, H:], dout[:, :, :H] # 分离出词嵌入层的梯度和h的梯度\n",
    "        self.embed.backward(dembed)\n",
    "\n",
    "        dhs = dhs0 + dhs1 # 将两个h的梯度相加\n",
    "        dh = self.lstm.dh + np.sum(dhs, axis=1) # 计算最终的h的梯度\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = [] # 采样的单词ID列表\n",
    "        char_id = start_id # 当前采样的单词ID\n",
    "        self.lstm.set_state(h) # 设置LSTM的隐藏状态\n",
    "\n",
    "        H = h.shape[1] # 隐藏状态的维度\n",
    "        peeky_h = h.reshape(1, 1, H) # 形状为 (1, 1, H)\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([char_id]).reshape((1, 1)) # 整理成形状为1 × 1的数组\n",
    "            out = self.embed.forward(x) # 词嵌入层的前向传播，形状为 (1, 1, D)\n",
    "\n",
    "            out = np.concatenate((peeky_h, out), axis=2) # 将peeky_h和out在特征维度上连接，形状为 (1, 1, H + D)\n",
    "            out = self.lstm.forward(out) # LSTM层的前向传播，形状为 (1, 1, H)\n",
    "            out = np.concatenate((peeky_h, out), axis=2) # 将peeky_h和out在特征维度上连接，形状为 (1, 1, H + H)\n",
    "            score = self.affine.forward(out) # 仿射变换层的前向传播，形状为 (1, 1, V)\n",
    "\n",
    "            char_id = np.argmax(score.flatten()) # 选择概率最高的单词ID\n",
    "            sampled.append(char_id) # 将采样的单词ID添加到结果列表中\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bba3f",
   "metadata": {},
   "source": [
    "`PeekyDecoder` 的初始化和上一节的 `Decoder` 基本上是一样的，不同之处仅在于 `LSTM` 层权重和 `Affine` 层权重的形状。因为这次的实现要接收编码器编码好的向量，所以权重参数的形状相应地变大了。\n",
    "\n",
    "接着是 `forward()` 的实现。这里首先使用 `np.repeat()` 根据时序大小复制相应份数的 `h`，并将其设置为 `hs`。然后，将 `hs` 和 `Embedding` 层的输出用 `np.concatenate()` 拼接，并输入 `LSTM` 层。同样地，`Affine` 层的输入也是 `hs` 和 `LSTM` 层的输出的拼接。\n",
    "\n",
    "编码器和上一节没有变化，因此直接使用上一节的编码器。\n",
    "\n",
    "最后，我们来实现 `PeekySeq2seq`，不过这和上一节的 `Seq2seq` 类基本相同，唯一的区别是 `Decoder` 层。上一节的 `Seq2seq` 类使用了 `Decoder` 类，与此相对，这里使用 `PeekyDecoder`，剩余的逻辑完全一样。因此，`PeekySeq2seq` 类的实现只需要继承上一章的 `Seq2seq` 类，并修改一下初始化部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ef16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq import Seq2seq, Encoder\n",
    "\n",
    "class PeekySeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = PeekyDecoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d835e21a",
   "metadata": {},
   "source": [
    "至此，准备工作就完成了。现在我们使用这个 `PeekySeq2seq` 类，再次挑战加法问题。学习用代码仍使用上一节的代码，只需要将 `Seq2seq` 类换成 `PeekySeq2seq` 类。\n",
    "\n",
    "```python\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c87d849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 2.57\n",
      "| epoch 1 |  iter 21 / 351 | time 0[s] | loss 2.48\n",
      "| epoch 1 |  iter 41 / 351 | time 1[s] | loss 2.20\n",
      "| epoch 1 |  iter 61 / 351 | time 1[s] | loss 1.99\n",
      "| epoch 1 |  iter 81 / 351 | time 2[s] | loss 1.89\n",
      "| epoch 1 |  iter 101 / 351 | time 3[s] | loss 1.82\n",
      "| epoch 1 |  iter 121 / 351 | time 3[s] | loss 1.82\n",
      "| epoch 1 |  iter 141 / 351 | time 4[s] | loss 1.80\n",
      "| epoch 1 |  iter 161 / 351 | time 4[s] | loss 1.79\n",
      "| epoch 1 |  iter 181 / 351 | time 5[s] | loss 1.78\n",
      "| epoch 1 |  iter 201 / 351 | time 6[s] | loss 1.77\n",
      "| epoch 1 |  iter 221 / 351 | time 6[s] | loss 1.76\n",
      "| epoch 1 |  iter 241 / 351 | time 7[s] | loss 1.76\n",
      "| epoch 1 |  iter 261 / 351 | time 7[s] | loss 1.75\n",
      "| epoch 1 |  iter 281 / 351 | time 8[s] | loss 1.74\n",
      "| epoch 1 |  iter 301 / 351 | time 9[s] | loss 1.74\n",
      "| epoch 1 |  iter 321 / 351 | time 9[s] | loss 1.73\n",
      "| epoch 1 |  iter 341 / 351 | time 10[s] | loss 1.73\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1013\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 102 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 1023\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1023\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1023\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1111\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 102 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 102 \n",
      "---\n",
      "验证集准确率 0.280%\n",
      "| epoch 2 |  iter 1 / 351 | time 0[s] | loss 1.71\n",
      "| epoch 2 |  iter 21 / 351 | time 0[s] | loss 1.71\n",
      "| epoch 2 |  iter 41 / 351 | time 1[s] | loss 1.71\n",
      "| epoch 2 |  iter 61 / 351 | time 1[s] | loss 1.71\n",
      "| epoch 2 |  iter 81 / 351 | time 2[s] | loss 1.70\n",
      "| epoch 2 |  iter 101 / 351 | time 3[s] | loss 1.68\n",
      "| epoch 2 |  iter 121 / 351 | time 3[s] | loss 1.69\n",
      "| epoch 2 |  iter 141 / 351 | time 4[s] | loss 1.68\n",
      "| epoch 2 |  iter 161 / 351 | time 4[s] | loss 1.67\n",
      "| epoch 2 |  iter 181 / 351 | time 5[s] | loss 1.67\n",
      "| epoch 2 |  iter 201 / 351 | time 6[s] | loss 1.65\n",
      "| epoch 2 |  iter 221 / 351 | time 6[s] | loss 1.65\n",
      "| epoch 2 |  iter 241 / 351 | time 7[s] | loss 1.65\n",
      "| epoch 2 |  iter 261 / 351 | time 8[s] | loss 1.63\n",
      "| epoch 2 |  iter 281 / 351 | time 8[s] | loss 1.62\n",
      "| epoch 2 |  iter 301 / 351 | time 9[s] | loss 1.61\n",
      "| epoch 2 |  iter 321 / 351 | time 9[s] | loss 1.61\n",
      "| epoch 2 |  iter 341 / 351 | time 10[s] | loss 1.60\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1200\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 690 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 690 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 999 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1029\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1240\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 792 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 290 \n",
      "---\n",
      "验证集准确率 0.400%\n",
      "| epoch 3 |  iter 1 / 351 | time 0[s] | loss 1.58\n",
      "| epoch 3 |  iter 21 / 351 | time 0[s] | loss 1.59\n",
      "| epoch 3 |  iter 41 / 351 | time 1[s] | loss 1.58\n",
      "| epoch 3 |  iter 61 / 351 | time 1[s] | loss 1.56\n",
      "| epoch 3 |  iter 81 / 351 | time 2[s] | loss 1.55\n",
      "| epoch 3 |  iter 101 / 351 | time 3[s] | loss 1.53\n",
      "| epoch 3 |  iter 121 / 351 | time 3[s] | loss 1.51\n",
      "| epoch 3 |  iter 141 / 351 | time 4[s] | loss 1.50\n",
      "| epoch 3 |  iter 161 / 351 | time 5[s] | loss 1.49\n",
      "| epoch 3 |  iter 181 / 351 | time 5[s] | loss 1.47\n",
      "| epoch 3 |  iter 201 / 351 | time 6[s] | loss 1.46\n",
      "| epoch 3 |  iter 221 / 351 | time 6[s] | loss 1.43\n",
      "| epoch 3 |  iter 241 / 351 | time 7[s] | loss 1.42\n",
      "| epoch 3 |  iter 261 / 351 | time 8[s] | loss 1.41\n",
      "| epoch 3 |  iter 281 / 351 | time 8[s] | loss 1.39\n",
      "| epoch 3 |  iter 301 / 351 | time 9[s] | loss 1.37\n",
      "| epoch 3 |  iter 321 / 351 | time 9[s] | loss 1.36\n",
      "| epoch 3 |  iter 341 / 351 | time 10[s] | loss 1.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 154 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1033\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 644 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 161 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 433 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 818 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1018\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1344\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 834 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 211 \n",
      "---\n",
      "验证集准确率 1.600%\n",
      "| epoch 4 |  iter 1 / 351 | time 0[s] | loss 1.32\n",
      "| epoch 4 |  iter 21 / 351 | time 0[s] | loss 1.32\n",
      "| epoch 4 |  iter 41 / 351 | time 1[s] | loss 1.30\n",
      "| epoch 4 |  iter 61 / 351 | time 1[s] | loss 1.30\n",
      "| epoch 4 |  iter 81 / 351 | time 2[s] | loss 1.28\n",
      "| epoch 4 |  iter 101 / 351 | time 3[s] | loss 1.27\n",
      "| epoch 4 |  iter 121 / 351 | time 3[s] | loss 1.25\n",
      "| epoch 4 |  iter 141 / 351 | time 4[s] | loss 1.24\n",
      "| epoch 4 |  iter 161 / 351 | time 4[s] | loss 1.22\n",
      "| epoch 4 |  iter 181 / 351 | time 5[s] | loss 1.21\n",
      "| epoch 4 |  iter 201 / 351 | time 6[s] | loss 1.20\n",
      "| epoch 4 |  iter 221 / 351 | time 6[s] | loss 1.20\n",
      "| epoch 4 |  iter 241 / 351 | time 7[s] | loss 1.17\n",
      "| epoch 4 |  iter 261 / 351 | time 8[s] | loss 1.16\n",
      "| epoch 4 |  iter 281 / 351 | time 8[s] | loss 1.14\n",
      "| epoch 4 |  iter 301 / 351 | time 9[s] | loss 1.12\n",
      "| epoch 4 |  iter 321 / 351 | time 9[s] | loss 1.11\n",
      "| epoch 4 |  iter 341 / 351 | time 10[s] | loss 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 158 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1123\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 165 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 777 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1023\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1388\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 887 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 223 \n",
      "---\n",
      "验证集准确率 5.140%\n",
      "| epoch 5 |  iter 1 / 351 | time 0[s] | loss 1.08\n",
      "| epoch 5 |  iter 21 / 351 | time 0[s] | loss 1.07\n",
      "| epoch 5 |  iter 41 / 351 | time 1[s] | loss 1.05\n",
      "| epoch 5 |  iter 61 / 351 | time 2[s] | loss 1.04\n",
      "| epoch 5 |  iter 81 / 351 | time 2[s] | loss 1.02\n",
      "| epoch 5 |  iter 101 / 351 | time 3[s] | loss 1.01\n",
      "| epoch 5 |  iter 121 / 351 | time 3[s] | loss 1.00\n",
      "| epoch 5 |  iter 141 / 351 | time 4[s] | loss 0.99\n",
      "| epoch 5 |  iter 161 / 351 | time 5[s] | loss 0.99\n",
      "| epoch 5 |  iter 181 / 351 | time 5[s] | loss 0.96\n",
      "| epoch 5 |  iter 201 / 351 | time 6[s] | loss 0.95\n",
      "| epoch 5 |  iter 221 / 351 | time 6[s] | loss 0.94\n",
      "| epoch 5 |  iter 241 / 351 | time 7[s] | loss 0.92\n",
      "| epoch 5 |  iter 261 / 351 | time 8[s] | loss 0.91\n",
      "| epoch 5 |  iter 281 / 351 | time 8[s] | loss 0.90\n",
      "| epoch 5 |  iter 301 / 351 | time 9[s] | loss 0.89\n",
      "| epoch 5 |  iter 321 / 351 | time 10[s] | loss 0.88\n",
      "| epoch 5 |  iter 341 / 351 | time 10[s] | loss 0.87\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1135\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 169 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 861 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1045\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1324\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 861 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 239 \n",
      "---\n",
      "验证集准确率 9.380%\n",
      "| epoch 6 |  iter 1 / 351 | time 0[s] | loss 0.90\n",
      "| epoch 6 |  iter 21 / 351 | time 0[s] | loss 0.86\n",
      "| epoch 6 |  iter 41 / 351 | time 1[s] | loss 0.83\n",
      "| epoch 6 |  iter 61 / 351 | time 1[s] | loss 0.84\n",
      "| epoch 6 |  iter 81 / 351 | time 2[s] | loss 0.82\n",
      "| epoch 6 |  iter 101 / 351 | time 3[s] | loss 0.81\n",
      "| epoch 6 |  iter 121 / 351 | time 3[s] | loss 0.80\n",
      "| epoch 6 |  iter 141 / 351 | time 4[s] | loss 0.79\n",
      "| epoch 6 |  iter 161 / 351 | time 4[s] | loss 0.78\n",
      "| epoch 6 |  iter 181 / 351 | time 5[s] | loss 0.77\n",
      "| epoch 6 |  iter 201 / 351 | time 6[s] | loss 0.76\n",
      "| epoch 6 |  iter 221 / 351 | time 6[s] | loss 0.76\n",
      "| epoch 6 |  iter 241 / 351 | time 7[s] | loss 0.74\n",
      "| epoch 6 |  iter 261 / 351 | time 7[s] | loss 0.74\n",
      "| epoch 6 |  iter 281 / 351 | time 8[s] | loss 0.73\n",
      "| epoch 6 |  iter 301 / 351 | time 9[s] | loss 0.72\n",
      "| epoch 6 |  iter 321 / 351 | time 9[s] | loss 0.72\n",
      "| epoch 6 |  iter 341 / 351 | time 10[s] | loss 0.71\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 163 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1138\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 668 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 166 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 423 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1048\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 873 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 239 \n",
      "---\n",
      "验证集准确率 15.040%\n",
      "| epoch 7 |  iter 1 / 351 | time 0[s] | loss 0.68\n",
      "| epoch 7 |  iter 21 / 351 | time 0[s] | loss 0.69\n",
      "| epoch 7 |  iter 41 / 351 | time 1[s] | loss 0.67\n",
      "| epoch 7 |  iter 61 / 351 | time 1[s] | loss 0.66\n",
      "| epoch 7 |  iter 81 / 351 | time 2[s] | loss 0.66\n",
      "| epoch 7 |  iter 101 / 351 | time 3[s] | loss 0.65\n",
      "| epoch 7 |  iter 121 / 351 | time 3[s] | loss 0.65\n",
      "| epoch 7 |  iter 141 / 351 | time 4[s] | loss 0.64\n",
      "| epoch 7 |  iter 161 / 351 | time 4[s] | loss 0.63\n",
      "| epoch 7 |  iter 181 / 351 | time 5[s] | loss 0.61\n",
      "| epoch 7 |  iter 201 / 351 | time 6[s] | loss 0.61\n",
      "| epoch 7 |  iter 221 / 351 | time 6[s] | loss 0.60\n",
      "| epoch 7 |  iter 241 / 351 | time 7[s] | loss 0.57\n",
      "| epoch 7 |  iter 261 / 351 | time 7[s] | loss 0.57\n",
      "| epoch 7 |  iter 281 / 351 | time 8[s] | loss 0.57\n",
      "| epoch 7 |  iter 301 / 351 | time 9[s] | loss 0.55\n",
      "| epoch 7 |  iter 321 / 351 | time 9[s] | loss 0.54\n",
      "| epoch 7 |  iter 341 / 351 | time 10[s] | loss 0.53\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 156 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 858 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1052\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1428\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 235 \n",
      "---\n",
      "验证集准确率 39.100%\n",
      "| epoch 8 |  iter 1 / 351 | time 0[s] | loss 0.51\n",
      "| epoch 8 |  iter 21 / 351 | time 0[s] | loss 0.50\n",
      "| epoch 8 |  iter 41 / 351 | time 1[s] | loss 0.49\n",
      "| epoch 8 |  iter 61 / 351 | time 1[s] | loss 0.48\n",
      "| epoch 8 |  iter 81 / 351 | time 2[s] | loss 0.47\n",
      "| epoch 8 |  iter 101 / 351 | time 3[s] | loss 0.46\n",
      "| epoch 8 |  iter 121 / 351 | time 3[s] | loss 0.46\n",
      "| epoch 8 |  iter 141 / 351 | time 4[s] | loss 0.44\n",
      "| epoch 8 |  iter 161 / 351 | time 4[s] | loss 0.41\n",
      "| epoch 8 |  iter 181 / 351 | time 5[s] | loss 0.42\n",
      "| epoch 8 |  iter 201 / 351 | time 6[s] | loss 0.41\n",
      "| epoch 8 |  iter 221 / 351 | time 6[s] | loss 0.40\n",
      "| epoch 8 |  iter 241 / 351 | time 7[s] | loss 0.39\n",
      "| epoch 8 |  iter 261 / 351 | time 8[s] | loss 0.37\n",
      "| epoch 8 |  iter 281 / 351 | time 8[s] | loss 0.36\n",
      "| epoch 8 |  iter 301 / 351 | time 9[s] | loss 0.36\n",
      "| epoch 8 |  iter 321 / 351 | time 9[s] | loss 0.35\n",
      "| epoch 8 |  iter 341 / 351 | time 10[s] | loss 0.34\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 161 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 155 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1438\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 65.060%\n",
      "| epoch 9 |  iter 1 / 351 | time 0[s] | loss 0.32\n",
      "| epoch 9 |  iter 21 / 351 | time 0[s] | loss 0.31\n",
      "| epoch 9 |  iter 41 / 351 | time 1[s] | loss 0.31\n",
      "| epoch 9 |  iter 61 / 351 | time 1[s] | loss 0.31\n",
      "| epoch 9 |  iter 81 / 351 | time 2[s] | loss 0.29\n",
      "| epoch 9 |  iter 101 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 9 |  iter 121 / 351 | time 3[s] | loss 0.29\n",
      "| epoch 9 |  iter 141 / 351 | time 4[s] | loss 0.27\n",
      "| epoch 9 |  iter 161 / 351 | time 4[s] | loss 0.27\n",
      "| epoch 9 |  iter 181 / 351 | time 5[s] | loss 0.26\n",
      "| epoch 9 |  iter 201 / 351 | time 6[s] | loss 0.25\n",
      "| epoch 9 |  iter 221 / 351 | time 6[s] | loss 0.25\n",
      "| epoch 9 |  iter 241 / 351 | time 7[s] | loss 0.24\n",
      "| epoch 9 |  iter 261 / 351 | time 7[s] | loss 0.24\n",
      "| epoch 9 |  iter 281 / 351 | time 8[s] | loss 0.23\n",
      "| epoch 9 |  iter 301 / 351 | time 9[s] | loss 0.22\n",
      "| epoch 9 |  iter 321 / 351 | time 9[s] | loss 0.22\n",
      "| epoch 9 |  iter 341 / 351 | time 10[s] | loss 0.21\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1140\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 657 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 83.280%\n",
      "| epoch 10 |  iter 1 / 351 | time 0[s] | loss 0.22\n",
      "| epoch 10 |  iter 21 / 351 | time 0[s] | loss 0.20\n",
      "| epoch 10 |  iter 41 / 351 | time 1[s] | loss 0.20\n",
      "| epoch 10 |  iter 61 / 351 | time 1[s] | loss 0.20\n",
      "| epoch 10 |  iter 81 / 351 | time 2[s] | loss 0.18\n",
      "| epoch 10 |  iter 101 / 351 | time 3[s] | loss 0.17\n",
      "| epoch 10 |  iter 121 / 351 | time 3[s] | loss 0.18\n",
      "| epoch 10 |  iter 141 / 351 | time 4[s] | loss 0.17\n",
      "| epoch 10 |  iter 161 / 351 | time 4[s] | loss 0.17\n",
      "| epoch 10 |  iter 181 / 351 | time 5[s] | loss 0.17\n",
      "| epoch 10 |  iter 201 / 351 | time 6[s] | loss 0.17\n",
      "| epoch 10 |  iter 221 / 351 | time 6[s] | loss 0.16\n",
      "| epoch 10 |  iter 241 / 351 | time 7[s] | loss 0.15\n",
      "| epoch 10 |  iter 261 / 351 | time 7[s] | loss 0.15\n",
      "| epoch 10 |  iter 281 / 351 | time 8[s] | loss 0.15\n",
      "| epoch 10 |  iter 301 / 351 | time 9[s] | loss 0.15\n",
      "| epoch 10 |  iter 321 / 351 | time 9[s] | loss 0.14\n",
      "| epoch 10 |  iter 341 / 351 | time 10[s] | loss 0.14\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 656 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 88.400%\n",
      "| epoch 11 |  iter 1 / 351 | time 0[s] | loss 0.13\n",
      "| epoch 11 |  iter 21 / 351 | time 0[s] | loss 0.13\n",
      "| epoch 11 |  iter 41 / 351 | time 1[s] | loss 0.13\n",
      "| epoch 11 |  iter 61 / 351 | time 1[s] | loss 0.12\n",
      "| epoch 11 |  iter 81 / 351 | time 2[s] | loss 0.12\n",
      "| epoch 11 |  iter 101 / 351 | time 3[s] | loss 0.12\n",
      "| epoch 11 |  iter 121 / 351 | time 3[s] | loss 0.11\n",
      "| epoch 11 |  iter 141 / 351 | time 4[s] | loss 0.12\n",
      "| epoch 11 |  iter 161 / 351 | time 4[s] | loss 0.11\n",
      "| epoch 11 |  iter 181 / 351 | time 5[s] | loss 0.11\n",
      "| epoch 11 |  iter 201 / 351 | time 6[s] | loss 0.12\n",
      "| epoch 11 |  iter 221 / 351 | time 6[s] | loss 0.11\n",
      "| epoch 11 |  iter 241 / 351 | time 7[s] | loss 0.11\n",
      "| epoch 11 |  iter 261 / 351 | time 7[s] | loss 0.10\n",
      "| epoch 11 |  iter 281 / 351 | time 8[s] | loss 0.10\n",
      "| epoch 11 |  iter 301 / 351 | time 9[s] | loss 0.10\n",
      "| epoch 11 |  iter 321 / 351 | time 9[s] | loss 0.09\n",
      "| epoch 11 |  iter 341 / 351 | time 10[s] | loss 0.09\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 90.940%\n",
      "| epoch 12 |  iter 1 / 351 | time 0[s] | loss 0.09\n",
      "| epoch 12 |  iter 21 / 351 | time 0[s] | loss 0.09\n",
      "| epoch 12 |  iter 41 / 351 | time 1[s] | loss 0.09\n",
      "| epoch 12 |  iter 61 / 351 | time 1[s] | loss 0.09\n",
      "| epoch 12 |  iter 81 / 351 | time 2[s] | loss 0.09\n",
      "| epoch 12 |  iter 101 / 351 | time 3[s] | loss 0.08\n",
      "| epoch 12 |  iter 121 / 351 | time 3[s] | loss 0.08\n",
      "| epoch 12 |  iter 141 / 351 | time 4[s] | loss 0.08\n",
      "| epoch 12 |  iter 161 / 351 | time 4[s] | loss 0.08\n",
      "| epoch 12 |  iter 181 / 351 | time 5[s] | loss 0.08\n",
      "| epoch 12 |  iter 201 / 351 | time 6[s] | loss 0.08\n",
      "| epoch 12 |  iter 221 / 351 | time 6[s] | loss 0.09\n",
      "| epoch 12 |  iter 241 / 351 | time 7[s] | loss 0.09\n",
      "| epoch 12 |  iter 261 / 351 | time 8[s] | loss 0.09\n",
      "| epoch 12 |  iter 281 / 351 | time 8[s] | loss 0.08\n",
      "| epoch 12 |  iter 301 / 351 | time 9[s] | loss 0.08\n",
      "| epoch 12 |  iter 321 / 351 | time 9[s] | loss 0.07\n",
      "| epoch 12 |  iter 341 / 351 | time 10[s] | loss 0.08\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 92.220%\n",
      "| epoch 13 |  iter 1 / 351 | time 0[s] | loss 0.07\n",
      "| epoch 13 |  iter 21 / 351 | time 0[s] | loss 0.07\n",
      "| epoch 13 |  iter 41 / 351 | time 1[s] | loss 0.07\n",
      "| epoch 13 |  iter 61 / 351 | time 1[s] | loss 0.07\n",
      "| epoch 13 |  iter 81 / 351 | time 2[s] | loss 0.06\n",
      "| epoch 13 |  iter 101 / 351 | time 3[s] | loss 0.06\n",
      "| epoch 13 |  iter 121 / 351 | time 3[s] | loss 0.07\n",
      "| epoch 13 |  iter 141 / 351 | time 4[s] | loss 0.06\n",
      "| epoch 13 |  iter 161 / 351 | time 4[s] | loss 0.06\n",
      "| epoch 13 |  iter 181 / 351 | time 5[s] | loss 0.06\n",
      "| epoch 13 |  iter 201 / 351 | time 6[s] | loss 0.06\n",
      "| epoch 13 |  iter 221 / 351 | time 6[s] | loss 0.06\n",
      "| epoch 13 |  iter 241 / 351 | time 7[s] | loss 0.06\n",
      "| epoch 13 |  iter 261 / 351 | time 7[s] | loss 0.06\n",
      "| epoch 13 |  iter 281 / 351 | time 8[s] | loss 0.06\n",
      "| epoch 13 |  iter 301 / 351 | time 9[s] | loss 0.05\n",
      "| epoch 13 |  iter 321 / 351 | time 9[s] | loss 0.05\n",
      "| epoch 13 |  iter 341 / 351 | time 10[s] | loss 0.06\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 94.380%\n",
      "| epoch 14 |  iter 1 / 351 | time 0[s] | loss 0.05\n",
      "| epoch 14 |  iter 21 / 351 | time 0[s] | loss 0.05\n",
      "| epoch 14 |  iter 41 / 351 | time 1[s] | loss 0.05\n",
      "| epoch 14 |  iter 61 / 351 | time 1[s] | loss 0.05\n",
      "| epoch 14 |  iter 81 / 351 | time 2[s] | loss 0.05\n",
      "| epoch 14 |  iter 101 / 351 | time 3[s] | loss 0.05\n",
      "| epoch 14 |  iter 121 / 351 | time 3[s] | loss 0.05\n",
      "| epoch 14 |  iter 141 / 351 | time 4[s] | loss 0.05\n",
      "| epoch 14 |  iter 161 / 351 | time 4[s] | loss 0.05\n",
      "| epoch 14 |  iter 181 / 351 | time 5[s] | loss 0.05\n",
      "| epoch 14 |  iter 201 / 351 | time 6[s] | loss 0.05\n",
      "| epoch 14 |  iter 221 / 351 | time 6[s] | loss 0.06\n",
      "| epoch 14 |  iter 241 / 351 | time 7[s] | loss 0.06\n",
      "| epoch 14 |  iter 261 / 351 | time 8[s] | loss 0.07\n",
      "| epoch 14 |  iter 281 / 351 | time 8[s] | loss 0.06\n",
      "| epoch 14 |  iter 301 / 351 | time 9[s] | loss 0.06\n",
      "| epoch 14 |  iter 321 / 351 | time 9[s] | loss 0.05\n",
      "| epoch 14 |  iter 341 / 351 | time 10[s] | loss 0.05\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 95.240%\n",
      "| epoch 15 |  iter 1 / 351 | time 0[s] | loss 0.04\n",
      "| epoch 15 |  iter 21 / 351 | time 0[s] | loss 0.04\n",
      "| epoch 15 |  iter 41 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 15 |  iter 61 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 15 |  iter 81 / 351 | time 2[s] | loss 0.04\n",
      "| epoch 15 |  iter 101 / 351 | time 3[s] | loss 0.05\n",
      "| epoch 15 |  iter 121 / 351 | time 3[s] | loss 0.04\n",
      "| epoch 15 |  iter 141 / 351 | time 4[s] | loss 0.04\n",
      "| epoch 15 |  iter 161 / 351 | time 4[s] | loss 0.04\n",
      "| epoch 15 |  iter 181 / 351 | time 5[s] | loss 0.05\n",
      "| epoch 15 |  iter 201 / 351 | time 6[s] | loss 0.04\n",
      "| epoch 15 |  iter 221 / 351 | time 6[s] | loss 0.04\n",
      "| epoch 15 |  iter 241 / 351 | time 7[s] | loss 0.04\n",
      "| epoch 15 |  iter 261 / 351 | time 8[s] | loss 0.04\n",
      "| epoch 15 |  iter 281 / 351 | time 8[s] | loss 0.04\n",
      "| epoch 15 |  iter 301 / 351 | time 9[s] | loss 0.05\n",
      "| epoch 15 |  iter 321 / 351 | time 9[s] | loss 0.05\n",
      "| epoch 15 |  iter 341 / 351 | time 10[s] | loss 0.05\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1149\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 92.820%\n",
      "| epoch 16 |  iter 1 / 351 | time 0[s] | loss 0.04\n",
      "| epoch 16 |  iter 21 / 351 | time 0[s] | loss 0.05\n",
      "| epoch 16 |  iter 41 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 16 |  iter 61 / 351 | time 1[s] | loss 0.05\n",
      "| epoch 16 |  iter 81 / 351 | time 2[s] | loss 0.05\n",
      "| epoch 16 |  iter 101 / 351 | time 3[s] | loss 0.04\n",
      "| epoch 16 |  iter 121 / 351 | time 3[s] | loss 0.04\n",
      "| epoch 16 |  iter 141 / 351 | time 4[s] | loss 0.04\n",
      "| epoch 16 |  iter 161 / 351 | time 4[s] | loss 0.03\n",
      "| epoch 16 |  iter 181 / 351 | time 5[s] | loss 0.03\n",
      "| epoch 16 |  iter 201 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 16 |  iter 221 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 16 |  iter 241 / 351 | time 7[s] | loss 0.03\n",
      "| epoch 16 |  iter 261 / 351 | time 7[s] | loss 0.03\n",
      "| epoch 16 |  iter 281 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 16 |  iter 301 / 351 | time 9[s] | loss 0.03\n",
      "| epoch 16 |  iter 321 / 351 | time 9[s] | loss 0.03\n",
      "| epoch 16 |  iter 341 / 351 | time 10[s] | loss 0.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 97.060%\n",
      "| epoch 17 |  iter 1 / 351 | time 0[s] | loss 0.04\n",
      "| epoch 17 |  iter 21 / 351 | time 0[s] | loss 0.03\n",
      "| epoch 17 |  iter 41 / 351 | time 1[s] | loss 0.03\n",
      "| epoch 17 |  iter 61 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 17 |  iter 81 / 351 | time 2[s] | loss 0.04\n",
      "| epoch 17 |  iter 101 / 351 | time 3[s] | loss 0.04\n",
      "| epoch 17 |  iter 121 / 351 | time 3[s] | loss 0.04\n",
      "| epoch 17 |  iter 141 / 351 | time 4[s] | loss 0.04\n",
      "| epoch 17 |  iter 161 / 351 | time 5[s] | loss 0.03\n",
      "| epoch 17 |  iter 181 / 351 | time 5[s] | loss 0.03\n",
      "| epoch 17 |  iter 201 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 17 |  iter 221 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 17 |  iter 241 / 351 | time 7[s] | loss 0.04\n",
      "| epoch 17 |  iter 261 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 17 |  iter 281 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 17 |  iter 301 / 351 | time 9[s] | loss 0.04\n",
      "| epoch 17 |  iter 321 / 351 | time 10[s] | loss 0.04\n",
      "| epoch 17 |  iter 341 / 351 | time 10[s] | loss 0.05\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 90.680%\n",
      "| epoch 18 |  iter 1 / 351 | time 0[s] | loss 0.05\n",
      "| epoch 18 |  iter 21 / 351 | time 0[s] | loss 0.05\n",
      "| epoch 18 |  iter 41 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 18 |  iter 61 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 18 |  iter 81 / 351 | time 2[s] | loss 0.03\n",
      "| epoch 18 |  iter 101 / 351 | time 3[s] | loss 0.03\n",
      "| epoch 18 |  iter 121 / 351 | time 3[s] | loss 0.03\n",
      "| epoch 18 |  iter 141 / 351 | time 4[s] | loss 0.03\n",
      "| epoch 18 |  iter 161 / 351 | time 4[s] | loss 0.03\n",
      "| epoch 18 |  iter 181 / 351 | time 5[s] | loss 0.03\n",
      "| epoch 18 |  iter 201 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 18 |  iter 221 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 18 |  iter 241 / 351 | time 7[s] | loss 0.03\n",
      "| epoch 18 |  iter 261 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 18 |  iter 281 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 18 |  iter 301 / 351 | time 9[s] | loss 0.02\n",
      "| epoch 18 |  iter 321 / 351 | time 9[s] | loss 0.02\n",
      "| epoch 18 |  iter 341 / 351 | time 10[s] | loss 0.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 95.600%\n",
      "| epoch 19 |  iter 1 / 351 | time 0[s] | loss 0.03\n",
      "| epoch 19 |  iter 21 / 351 | time 0[s] | loss 0.03\n",
      "| epoch 19 |  iter 41 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 19 |  iter 61 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 19 |  iter 81 / 351 | time 2[s] | loss 0.02\n",
      "| epoch 19 |  iter 101 / 351 | time 3[s] | loss 0.02\n",
      "| epoch 19 |  iter 121 / 351 | time 3[s] | loss 0.02\n",
      "| epoch 19 |  iter 141 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 19 |  iter 161 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 19 |  iter 181 / 351 | time 5[s] | loss 0.03\n",
      "| epoch 19 |  iter 201 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 19 |  iter 221 / 351 | time 6[s] | loss 0.03\n",
      "| epoch 19 |  iter 241 / 351 | time 7[s] | loss 0.03\n",
      "| epoch 19 |  iter 261 / 351 | time 8[s] | loss 0.05\n",
      "| epoch 19 |  iter 281 / 351 | time 8[s] | loss 0.07\n",
      "| epoch 19 |  iter 301 / 351 | time 9[s] | loss 0.07\n",
      "| epoch 19 |  iter 321 / 351 | time 10[s] | loss 0.04\n",
      "| epoch 19 |  iter 341 / 351 | time 10[s] | loss 0.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 95.800%\n",
      "| epoch 20 |  iter 1 / 351 | time 0[s] | loss 0.04\n",
      "| epoch 20 |  iter 21 / 351 | time 0[s] | loss 0.03\n",
      "| epoch 20 |  iter 41 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 20 |  iter 61 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 20 |  iter 81 / 351 | time 2[s] | loss 0.02\n",
      "| epoch 20 |  iter 101 / 351 | time 3[s] | loss 0.03\n",
      "| epoch 20 |  iter 121 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 20 |  iter 141 / 351 | time 5[s] | loss 0.02\n",
      "| epoch 20 |  iter 161 / 351 | time 6[s] | loss 0.02\n",
      "| epoch 20 |  iter 181 / 351 | time 6[s] | loss 0.02\n",
      "| epoch 20 |  iter 201 / 351 | time 7[s] | loss 0.02\n",
      "| epoch 20 |  iter 221 / 351 | time 8[s] | loss 0.02\n",
      "| epoch 20 |  iter 241 / 351 | time 9[s] | loss 0.02\n",
      "| epoch 20 |  iter 261 / 351 | time 9[s] | loss 0.02\n",
      "| epoch 20 |  iter 281 / 351 | time 10[s] | loss 0.01\n",
      "| epoch 20 |  iter 301 / 351 | time 11[s] | loss 0.02\n",
      "| epoch 20 |  iter 321 / 351 | time 12[s] | loss 0.02\n",
      "| epoch 20 |  iter 341 / 351 | time 13[s] | loss 0.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 97.020%\n",
      "| epoch 21 |  iter 1 / 351 | time 0[s] | loss 0.03\n",
      "| epoch 21 |  iter 21 / 351 | time 0[s] | loss 0.02\n",
      "| epoch 21 |  iter 41 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 21 |  iter 61 / 351 | time 2[s] | loss 0.02\n",
      "| epoch 21 |  iter 81 / 351 | time 3[s] | loss 0.02\n",
      "| epoch 21 |  iter 101 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 21 |  iter 121 / 351 | time 5[s] | loss 0.03\n",
      "| epoch 21 |  iter 141 / 351 | time 6[s] | loss 0.05\n",
      "| epoch 21 |  iter 161 / 351 | time 7[s] | loss 0.04\n",
      "| epoch 21 |  iter 181 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 21 |  iter 201 / 351 | time 9[s] | loss 0.03\n",
      "| epoch 21 |  iter 221 / 351 | time 9[s] | loss 0.02\n",
      "| epoch 21 |  iter 241 / 351 | time 10[s] | loss 0.02\n",
      "| epoch 21 |  iter 261 / 351 | time 11[s] | loss 0.02\n",
      "| epoch 21 |  iter 281 / 351 | time 12[s] | loss 0.02\n",
      "| epoch 21 |  iter 301 / 351 | time 13[s] | loss 0.02\n",
      "| epoch 21 |  iter 321 / 351 | time 14[s] | loss 0.02\n",
      "| epoch 21 |  iter 341 / 351 | time 14[s] | loss 0.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 96.220%\n",
      "| epoch 22 |  iter 1 / 351 | time 0[s] | loss 0.03\n",
      "| epoch 22 |  iter 21 / 351 | time 0[s] | loss 0.02\n",
      "| epoch 22 |  iter 41 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 22 |  iter 61 / 351 | time 2[s] | loss 0.02\n",
      "| epoch 22 |  iter 81 / 351 | time 3[s] | loss 0.02\n",
      "| epoch 22 |  iter 101 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 22 |  iter 121 / 351 | time 5[s] | loss 0.02\n",
      "| epoch 22 |  iter 141 / 351 | time 5[s] | loss 0.02\n",
      "| epoch 22 |  iter 161 / 351 | time 6[s] | loss 0.02\n",
      "| epoch 22 |  iter 181 / 351 | time 7[s] | loss 0.01\n",
      "| epoch 22 |  iter 201 / 351 | time 8[s] | loss 0.01\n",
      "| epoch 22 |  iter 221 / 351 | time 9[s] | loss 0.01\n",
      "| epoch 22 |  iter 241 / 351 | time 9[s] | loss 0.01\n",
      "| epoch 22 |  iter 261 / 351 | time 10[s] | loss 0.02\n",
      "| epoch 22 |  iter 281 / 351 | time 11[s] | loss 0.03\n",
      "| epoch 22 |  iter 301 / 351 | time 12[s] | loss 0.03\n",
      "| epoch 22 |  iter 321 / 351 | time 13[s] | loss 0.02\n",
      "| epoch 22 |  iter 341 / 351 | time 14[s] | loss 0.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 97.120%\n",
      "| epoch 23 |  iter 1 / 351 | time 0[s] | loss 0.01\n",
      "| epoch 23 |  iter 21 / 351 | time 0[s] | loss 0.02\n",
      "| epoch 23 |  iter 41 / 351 | time 1[s] | loss 0.01\n",
      "| epoch 23 |  iter 61 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 23 |  iter 81 / 351 | time 2[s] | loss 0.02\n",
      "| epoch 23 |  iter 101 / 351 | time 3[s] | loss 0.01\n",
      "| epoch 23 |  iter 121 / 351 | time 3[s] | loss 0.01\n",
      "| epoch 23 |  iter 141 / 351 | time 4[s] | loss 0.01\n",
      "| epoch 23 |  iter 161 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 23 |  iter 181 / 351 | time 5[s] | loss 0.02\n",
      "| epoch 23 |  iter 201 / 351 | time 6[s] | loss 0.01\n",
      "| epoch 23 |  iter 221 / 351 | time 6[s] | loss 0.02\n",
      "| epoch 23 |  iter 241 / 351 | time 7[s] | loss 0.01\n",
      "| epoch 23 |  iter 261 / 351 | time 8[s] | loss 0.02\n",
      "| epoch 23 |  iter 281 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 23 |  iter 301 / 351 | time 9[s] | loss 0.03\n",
      "| epoch 23 |  iter 321 / 351 | time 9[s] | loss 0.03\n",
      "| epoch 23 |  iter 341 / 351 | time 10[s] | loss 0.04\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 93.920%\n",
      "| epoch 24 |  iter 1 / 351 | time 0[s] | loss 0.04\n",
      "| epoch 24 |  iter 21 / 351 | time 0[s] | loss 0.04\n",
      "| epoch 24 |  iter 41 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 24 |  iter 61 / 351 | time 1[s] | loss 0.04\n",
      "| epoch 24 |  iter 81 / 351 | time 2[s] | loss 0.03\n",
      "| epoch 24 |  iter 101 / 351 | time 3[s] | loss 0.03\n",
      "| epoch 24 |  iter 121 / 351 | time 3[s] | loss 0.04\n",
      "| epoch 24 |  iter 141 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 24 |  iter 161 / 351 | time 4[s] | loss 0.02\n",
      "| epoch 24 |  iter 181 / 351 | time 5[s] | loss 0.02\n",
      "| epoch 24 |  iter 201 / 351 | time 6[s] | loss 0.02\n",
      "| epoch 24 |  iter 221 / 351 | time 6[s] | loss 0.02\n",
      "| epoch 24 |  iter 241 / 351 | time 7[s] | loss 0.02\n",
      "| epoch 24 |  iter 261 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 24 |  iter 281 / 351 | time 8[s] | loss 0.03\n",
      "| epoch 24 |  iter 301 / 351 | time 9[s] | loss 0.03\n",
      "| epoch 24 |  iter 321 / 351 | time 9[s] | loss 0.02\n",
      "| epoch 24 |  iter 341 / 351 | time 10[s] | loss 0.02\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 97.060%\n",
      "| epoch 25 |  iter 1 / 351 | time 0[s] | loss 0.01\n",
      "| epoch 25 |  iter 21 / 351 | time 0[s] | loss 0.01\n",
      "| epoch 25 |  iter 41 / 351 | time 1[s] | loss 0.01\n",
      "| epoch 25 |  iter 61 / 351 | time 1[s] | loss 0.02\n",
      "| epoch 25 |  iter 81 / 351 | time 2[s] | loss 0.01\n",
      "| epoch 25 |  iter 101 / 351 | time 3[s] | loss 0.01\n",
      "| epoch 25 |  iter 121 / 351 | time 3[s] | loss 0.01\n",
      "| epoch 25 |  iter 141 / 351 | time 4[s] | loss 0.01\n",
      "| epoch 25 |  iter 161 / 351 | time 5[s] | loss 0.01\n",
      "| epoch 25 |  iter 181 / 351 | time 5[s] | loss 0.01\n",
      "| epoch 25 |  iter 201 / 351 | time 6[s] | loss 0.01\n",
      "| epoch 25 |  iter 221 / 351 | time 7[s] | loss 0.01\n",
      "| epoch 25 |  iter 241 / 351 | time 7[s] | loss 0.01\n",
      "| epoch 25 |  iter 261 / 351 | time 8[s] | loss 0.01\n",
      "| epoch 25 |  iter 281 / 351 | time 8[s] | loss 0.01\n",
      "| epoch 25 |  iter 301 / 351 | time 9[s] | loss 0.01\n",
      "| epoch 25 |  iter 321 / 351 | time 10[s] | loss 0.01\n",
      "| epoch 25 |  iter 341 / 351 | time 10[s] | loss 0.01\n",
      "Q 77+85  \n",
      "T 162 \n",
      "O 162 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "O 1139\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "O 163 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "O 857 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "O 1053\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "O 1427\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "O 236 \n",
      "---\n",
      "验证集准确率 98.500%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..') # 为了导入上层目录的文件而进行的设置\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # 忽略警告信息\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 读入数据集\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt') # 读取加法运算数据集\n",
    "char_to_id, id_to_char = sequence.get_vocab() # 获取字符和ID的对应关系\n",
    "\n",
    "# 是否反转输入序列（有时反转输入可以提高Seq2Seq模型的性能）\n",
    "is_reverse = True  # 可以改为True尝试\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1] # 反转输入序列，[:: -1]表示步长为-1，即从后向前取元素\n",
    "# =========================================================\n",
    "\n",
    "# 设定超参数\n",
    "vocab_size = len(char_to_id) # 词典大小\n",
    "wordvec_size = 16 # 词向量维度\n",
    "hidden_size = 128 # 隐藏状态维度\n",
    "batch_size = 128 # 批量大小\n",
    "max_epoch = 25 # 最大训练轮数\n",
    "max_grad = 5.0 # 用于梯度裁剪的阈值\n",
    "\n",
    "# 选择使用基础Seq2Seq还是Peeky Seq2Seq模型 ========================\n",
    "# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n",
    "# ================================================================\n",
    "optimizer = Adam() # Adam优化器\n",
    "trainer = Trainer(model, optimizer) # 训练器\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad) # 训练一个epoch\n",
    "\n",
    "    correct_num = 0 # 预测正确的样本数\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]] # 取出一个样本，question的形状为(1, 7)，correct的形状为(1, 5)\n",
    "        verbose = i < 10 # 前10个样本打印详细信息\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse) # 评估样本\n",
    "\n",
    "    acc = float(correct_num) / len(x_test) # 计算准确率\n",
    "    acc_list.append(acc) # 记录准确率\n",
    "    print('验证集准确率 %.3f%%' % (acc * 100)) # 打印验证集准确率\n",
    "\n",
    "# 绘制图形\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('训练轮数')\n",
    "plt.ylabel('验证集准确率')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6999b",
   "metadata": {},
   "source": [
    "这里，我们在第一个改进（反转输入）的基础上进行实验，结果如图所示。\n",
    "\n",
    "<img src=\"./fig/reverse_peeky.png\" alt=\"reverse_peeky\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "如图所示，加上了 Peeky 的 seq2seq 的结果大幅变好。刚过 10 个 epoch 时，正确率已经超过 90%，最终的正确率接近 100%。\n",
    "\n",
    "从上述实验结果可知，Reverse 和 Peeky 都有很好的效果。借助反转输入语句的 Reverse 和共享编码器信息的 Peeky，我们获得了令人满意的结果！\n",
    "\n",
    "这样我们就结束了对 seq2seq 的改进，不过故事仍在继续。实际上，本节的改进只能说是 “小改进”，下一章我们将对 seq2seq 进行 “大改进”。届时将使用名为 Attention 的技术，它能使 seq2seq 发生巨大变化。\n",
    "\n",
    "这里的实验有几个需要注意的地方。因为使用 Peeky 后，网络的权重参数会额外地增加，计算量也会增加，所以这里的实验结果必须考虑到相应地增加的 “负担”。另外，seq2seq 的精度会随着超参数的调整而大幅变化。虽然这里的结果是可靠的，但是在实际问题中，它的效果可能不稳定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293931da",
   "metadata": {},
   "source": [
    "## seq2seq的应用\n",
    "seq2seq 将某个时序数据转换为另一个时序数据，这个转换时序数据的框架可以应用在各种各样的任务中，比如以下几个例子。\n",
    "- 机器翻译：将 “一种语言的文本” 转换为 “另一种语言的文本”\n",
    "- 自动摘要：将 “一个长文本” 转换为 “短摘要”\n",
    "- 问答系统：将 “问题” 转换为 “答案”\n",
    "- 邮件自动回复：将 “接收到的邮件文本” 转换为 “回复文本”\n",
    "\n",
    "像这样，seq2seq 可以用于处理成对的时序数据的问题。除了自然语言之外，也可以用于语音、视频等数据。有些乍一看不属于 seq2seq 的问题，通过对输入输出数据进行预处理，也可以应用 seq2seq。本节将介绍几个使用 seq2seq 的应用。如果读者能由此感受到 seq2seq 的潜力和乐趣，那就再好不过了。\n",
    "\n",
    "##1 聊天机器人\n",
    "聊天机器人是人和计算机使用文本进行对话的程序，现在已经被用于 Facebook、Twitter 等各种各样的服务中。\n",
    "\n",
    "毫无疑问，聊天机器人可以使用 seq2seq。因为对话是由 “对方的发言” 和 “本方的发言” 构成的，可以理解为是将 “对方的发言” 转换为 “本方的发言” 的问题。也就是说，如果有对话文本数据，seq2seq 就可以学习它。\n",
    "\n",
    "另外，聊天机器人也可以用在实用场景中。文献进行了将基于 seq2seq 的聊天机器人应用于 IT 帮助台的实验，并展示了它成功解决有关 VPN 接入问题的例子。这里，我们将其中的一部分对话翻译成中文。\n",
    "\n",
    "<img src=\"./fig/seq2seq_chat.png\" alt=\"seq2seq_chat\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "从图中可知，机器（聊天机器人）很好地解决了问题，遇到 VPN 接入问题的人被引导到了能解决该问题的 URL。当然，它只能解决与 IT 帮助台相关的问题，无法泛化。但是，基于对话获取答案或者线索，这一点非常实用，应用范围很广。实际上，这样的服务（简易版）已经可以在若干网站上看到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59af6b",
   "metadata": {},
   "source": [
    "## 算法学习\n",
    "本章进行的 seq2seq 实验是加法这样的简单问题，但理论上它也能处理更加高级的问题，比如下图所示的 Python 代码。\n",
    "\n",
    "<img src=\"./fig/python_example.png\" alt=\"python_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "源代码也是用字符编写的时序数据。我们可以将跨行的代码处理为一条语句（将换行视为换行符）。因此，可以直接将源代码输入 seq2seq，让 seq2seq 对源代码与目标答案一起进行学习。\n",
    "\n",
    "上述包含 for 语句和 if 语句的问题不太容易解决。不过，即便是这样的问题，也可以在 seq2seq 框架内处理。通过改造 seq2seq 的结构，可以期待这样的问题能够被解决。\n",
    "\n",
    "下一章将介绍 RNN 的扩展——NTM（Neural Turing Machine，神经图灵机）模型。届时计算机（图灵机）将学习内存的读写顺序，重现算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788946bd",
   "metadata": {},
   "source": [
    "## 自动图像描述\n",
    "到目前为止，我们只看了处理文本的 seq2seq 的应用示例，除了文本之外，seq2seq 还可以处理图像、语音等类型的数据。本节我们来看一下将图像转换为文本的自动图像描述（image captioning）。\n",
    "\n",
    "自动图像描述将 “图像” 转换为 “文本”。如图所示，这也可以在 seq2seq 的框架下解决。\n",
    "\n",
    "<img src=\"./fig/auto_image.png\" alt=\"auto_image\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "上图是我们熟悉的网络结构。实际上，它和之前的网络的唯一区别在于，编码器从 LSTM 换成了 CNN（Convolutional Neural Network，卷积神经网络），而解码器仍使用与之前相同的网络。仅通过这点改变（用 CNN 替代 LSTM），seq2seq 就可以处理图像了。\n",
    "\n",
    "这里补充说明一下图中的 CNN。此处，CNN 对图像进行编码，这时 CNN 的最终输出是特征图。因为特征图是三维（高、宽、通道）的，所以需要想一些办法让解码器的 LSTM 可以处理它。于是，我们将 CNN 的特征图扁平化到一维，并基于全连接的 Affine 层进行转换。之后，再将转换后的数据传递给解码器，就可以像之前一样生成文本了。\n",
    "\n",
    "图中的CNN使用VGG、ResNet等成熟网络，并使用在别的图像数据集（ImageNet等）上学习好的权重，这样可以获得好的编码，从而生成好的文本。\n",
    "\n",
    "现在我们看几个基于 seq2seq 的自动图像描述的例子。下图显示的是由基于 TensorFlow 的 im2txt生成的例子。此处使用的网络基于上图，并在其上进行了若干改进。\n",
    "\n",
    "<img src=\"./fig/auto_image_example.png\" alt=\"auto_image_example\" style=\"display: block; margin: 0 auto;\">\n",
    "\n",
    "由图可知，这里得到了很不错的结果。之所以能够达到这样的效果，是因为存在大量的图像和说明文字等训练数据（比如，ImageNet 等大规模的图像数据）。再加上可以高效学习这些训练数据的 seq2seq 的应用，最终得到了上图所示的出色结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026c558",
   "metadata": {},
   "source": [
    "## 小结\n",
    "- 基于 RNN 的语言模型可以生成新的文本\n",
    "- 在进行文本生成时，重复“输入一个单词（字符），基于模型的输出（概率分布）进行采样”这一过程\n",
    "- 通过组合两个 RNN，可以将一个时序数据转换为另一个时序数据（seq2seq）\n",
    "- 在 seq2seq 中，编码器对输入语句进行编码，解码器接收并解码这个编码信息，获得目标输出语句\n",
    "- 反转输入语句（Reverse）和将编码信息分配给解码器的多个层（Peeky）可以有效提高 seq2seq 的精度\n",
    "- seq2seq 可以用在机器翻译、聊天机器人和自动图像描述等各种各样的应用中"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
